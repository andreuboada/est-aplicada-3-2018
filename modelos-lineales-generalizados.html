<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Estadística Aplicada III</title>
  <meta name="description" content="Notas y material para el curso de Estadística Aplicada III, 2018 (ITAM)">
  <meta name="generator" content="bookdown 0.7.8 and GitBook 2.6.7">

  <meta property="og:title" content="Estadística Aplicada III" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Notas y material para el curso de Estadística Aplicada III, 2018 (ITAM)" />
  <meta name="github-repo" content="andreuboada/est-aplicada-3-2018" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Estadística Aplicada III" />
  
  <meta name="twitter:description" content="Notas y material para el curso de Estadística Aplicada III, 2018 (ITAM)" />
  

<meta name="author" content="Andreu Boada de Atela">


<meta name="date" content="2018-05-02">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="regularizacion.html">
<link rel="next" href="analisis-de-discriminante-lineal-1.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
<link rel="stylesheet" href="toc.css" type="text/css" />
<link rel="stylesheet" href="font-awesome.min.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Estadística Aplicada III</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Temario y referencias</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#evaluacion"><i class="fa fa-check"></i>Evaluación</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#software-r-y-rstudio"><i class="fa fa-check"></i>Software: R y Rstudio</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#referencias-principales"><i class="fa fa-check"></i>Referencias principales</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#otras-referencias"><i class="fa fa-check"></i>Otras referencias</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#tareas"><i class="fa fa-check"></i>Tareas</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introducción</a><ul>
<li class="chapter" data-level="1.1" data-path="intro.html"><a href="intro.html#por-que-un-analisis-multivariado"><i class="fa fa-check"></i><b>1.1</b> ¿Por qué un análisis multivariado?</a></li>
<li class="chapter" data-level="1.2" data-path="intro.html"><a href="intro.html#la-paradoja-de-simpson"><i class="fa fa-check"></i><b>1.2</b> La paradoja de Simpson</a></li>
<li class="chapter" data-level="1.3" data-path="intro.html"><a href="intro.html#modelos-log-lineales"><i class="fa fa-check"></i><b>1.3</b> Modelos log-lineales</a></li>
<li class="chapter" data-level="1.4" data-path="intro.html"><a href="intro.html#interpretacion-de-parametros"><i class="fa fa-check"></i><b>1.4</b> Interpretación de parámetros</a><ul>
<li class="chapter" data-level="1.4.1" data-path="intro.html"><a href="intro.html#ejemplo-dos-monedas"><i class="fa fa-check"></i><b>1.4.1</b> Ejemplo: dos monedas</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="intro.html"><a href="intro.html#otros-ejemplos"><i class="fa fa-check"></i><b>1.5</b> Otros ejemplos</a><ul>
<li class="chapter" data-level="1.5.1" data-path="intro.html"><a href="intro.html#discriminacion-de-residentes-hispanos-con-discapacidades"><i class="fa fa-check"></i><b>1.5.1</b> Discriminación de residentes hispanos con discapacidades</a></li>
<li class="chapter" data-level="1.5.2" data-path="intro.html"><a href="intro.html#consumo-de-chocolate-y-premios-nobel"><i class="fa fa-check"></i><b>1.5.2</b> Consumo de chocolate y premios Nobel</a></li>
</ul></li>
<li class="chapter" data-level="1.6" data-path="intro.html"><a href="intro.html#tarea"><i class="fa fa-check"></i><b>1.6</b> Tarea</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="Rintro.html"><a href="Rintro.html"><i class="fa fa-check"></i><b>2</b> Temas selectos de R</a><ul>
<li class="chapter" data-level="2.1" data-path="Rintro.html"><a href="Rintro.html#que-ventajas-tiene-r"><i class="fa fa-check"></i><b>2.1</b> ¿Qué ventajas tiene R?</a><ul>
<li class="chapter" data-level="2.1.1" data-path="Rintro.html"><a href="Rintro.html#r-es-gratuito-y-de-codigo-abierto"><i class="fa fa-check"></i><b>2.1.1</b> R es gratuito y de código abierto</a></li>
<li class="chapter" data-level="2.1.2" data-path="Rintro.html"><a href="Rintro.html#r-tiene-una-comunidad-comprometida"><i class="fa fa-check"></i><b>2.1.2</b> R tiene una comunidad comprometida</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="Rintro.html"><a href="Rintro.html#flujo-basico-de-trabajo-para-el-analisis-de-datos-en-r."><i class="fa fa-check"></i><b>2.2</b> Flujo básico de trabajo para el análisis de datos en R.</a></li>
<li class="chapter" data-level="2.3" data-path="Rintro.html"><a href="Rintro.html#introduccion-a-r-como-lenguaje-de-programacion-y-la-plataforma-interactiva-de-rstudio."><i class="fa fa-check"></i><b>2.3</b> Introducción a R como lenguaje de programación, y la plataforma interactiva de RStudio.</a><ul>
<li class="chapter" data-level="2.3.1" data-path="Rintro.html"><a href="Rintro.html#como-entender-r"><i class="fa fa-check"></i><b>2.3.1</b> ¿Cómo entender R?</a></li>
<li class="chapter" data-level="2.3.2" data-path="Rintro.html"><a href="Rintro.html#por-que-r"><i class="fa fa-check"></i><b>2.3.2</b> ¿Por qué R?</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="Rintro.html"><a href="Rintro.html#estructuras-de-datos"><i class="fa fa-check"></i><b>2.4</b> Estructuras de datos</a><ul>
<li class="chapter" data-level="2.4.1" data-path="Rintro.html"><a href="Rintro.html#vectores"><i class="fa fa-check"></i><b>2.4.1</b> Vectores</a></li>
<li class="chapter" data-level="2.4.2" data-path="Rintro.html"><a href="Rintro.html#data-frames"><i class="fa fa-check"></i><b>2.4.2</b> Data Frames</a></li>
<li class="chapter" data-level="2.4.3" data-path="Rintro.html"><a href="Rintro.html#listas"><i class="fa fa-check"></i><b>2.4.3</b> Listas</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="Rintro.html"><a href="Rintro.html#r-markdown"><i class="fa fa-check"></i><b>2.5</b> R Markdown</a><ul>
<li class="chapter" data-level="2.5.1" data-path="Rintro.html"><a href="Rintro.html#que-es-r-markdown"><i class="fa fa-check"></i><b>2.5.1</b> ¿Qué es R Markdown?</a></li>
<li class="chapter" data-level="2.5.2" data-path="Rintro.html"><a href="Rintro.html#estructura-basica-de-r-markdown"><i class="fa fa-check"></i><b>2.5.2</b> Estructura básica de R Markdown</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="Rintro.html"><a href="Rintro.html#proyectos-de-rstudio"><i class="fa fa-check"></i><b>2.6</b> Proyectos de RStudio</a></li>
<li class="chapter" data-level="2.7" data-path="Rintro.html"><a href="Rintro.html#otros-aspectos-importantes-de-r"><i class="fa fa-check"></i><b>2.7</b> Otros aspectos importantes de R</a><ul>
<li class="chapter" data-level="2.7.1" data-path="Rintro.html"><a href="Rintro.html#valores-faltantes"><i class="fa fa-check"></i><b>2.7.1</b> Valores faltantes</a></li>
<li class="chapter" data-level="2.7.2" data-path="Rintro.html"><a href="Rintro.html#funciones"><i class="fa fa-check"></i><b>2.7.2</b> Funciones</a></li>
<li class="chapter" data-level="2.7.3" data-path="Rintro.html"><a href="Rintro.html#funcionales"><i class="fa fa-check"></i><b>2.7.3</b> Funcionales</a></li>
<li class="chapter" data-level="2.7.4" data-path="Rintro.html"><a href="Rintro.html#rendimiento-en-r"><i class="fa fa-check"></i><b>2.7.4</b> Rendimiento en R</a></li>
</ul></li>
<li class="chapter" data-level="2.8" data-path="Rintro.html"><a href="Rintro.html#tarea-1"><i class="fa fa-check"></i><b>2.8</b> Tarea</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="manipulacion-y-visualizacion-de-datos.html"><a href="manipulacion-y-visualizacion-de-datos.html"><i class="fa fa-check"></i><b>3</b> Manipulación y visualización de datos</a><ul>
<li class="chapter" data-level="3.1" data-path="manipulacion-y-visualizacion-de-datos.html"><a href="manipulacion-y-visualizacion-de-datos.html#el-principio-de-datos-limpios"><i class="fa fa-check"></i><b>3.1</b> El principio de datos limpios</a></li>
<li class="chapter" data-level="3.2" data-path="manipulacion-y-visualizacion-de-datos.html"><a href="manipulacion-y-visualizacion-de-datos.html#limpieza-de-datos"><i class="fa fa-check"></i><b>3.2</b> Limpieza de datos</a></li>
<li class="chapter" data-level="3.3" data-path="manipulacion-y-visualizacion-de-datos.html"><a href="manipulacion-y-visualizacion-de-datos.html#separa-aplica-combina"><i class="fa fa-check"></i><b>3.3</b> <em>Separa-aplica-combina</em></a></li>
<li class="chapter" data-level="3.4" data-path="manipulacion-y-visualizacion-de-datos.html"><a href="manipulacion-y-visualizacion-de-datos.html#muertes-por-armas-de-fuego-en-eua"><i class="fa fa-check"></i><b>3.4</b> Muertes por armas de fuego en EUA</a></li>
<li class="chapter" data-level="3.5" data-path="manipulacion-y-visualizacion-de-datos.html"><a href="manipulacion-y-visualizacion-de-datos.html#el-cuarteto-de-anscombe"><i class="fa fa-check"></i><b>3.5</b> El Cuarteto de Anscombe</a></li>
<li class="chapter" data-level="3.6" data-path="manipulacion-y-visualizacion-de-datos.html"><a href="manipulacion-y-visualizacion-de-datos.html#the-grammar-of-graphics-de-leland-wilkinson"><i class="fa fa-check"></i><b>3.6</b> The <em>Grammar of Graphics</em> de Leland Wilkinson</a></li>
<li class="chapter" data-level="3.7" data-path="manipulacion-y-visualizacion-de-datos.html"><a href="manipulacion-y-visualizacion-de-datos.html#ggplot"><i class="fa fa-check"></i><b>3.7</b> ggplot</a></li>
<li class="chapter" data-level="3.8" data-path="manipulacion-y-visualizacion-de-datos.html"><a href="manipulacion-y-visualizacion-de-datos.html#un-histograma-de-las-muertes-en-iraq"><i class="fa fa-check"></i><b>3.8</b> Un histograma de las muertes en Iraq</a></li>
<li class="chapter" data-level="3.9" data-path="manipulacion-y-visualizacion-de-datos.html"><a href="manipulacion-y-visualizacion-de-datos.html#inglehartwelzel-un-mapa-cultural-del-mundo"><i class="fa fa-check"></i><b>3.9</b> Inglehart–Welzel: un mapa cultural del mundo</a><ul>
<li class="chapter" data-level="3.9.1" data-path="manipulacion-y-visualizacion-de-datos.html"><a href="manipulacion-y-visualizacion-de-datos.html#creando-un-ggplot"><i class="fa fa-check"></i><b>3.9.1</b> Creando un ggplot</a></li>
<li class="chapter" data-level="3.9.2" data-path="manipulacion-y-visualizacion-de-datos.html"><a href="manipulacion-y-visualizacion-de-datos.html#mapeos-aesthetics"><i class="fa fa-check"></i><b>3.9.2</b> Mapeos: Aesthetics</a></li>
</ul></li>
<li class="chapter" data-level="3.10" data-path="manipulacion-y-visualizacion-de-datos.html"><a href="manipulacion-y-visualizacion-de-datos.html#poniendo-todo-junto"><i class="fa fa-check"></i><b>3.10</b> Poniendo todo junto</a></li>
<li class="chapter" data-level="3.11" data-path="manipulacion-y-visualizacion-de-datos.html"><a href="manipulacion-y-visualizacion-de-datos.html#tarea-2"><i class="fa fa-check"></i><b>3.11</b> Tarea</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="teorema-del-limite-central.html"><a href="teorema-del-limite-central.html"><i class="fa fa-check"></i><b>4</b> Teorema del Límite Central</a><ul>
<li class="chapter" data-level="4.1" data-path="teorema-del-limite-central.html"><a href="teorema-del-limite-central.html#la-distribucion-de-la-media"><i class="fa fa-check"></i><b>4.1</b> La distribución de la media</a></li>
<li class="chapter" data-level="4.2" data-path="teorema-del-limite-central.html"><a href="teorema-del-limite-central.html#de-donde-proviene-la-distribucion-normal"><i class="fa fa-check"></i><b>4.2</b> ¿De dónde proviene la distribución normal?</a><ul>
<li class="chapter" data-level="4.2.1" data-path="teorema-del-limite-central.html"><a href="teorema-del-limite-central.html#que-signo-tiene-c"><i class="fa fa-check"></i><b>4.2.1</b> ¿Qué signo tiene c?</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="teorema-del-limite-central.html"><a href="teorema-del-limite-central.html#otras-observaciones"><i class="fa fa-check"></i><b>4.3</b> Otras observaciones</a></li>
<li class="chapter" data-level="4.4" data-path="teorema-del-limite-central.html"><a href="teorema-del-limite-central.html#diagramas-de-caja-y-brazos"><i class="fa fa-check"></i><b>4.4</b> Diagramas de caja y brazos</a><ul>
<li class="chapter" data-level="" data-path="teorema-del-limite-central.html"><a href="teorema-del-limite-central.html#ejemplo"><i class="fa fa-check"></i>Ejemplo</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="teorema-del-limite-central.html"><a href="teorema-del-limite-central.html#graficas-de-cuantiles-teoricos"><i class="fa fa-check"></i><b>4.5</b> Gráficas de cuantiles teóricos</a><ul>
<li class="chapter" data-level="" data-path="teorema-del-limite-central.html"><a href="teorema-del-limite-central.html#ejemplo-normal"><i class="fa fa-check"></i>Ejemplo: normal</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="teorema-del-limite-central.html"><a href="teorema-del-limite-central.html#graficas-de-cuantiles-para-un-conjunto-de-datos"><i class="fa fa-check"></i><b>4.6</b> Gráficas de cuantiles para un conjunto de datos</a><ul>
<li class="chapter" data-level="4.6.1" data-path="teorema-del-limite-central.html"><a href="teorema-del-limite-central.html#que-buscar-en-una-grafica-de-cuantiles"><i class="fa fa-check"></i><b>4.6.1</b> ¿Qué buscar en una gráfica de cuantiles?</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="teorema-del-limite-central.html"><a href="teorema-del-limite-central.html#graficas-qq-normales"><i class="fa fa-check"></i><b>4.7</b> Gráficas qq-normales</a><ul>
<li class="chapter" data-level="" data-path="teorema-del-limite-central.html"><a href="teorema-del-limite-central.html#ejemplo-cantantes"><i class="fa fa-check"></i>Ejemplo: cantantes</a></li>
</ul></li>
<li class="chapter" data-level="4.8" data-path="teorema-del-limite-central.html"><a href="teorema-del-limite-central.html#el-tlc-y-errores-estandar"><i class="fa fa-check"></i><b>4.8</b> El TLC y errores estándar</a></li>
<li class="chapter" data-level="4.9" data-path="teorema-del-limite-central.html"><a href="teorema-del-limite-central.html#ejemplo-1"><i class="fa fa-check"></i><b>4.9</b> Ejemplo</a></li>
<li class="chapter" data-level="4.10" data-path="teorema-del-limite-central.html"><a href="teorema-del-limite-central.html#tarea-3"><i class="fa fa-check"></i><b>4.10</b> Tarea</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="analisis-de-datos-categoricos.html"><a href="analisis-de-datos-categoricos.html"><i class="fa fa-check"></i><b>5</b> Análisis de datos categóricos</a><ul>
<li class="chapter" data-level="5.1" data-path="analisis-de-datos-categoricos.html"><a href="analisis-de-datos-categoricos.html#repaso-y-algunos-conceptos"><i class="fa fa-check"></i><b>5.1</b> Repaso y algunos conceptos</a><ul>
<li class="chapter" data-level="5.1.1" data-path="analisis-de-datos-categoricos.html"><a href="analisis-de-datos-categoricos.html#caso-binomial"><i class="fa fa-check"></i><b>5.1.1</b> Caso binomial</a></li>
<li class="chapter" data-level="" data-path="analisis-de-datos-categoricos.html"><a href="analisis-de-datos-categoricos.html#estimacion-de-parametros-multinomiales"><i class="fa fa-check"></i>Estimación de parámetros multinomiales</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="analisis-de-datos-categoricos.html"><a href="analisis-de-datos-categoricos.html#la-chi2-de-pearson-de-una-multinomial"><i class="fa fa-check"></i><b>5.2</b> La <span class="math inline">\(\chi^2\)</span> de Pearson de una multinomial</a><ul>
<li class="chapter" data-level="5.2.1" data-path="analisis-de-datos-categoricos.html"><a href="analisis-de-datos-categoricos.html#cociente-de-verosimilitud-de-una-multinomial"><i class="fa fa-check"></i><b>5.2.1</b> Cociente de verosimilitud de una multinomial</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="analisis-de-datos-categoricos.html"><a href="analisis-de-datos-categoricos.html#definiciones"><i class="fa fa-check"></i><b>5.3</b> Definiciones</a><ul>
<li class="chapter" data-level="5.3.1" data-path="analisis-de-datos-categoricos.html"><a href="analisis-de-datos-categoricos.html#notacion"><i class="fa fa-check"></i><b>5.3.1</b> Notación</a></li>
<li class="chapter" data-level="5.3.2" data-path="analisis-de-datos-categoricos.html"><a href="analisis-de-datos-categoricos.html#razon-de-momios"><i class="fa fa-check"></i><b>5.3.2</b> Razón de momios</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="analisis-de-datos-categoricos.html"><a href="analisis-de-datos-categoricos.html#asociacion-en-tablas-de-tamano-itimes-j"><i class="fa fa-check"></i><b>5.4</b> Asociación en tablas de tamaño <span class="math inline">\(I\times J\)</span></a><ul>
<li class="chapter" data-level="5.4.1" data-path="analisis-de-datos-categoricos.html"><a href="analisis-de-datos-categoricos.html#razones-de-momios-en-tablas-itimes-j"><i class="fa fa-check"></i><b>5.4.1</b> Razones de momios en tablas <span class="math inline">\(I\times J\)</span></a></li>
<li class="chapter" data-level="5.4.2" data-path="analisis-de-datos-categoricos.html"><a href="analisis-de-datos-categoricos.html#ejemplo-mushrooms"><i class="fa fa-check"></i><b>5.4.2</b> Ejemplo: mushrooms</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="analisis-de-datos-categoricos.html"><a href="analisis-de-datos-categoricos.html#intervalos-de-confianza-para-los-parametros-de-asociacion"><i class="fa fa-check"></i><b>5.5</b> Intervalos de confianza para los parámetros de asociación</a><ul>
<li class="chapter" data-level="5.5.1" data-path="analisis-de-datos-categoricos.html"><a href="analisis-de-datos-categoricos.html#error-estandar-de-la-razon-de-momios"><i class="fa fa-check"></i><b>5.5.1</b> Error estándar de la razón de momios</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="analisis-de-datos-categoricos.html"><a href="analisis-de-datos-categoricos.html#prueba-de-independencia"><i class="fa fa-check"></i><b>5.6</b> Prueba de independencia</a><ul>
<li class="chapter" data-level="5.6.1" data-path="analisis-de-datos-categoricos.html"><a href="analisis-de-datos-categoricos.html#la-prueba-chi2-de-pearson"><i class="fa fa-check"></i><b>5.6.1</b> La prueba <span class="math inline">\(\chi^2\)</span> de Pearson</a></li>
<li class="chapter" data-level="5.6.2" data-path="analisis-de-datos-categoricos.html"><a href="analisis-de-datos-categoricos.html#ejemplo-brecha-de-genero"><i class="fa fa-check"></i><b>5.6.2</b> Ejemplo: brecha de género</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="analisis-de-datos-categoricos.html"><a href="analisis-de-datos-categoricos.html#general-social-survey-1972---2016"><i class="fa fa-check"></i><b>5.7</b> General Social Survey 1972 - 2016</a></li>
<li class="chapter" data-level="5.8" data-path="analisis-de-datos-categoricos.html"><a href="analisis-de-datos-categoricos.html#la-catadora-de-te"><i class="fa fa-check"></i><b>5.8</b> La catadora de té</a></li>
<li class="chapter" data-level="5.9" data-path="analisis-de-datos-categoricos.html"><a href="analisis-de-datos-categoricos.html#modelos-multinomiales-para-conteos"><i class="fa fa-check"></i><b>5.9</b> Modelos multinomiales para conteos</a></li>
<li class="chapter" data-level="5.10" data-path="analisis-de-datos-categoricos.html"><a href="analisis-de-datos-categoricos.html#modelos-log-lineales-con-tres-variables-categoricas"><i class="fa fa-check"></i><b>5.10</b> Modelos log lineales con tres variables categóricas</a><ul>
<li class="chapter" data-level="5.10.1" data-path="analisis-de-datos-categoricos.html"><a href="analisis-de-datos-categoricos.html#tipos-de-independencia"><i class="fa fa-check"></i><b>5.10.1</b> Tipos de independencia</a></li>
<li class="chapter" data-level="5.10.2" data-path="analisis-de-datos-categoricos.html"><a href="analisis-de-datos-categoricos.html#asociacion-homogenea-e-interacciones-de-3-factores"><i class="fa fa-check"></i><b>5.10.2</b> Asociación homogénea e interacciones de 3 factores</a></li>
</ul></li>
<li class="chapter" data-level="5.11" data-path="analisis-de-datos-categoricos.html"><a href="analisis-de-datos-categoricos.html#ejemplo-sensitividad-y-especificidad"><i class="fa fa-check"></i><b>5.11</b> Ejemplo: sensitividad y especificidad</a></li>
<li class="chapter" data-level="5.12" data-path="analisis-de-datos-categoricos.html"><a href="analisis-de-datos-categoricos.html#ejemplo-horoscopos"><i class="fa fa-check"></i><b>5.12</b> Ejemplo: horóscopos</a></li>
<li class="chapter" data-level="5.13" data-path="analisis-de-datos-categoricos.html"><a href="analisis-de-datos-categoricos.html#tarea-opcional"><i class="fa fa-check"></i><b>5.13</b> Tarea (opcional)</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="regresion-logistica-1.html"><a href="regresion-logistica-1.html"><i class="fa fa-check"></i><b>6</b> Regresión logística 1</a><ul>
<li class="chapter" data-level="6.1" data-path="regresion-logistica-1.html"><a href="regresion-logistica-1.html#regresion-logistica-con-un-solo-predictor"><i class="fa fa-check"></i><b>6.1</b> Regresión logística con un solo predictor</a></li>
<li class="chapter" data-level="6.2" data-path="regresion-logistica-1.html"><a href="regresion-logistica-1.html#el-modelo-de-regresion-logistica"><i class="fa fa-check"></i><b>6.2</b> El modelo de regresión logística</a><ul>
<li class="chapter" data-level="6.2.1" data-path="regresion-logistica-1.html"><a href="regresion-logistica-1.html#funcion-logistica"><i class="fa fa-check"></i><b>6.2.1</b> Función logística</a></li>
<li class="chapter" data-level="" data-path="regresion-logistica-1.html"><a href="regresion-logistica-1.html#ejemplo-2"><i class="fa fa-check"></i>Ejemplo</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="regresion-logistica-1.html"><a href="regresion-logistica-1.html#tarea-4"><i class="fa fa-check"></i><b>6.3</b> Tarea</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="regresion-logistica-2.html"><a href="regresion-logistica-2.html"><i class="fa fa-check"></i><b>7</b> Regresión logística 2</a><ul>
<li class="chapter" data-level="7.1" data-path="regresion-logistica-2.html"><a href="regresion-logistica-2.html#incertidumbre-en-la-estimacion"><i class="fa fa-check"></i><b>7.1</b> Incertidumbre en la estimación</a></li>
<li class="chapter" data-level="7.2" data-path="regresion-logistica-2.html"><a href="regresion-logistica-2.html#funcion-logistica-1"><i class="fa fa-check"></i><b>7.2</b> Función logística</a></li>
<li class="chapter" data-level="7.3" data-path="regresion-logistica-2.html"><a href="regresion-logistica-2.html#interpretacion-de-los-coeficientes"><i class="fa fa-check"></i><b>7.3</b> Interpretación de los coeficientes</a><ul>
<li class="chapter" data-level="7.3.1" data-path="regresion-logistica-2.html"><a href="regresion-logistica-2.html#evaluar-en-o-alrededor-de-la-media"><i class="fa fa-check"></i><b>7.3.1</b> Evaluar en (o alrededor de) la media</a></li>
<li class="chapter" data-level="7.3.2" data-path="regresion-logistica-2.html"><a href="regresion-logistica-2.html#la-regla-de-dividir-entre-4"><i class="fa fa-check"></i><b>7.3.2</b> La regla de “dividir entre 4”</a></li>
<li class="chapter" data-level="7.3.3" data-path="regresion-logistica-2.html"><a href="regresion-logistica-2.html#interpretacion-de-los-coeficientes-como-cocientes-de-momios"><i class="fa fa-check"></i><b>7.3.3</b> Interpretación de los coeficientes como cocientes de momios</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="regresion-logistica-2.html"><a href="regresion-logistica-2.html#ejemplo-pozos-en-bangladesh"><i class="fa fa-check"></i><b>7.4</b> Ejemplo: pozos en Bangladesh</a><ul>
<li class="chapter" data-level="7.4.1" data-path="regresion-logistica-2.html"><a href="regresion-logistica-2.html#descripcion-del-problema"><i class="fa fa-check"></i><b>7.4.1</b> Descripción del problema</a></li>
<li class="chapter" data-level="7.4.2" data-path="regresion-logistica-2.html"><a href="regresion-logistica-2.html#antecedentes-del-problema"><i class="fa fa-check"></i><b>7.4.2</b> Antecedentes del problema</a></li>
<li class="chapter" data-level="7.4.3" data-path="regresion-logistica-2.html"><a href="regresion-logistica-2.html#metodologia-para-abordar-el-problema"><i class="fa fa-check"></i><b>7.4.3</b> Metodología para abordar el problema</a></li>
<li class="chapter" data-level="7.4.4" data-path="regresion-logistica-2.html"><a href="regresion-logistica-2.html#ajuste-y-resultados-del-modelo"><i class="fa fa-check"></i><b>7.4.4</b> Ajuste y resultados del modelo</a></li>
<li class="chapter" data-level="7.4.5" data-path="regresion-logistica-2.html"><a href="regresion-logistica-2.html#interpretacion-de-los-coeficientes-1"><i class="fa fa-check"></i><b>7.4.5</b> Interpretación de los coeficientes</a></li>
<li class="chapter" data-level="7.4.6" data-path="regresion-logistica-2.html"><a href="regresion-logistica-2.html#agregamos-una-segunda-variable-de-entrada"><i class="fa fa-check"></i><b>7.4.6</b> Agregamos una segunda variable de entrada</a></li>
<li class="chapter" data-level="7.4.7" data-path="regresion-logistica-2.html"><a href="regresion-logistica-2.html#comparacion-de-coeficientes-cuando-anades-un-predictor"><i class="fa fa-check"></i><b>7.4.7</b> Comparación de coeficientes cuando añades un predictor</a></li>
<li class="chapter" data-level="7.4.8" data-path="regresion-logistica-2.html"><a href="regresion-logistica-2.html#graficar-el-modelo-ajustado-con-dos-predictores"><i class="fa fa-check"></i><b>7.4.8</b> Graficar el modelo ajustado con dos predictores</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="regresion-logistica-2.html"><a href="regresion-logistica-2.html#ajuste-de-coeficientes-para-regresion-logistica-binomial."><i class="fa fa-check"></i><b>7.5</b> Ajuste de coeficientes para regresión logística (binomial).</a></li>
<li class="chapter" data-level="7.6" data-path="regresion-logistica-2.html"><a href="regresion-logistica-2.html#descenso-en-gradiente"><i class="fa fa-check"></i><b>7.6</b> Descenso en gradiente</a><ul>
<li class="chapter" data-level="7.6.1" data-path="regresion-logistica-2.html"><a href="regresion-logistica-2.html#seleccion-de-tamano-de-paso-eta"><i class="fa fa-check"></i><b>7.6.1</b> Selección de tamaño de paso <span class="math inline">\(\eta\)</span></a></li>
<li class="chapter" data-level="7.6.2" data-path="regresion-logistica-2.html"><a href="regresion-logistica-2.html#funciones-de-varias-variables"><i class="fa fa-check"></i><b>7.6.2</b> Funciones de varias variables</a></li>
</ul></li>
<li class="chapter" data-level="7.7" data-path="regresion-logistica-2.html"><a href="regresion-logistica-2.html#ejemplo-diabetes"><i class="fa fa-check"></i><b>7.7</b> Ejemplo: diabetes</a></li>
<li class="chapter" data-level="7.8" data-path="regresion-logistica-2.html"><a href="regresion-logistica-2.html#observaciones-adicionales"><i class="fa fa-check"></i><b>7.8</b> Observaciones adicionales</a></li>
<li class="chapter" data-level="7.9" data-path="regresion-logistica-2.html"><a href="regresion-logistica-2.html#regresion-logistica-para-problemas-de-mas-de-2-clases"><i class="fa fa-check"></i><b>7.9</b> Regresión logística para problemas de más de 2 clases</a></li>
<li class="chapter" data-level="7.10" data-path="regresion-logistica-2.html"><a href="regresion-logistica-2.html#regresion-logistica-multinomial"><i class="fa fa-check"></i><b>7.10</b> Regresión logística multinomial</a></li>
<li class="chapter" data-level="7.11" data-path="regresion-logistica-2.html"><a href="regresion-logistica-2.html#identificabilidad-y-separacion"><i class="fa fa-check"></i><b>7.11</b> Identificabilidad y separación</a></li>
<li class="chapter" data-level="7.12" data-path="regresion-logistica-2.html"><a href="regresion-logistica-2.html#tarea-5"><i class="fa fa-check"></i><b>7.12</b> Tarea</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="regresion-logistica-3.html"><a href="regresion-logistica-3.html"><i class="fa fa-check"></i><b>8</b> Regresión logística 3</a><ul>
<li class="chapter" data-level="8.1" data-path="regresion-logistica-3.html"><a href="regresion-logistica-3.html#ejemplo-oscares"><i class="fa fa-check"></i><b>8.1</b> Ejemplo óscares</a></li>
<li class="chapter" data-level="8.2" data-path="regresion-logistica-3.html"><a href="regresion-logistica-3.html#repaso-de-regresion-logistica"><i class="fa fa-check"></i><b>8.2</b> Repaso de regresión logística</a></li>
<li class="chapter" data-level="8.3" data-path="regresion-logistica-3.html"><a href="regresion-logistica-3.html#regresion-logistica-con-interacciones"><i class="fa fa-check"></i><b>8.3</b> Regresión logística con interacciones</a></li>
<li class="chapter" data-level="8.4" data-path="regresion-logistica-3.html"><a href="regresion-logistica-3.html#graficas-del-modelo-con-interacciones"><i class="fa fa-check"></i><b>8.4</b> Gráficas del modelo con interacciones</a></li>
<li class="chapter" data-level="8.5" data-path="regresion-logistica-3.html"><a href="regresion-logistica-3.html#agregar-mas-predictores"><i class="fa fa-check"></i><b>8.5</b> Agregar más predictores</a></li>
<li class="chapter" data-level="8.6" data-path="regresion-logistica-3.html"><a href="regresion-logistica-3.html#evaluacion-de-modelos-de-regresion-logistica"><i class="fa fa-check"></i><b>8.6</b> Evaluación de modelos de regresión logística</a><ul>
<li class="chapter" data-level="8.6.1" data-path="regresion-logistica-3.html"><a href="regresion-logistica-3.html#graficas-de-residuales-agrupados-vs-predictores"><i class="fa fa-check"></i><b>8.6.1</b> Gráficas de residuales agrupados vs predictores</a></li>
<li class="chapter" data-level="8.6.2" data-path="regresion-logistica-3.html"><a href="regresion-logistica-3.html#transformaciones"><i class="fa fa-check"></i><b>8.6.2</b> Transformaciones</a></li>
<li class="chapter" data-level="8.6.3" data-path="regresion-logistica-3.html"><a href="regresion-logistica-3.html#tasa-de-error-y-comparacion-contra-el-modelo-nulo"><i class="fa fa-check"></i><b>8.6.3</b> Tasa de error y comparación contra el modelo nulo</a></li>
</ul></li>
<li class="chapter" data-level="8.7" data-path="regresion-logistica-3.html"><a href="regresion-logistica-3.html#diferencias-predictivas-promedio-en-la-escala-de-probabilidad"><i class="fa fa-check"></i><b>8.7</b> Diferencias predictivas promedio en la escala de probabilidad</a><ul>
<li class="chapter" data-level="" data-path="regresion-logistica-3.html"><a href="regresion-logistica-3.html#diferencias-predictivas-promedio-en-presencia-de-interacciones"><i class="fa fa-check"></i>Diferencias predictivas promedio en presencia de interacciones</a></li>
<li class="chapter" data-level="" data-path="regresion-logistica-3.html"><a href="regresion-logistica-3.html#notacion-general-para-diferencias-predictivas"><i class="fa fa-check"></i>Notación general para diferencias predictivas</a></li>
</ul></li>
<li class="chapter" data-level="8.8" data-path="regresion-logistica-3.html"><a href="regresion-logistica-3.html#tarea-6"><i class="fa fa-check"></i><b>8.8</b> Tarea</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="regularizacion.html"><a href="regularizacion.html"><i class="fa fa-check"></i><b>9</b> Regularización</a><ul>
<li class="chapter" data-level="9.1" data-path="regularizacion.html"><a href="regularizacion.html#repaso"><i class="fa fa-check"></i><b>9.1</b> Repaso</a></li>
<li class="chapter" data-level="9.2" data-path="regularizacion.html"><a href="regularizacion.html#otras-medidas-de-clasificacion"><i class="fa fa-check"></i><b>9.2</b> Otras medidas de clasificación</a></li>
<li class="chapter" data-level="9.3" data-path="regularizacion.html"><a href="regularizacion.html#analisis-de-error-en-clasificacion-binaria"><i class="fa fa-check"></i><b>9.3</b> Análisis de error en clasificación binaria</a><ul>
<li class="chapter" data-level="9.3.1" data-path="regularizacion.html"><a href="regularizacion.html#punto-de-corte-para-un-clasificador-binario"><i class="fa fa-check"></i><b>9.3.1</b> Punto de corte para un clasificador binario</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="regularizacion.html"><a href="regularizacion.html#curvas-roc"><i class="fa fa-check"></i><b>9.4</b> Curvas ROC</a><ul>
<li class="chapter" data-level="9.4.1" data-path="regularizacion.html"><a href="regularizacion.html#espacio-roc"><i class="fa fa-check"></i><b>9.4.1</b> Espacio ROC</a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="regularizacion.html"><a href="regularizacion.html#regularizacion-1"><i class="fa fa-check"></i><b>9.5</b> Regularización</a><ul>
<li class="chapter" data-level="9.5.1" data-path="regularizacion.html"><a href="regularizacion.html#reduciendo-varianza-de-los-coeficientes"><i class="fa fa-check"></i><b>9.5.1</b> Reduciendo varianza de los coeficientes</a></li>
</ul></li>
<li class="chapter" data-level="9.6" data-path="regularizacion.html"><a href="regularizacion.html#regularizacion-ridge"><i class="fa fa-check"></i><b>9.6</b> Regularización Ridge</a><ul>
<li class="chapter" data-level="9.6.1" data-path="regularizacion.html"><a href="regularizacion.html#seleccion-de-coeficiente-de-regularizacion"><i class="fa fa-check"></i><b>9.6.1</b> Selección de coeficiente de regularización</a></li>
</ul></li>
<li class="chapter" data-level="9.7" data-path="regularizacion.html"><a href="regularizacion.html#regularizacion-lasso"><i class="fa fa-check"></i><b>9.7</b> Regularización Lasso</a></li>
<li class="chapter" data-level="9.8" data-path="regularizacion.html"><a href="regularizacion.html#tarea-7"><i class="fa fa-check"></i><b>9.8</b> Tarea</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="modelos-lineales-generalizados.html"><a href="modelos-lineales-generalizados.html"><i class="fa fa-check"></i><b>10</b> Modelos lineales generalizados</a><ul>
<li class="chapter" data-level="10.1" data-path="modelos-lineales-generalizados.html"><a href="modelos-lineales-generalizados.html#regresion-lineal-y-logistica"><i class="fa fa-check"></i><b>10.1</b> Regresión lineal y logística</a></li>
<li class="chapter" data-level="10.2" data-path="modelos-lineales-generalizados.html"><a href="modelos-lineales-generalizados.html#otros-modelos"><i class="fa fa-check"></i><b>10.2</b> Otros modelos</a></li>
<li class="chapter" data-level="10.3" data-path="modelos-lineales-generalizados.html"><a href="modelos-lineales-generalizados.html#ejemplo-accidentes-de-trafico"><i class="fa fa-check"></i><b>10.3</b> Ejemplo: accidentes de tráfico</a></li>
<li class="chapter" data-level="10.4" data-path="modelos-lineales-generalizados.html"><a href="modelos-lineales-generalizados.html#interpretacion-de-coeficientes-poisson"><i class="fa fa-check"></i><b>10.4</b> Interpretación de coeficientes Poisson</a></li>
<li class="chapter" data-level="10.5" data-path="modelos-lineales-generalizados.html"><a href="modelos-lineales-generalizados.html#diferencias-entre-el-modelo-binomial-y-poisson"><i class="fa fa-check"></i><b>10.5</b> Diferencias entre el modelo binomial y Poisson</a></li>
<li class="chapter" data-level="10.6" data-path="modelos-lineales-generalizados.html"><a href="modelos-lineales-generalizados.html#ejemplo-fertilidad-en-fiji"><i class="fa fa-check"></i><b>10.6</b> Ejemplo: fertilidad en Fiji</a></li>
<li class="chapter" data-level="10.7" data-path="modelos-lineales-generalizados.html"><a href="modelos-lineales-generalizados.html#variable-de-expuestos-offset"><i class="fa fa-check"></i><b>10.7</b> Variable de expuestos (offset)</a></li>
<li class="chapter" data-level="10.8" data-path="modelos-lineales-generalizados.html"><a href="modelos-lineales-generalizados.html#ejemplos-seguros"><i class="fa fa-check"></i><b>10.8</b> Ejemplos: seguros</a><ul>
<li class="chapter" data-level="" data-path="modelos-lineales-generalizados.html"><a href="modelos-lineales-generalizados.html#numero-de-expuestos-interpretacion"><i class="fa fa-check"></i>Número de expuestos (interpretación)</a></li>
</ul></li>
<li class="chapter" data-level="10.9" data-path="modelos-lineales-generalizados.html"><a href="modelos-lineales-generalizados.html#ejemplo-arboles"><i class="fa fa-check"></i><b>10.9</b> Ejemplo: árboles</a></li>
<li class="chapter" data-level="10.10" data-path="modelos-lineales-generalizados.html"><a href="modelos-lineales-generalizados.html#sobredispersion"><i class="fa fa-check"></i><b>10.10</b> Sobredispersión</a></li>
<li class="chapter" data-level="10.11" data-path="modelos-lineales-generalizados.html"><a href="modelos-lineales-generalizados.html#ejemplo-numero-de-publicaciones"><i class="fa fa-check"></i><b>10.11</b> Ejemplo: número de publicaciones</a></li>
<li class="chapter" data-level="10.12" data-path="modelos-lineales-generalizados.html"><a href="modelos-lineales-generalizados.html#tarea-8"><i class="fa fa-check"></i><b>10.12</b> Tarea</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="analisis-de-discriminante-lineal-1.html"><a href="analisis-de-discriminante-lineal-1.html"><i class="fa fa-check"></i><b>11</b> Análisis de Discriminante Lineal 1</a><ul>
<li class="chapter" data-level="11.1" data-path="analisis-de-discriminante-lineal-1.html"><a href="analisis-de-discriminante-lineal-1.html#problemas-de-clasificacion"><i class="fa fa-check"></i><b>11.1</b> Problemas de clasificación</a></li>
<li class="chapter" data-level="11.2" data-path="analisis-de-discriminante-lineal-1.html"><a href="analisis-de-discriminante-lineal-1.html#funciones-de-discriminante"><i class="fa fa-check"></i><b>11.2</b> Funciones de discriminante</a></li>
<li class="chapter" data-level="11.3" data-path="analisis-de-discriminante-lineal-1.html"><a href="analisis-de-discriminante-lineal-1.html#regresion-lineal-en-una-matriz-indicadora"><i class="fa fa-check"></i><b>11.3</b> Regresión lineal en una matriz indicadora</a></li>
<li class="chapter" data-level="11.4" data-path="analisis-de-discriminante-lineal-1.html"><a href="analisis-de-discriminante-lineal-1.html#discriminante-lineal-de-fisher"><i class="fa fa-check"></i><b>11.4</b> Discriminante lineal de Fisher</a><ul>
<li class="chapter" data-level="11.4.1" data-path="analisis-de-discriminante-lineal-1.html"><a href="analisis-de-discriminante-lineal-1.html#ejemplo-separacion-entre-clases"><i class="fa fa-check"></i><b>11.4.1</b> Ejemplo: separación entre clases</a></li>
<li class="chapter" data-level="11.4.2" data-path="analisis-de-discriminante-lineal-1.html"><a href="analisis-de-discriminante-lineal-1.html#ejemplo-iris-de-fisher"><i class="fa fa-check"></i><b>11.4.2</b> Ejemplo: iris de Fisher</a></li>
</ul></li>
<li class="chapter" data-level="11.5" data-path="analisis-de-discriminante-lineal-1.html"><a href="analisis-de-discriminante-lineal-1.html#tarea-9"><i class="fa fa-check"></i><b>11.5</b> Tarea</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="analisis-de-discriminante-lineal-2.html"><a href="analisis-de-discriminante-lineal-2.html"><i class="fa fa-check"></i><b>12</b> Análisis de Discriminante Lineal 2</a><ul>
<li class="chapter" data-level="12.1" data-path="analisis-de-discriminante-lineal-2.html"><a href="analisis-de-discriminante-lineal-2.html#aplicaciones"><i class="fa fa-check"></i><b>12.1</b> Aplicaciones</a></li>
<li class="chapter" data-level="12.2" data-path="analisis-de-discriminante-lineal-2.html"><a href="analisis-de-discriminante-lineal-2.html#ejemplo-vinos"><i class="fa fa-check"></i><b>12.2</b> Ejemplo: vinos</a></li>
<li class="chapter" data-level="12.3" data-path="analisis-de-discriminante-lineal-2.html"><a href="analisis-de-discriminante-lineal-2.html#ejemplo-admisiones-al-mba"><i class="fa fa-check"></i><b>12.3</b> Ejemplo: admisiones al MBA</a></li>
<li class="chapter" data-level="12.4" data-path="analisis-de-discriminante-lineal-2.html"><a href="analisis-de-discriminante-lineal-2.html#repaso-1"><i class="fa fa-check"></i><b>12.4</b> Repaso</a><ul>
<li><a href="analisis-de-discriminante-lineal-2.html#caso-k2">Caso <span class="math inline">\(k=2\)</span></a></li>
</ul></li>
<li class="chapter" data-level="12.5" data-path="analisis-de-discriminante-lineal-2.html"><a href="analisis-de-discriminante-lineal-2.html#supuestos-probabilisticos"><i class="fa fa-check"></i><b>12.5</b> Supuestos probabilísticos</a></li>
<li class="chapter" data-level="12.6" data-path="analisis-de-discriminante-lineal-2.html"><a href="analisis-de-discriminante-lineal-2.html#relacion-con-minimos-cuadrados"><i class="fa fa-check"></i><b>12.6</b> Relación con mínimos cuadrados</a></li>
<li class="chapter" data-level="12.7" data-path="analisis-de-discriminante-lineal-2.html"><a href="analisis-de-discriminante-lineal-2.html#tarea-10"><i class="fa fa-check"></i><b>12.7</b> Tarea</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="componentes-principales-1.html"><a href="componentes-principales-1.html"><i class="fa fa-check"></i><b>13</b> Componentes Principales 1</a><ul>
<li class="chapter" data-level="13.1" data-path="componentes-principales-1.html"><a href="componentes-principales-1.html#motivacion"><i class="fa fa-check"></i><b>13.1</b> Motivación</a></li>
<li class="chapter" data-level="13.2" data-path="componentes-principales-1.html"><a href="componentes-principales-1.html#formulacion-de-maxima-varianza"><i class="fa fa-check"></i><b>13.2</b> Formulación de máxima varianza</a></li>
<li class="chapter" data-level="13.3" data-path="componentes-principales-1.html"><a href="componentes-principales-1.html#formulacion-de-error-minimo"><i class="fa fa-check"></i><b>13.3</b> Formulación de error mínimo</a></li>
<li class="chapter" data-level="13.4" data-path="componentes-principales-1.html"><a href="componentes-principales-1.html#aplicaciones-de-pca"><i class="fa fa-check"></i><b>13.4</b> Aplicaciones de PCA</a><ul>
<li class="chapter" data-level="13.4.1" data-path="componentes-principales-1.html"><a href="componentes-principales-1.html#compresion-de-datos"><i class="fa fa-check"></i><b>13.4.1</b> Compresión de datos</a></li>
<li class="chapter" data-level="13.4.2" data-path="componentes-principales-1.html"><a href="componentes-principales-1.html#ejemplo-compresion-de-una-imagen"><i class="fa fa-check"></i><b>13.4.2</b> Ejemplo: compresión de una imagen</a></li>
</ul></li>
<li class="chapter" data-level="13.5" data-path="componentes-principales-1.html"><a href="componentes-principales-1.html#tarea-11"><i class="fa fa-check"></i><b>13.5</b> Tarea</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="componentes-principales-2.html"><a href="componentes-principales-2.html"><i class="fa fa-check"></i><b>14</b> Componentes Principales 2</a><ul>
<li class="chapter" data-level="14.1" data-path="componentes-principales-2.html"><a href="componentes-principales-2.html#pca-probabilistico-y-analisis-de-factores"><i class="fa fa-check"></i><b>14.1</b> PCA probabilístico y Análisis de Factores</a><ul>
<li class="chapter" data-level="14.1.1" data-path="componentes-principales-2.html"><a href="componentes-principales-2.html#analisis-de-factores"><i class="fa fa-check"></i><b>14.1.1</b> Análisis de factores</a></li>
</ul></li>
<li class="chapter" data-level="14.2" data-path="componentes-principales-2.html"><a href="componentes-principales-2.html#analisis-de-factores-descripcion-tradicional"><i class="fa fa-check"></i><b>14.2</b> Análisis de factores (descripción tradicional)</a><ul>
<li class="chapter" data-level="14.2.1" data-path="componentes-principales-2.html"><a href="componentes-principales-2.html#el-modelo"><i class="fa fa-check"></i><b>14.2.1</b> El modelo</a></li>
<li class="chapter" data-level="14.2.2" data-path="componentes-principales-2.html"><a href="componentes-principales-2.html#estimacion-del-modelo"><i class="fa fa-check"></i><b>14.2.2</b> Estimación del modelo</a></li>
<li class="chapter" data-level="14.2.3" data-path="componentes-principales-2.html"><a href="componentes-principales-2.html#analisis-de-factores-de-maxima-verosimilitud"><i class="fa fa-check"></i><b>14.2.3</b> Análisis de factores de máxima verosimilitud</a></li>
<li class="chapter" data-level="14.2.4" data-path="componentes-principales-2.html"><a href="componentes-principales-2.html#evaluacion-del-modelo"><i class="fa fa-check"></i><b>14.2.4</b> Evaluación del modelo</a></li>
<li class="chapter" data-level="14.2.5" data-path="componentes-principales-2.html"><a href="componentes-principales-2.html#visualizacion"><i class="fa fa-check"></i><b>14.2.5</b> Visualización</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="componentes-principales-2.html"><a href="componentes-principales-2.html#tarea-12"><i class="fa fa-check"></i><b>14.3</b> Tarea</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="referencias.html"><a href="referencias.html"><i class="fa fa-check"></i>Referencias</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Publicado con bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Estadística Aplicada III</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="modelos-lineales-generalizados" class="section level1">
<h1><span class="header-section-number">Clase 10</span> Modelos lineales generalizados</h1>
<style>
  .espacio {
    margin-bottom: 1cm;
  }
</style>
<style>
  .espacio3 {
    margin-bottom: 3cm;
  }
</style>
<p class="espacio">
</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(tidyverse)</code></pre></div>
<div id="regresion-lineal-y-logistica" class="section level2">
<h2><span class="header-section-number">10.1</span> Regresión lineal y logística</h2>
<p>Los modelos lineales generalizados son una familia de modelos para el análisis estadístico. Incluye la regresión lineal y logística como casos especiales.</p>
<p>La regresión lineal predice directamente datos continuos <span class="math inline">\(y\)</span> de un <em>predictor lineal</em> <span class="math inline">\(X\beta = \beta_0 + X_1\beta_1 + \cdots + X_k\beta_k.\)</span></p>
<p>La regresión logística predice <span class="math inline">\(P(y=1)\)</span> para datos binarios a partir de un predictor lineal transformado por la función logística inversa.</p>
<p>Un modelo lineal generalizado consiste de:</p>
<ol style="list-style-type: decimal">
<li><p>Un vector de datos <span class="math inline">\(y=(y_1,\ldots,y_n)\)</span></p></li>
<li><p>Predictores <span class="math inline">\(X\)</span> y coeficientes <span class="math inline">\(\beta\)</span> para construir un predictor lineal <span class="math inline">\(X\beta\)</span>.</p></li>
<li><p>Una <em>función liga</em> <span class="math inline">\(g\)</span> que da como resultado datos transformados <span class="math display">\[\hat{y}=g^{-1}(X\beta)\]</span> que son usados para modelar los datos.</p></li>
<li><p>Una distribución para los datos <span class="math inline">\(p(y|\hat{y})\)</span>.</p></li>
<li><p>Posiblemente otros parámetros, como varianza, o puntos de corte, involucrados en los predictores, o bien, la función liga o la distribución de los datos.</p></li>
</ol>
<p class="espacio3">
</p>
<img src="figuras/manicule2.jpg" />
<div class="centered">
<p class="espacio">
</p>
<p>¿Qué función liga se utiliza en regresión lineal?</p>
<ol style="list-style-type: lower-alpha">
<li><p><span class="math inline">\(g(x) = X\beta\)</span>.</p></li>
<li><p><span class="math inline">\(g(x)=\alpha + \beta x\)</span>.</p></li>
<li><p><span class="math inline">\(g(x)=\dfrac{1}{\sqrt{2\pi\sigma^2}}\,e^{-\frac{1}{2\sigma^2}(x-\mu)^2}\)</span>.</p></li>
<li><p><span class="math inline">\(g(x)=x\)</span>.</p></li>
</ol>
<p class="espacio3">
</p>
</div>
<p><br></p>
<p class="espacio3">
</p>
<img src="figuras/manicule2.jpg" />
<div class="centered">
<p class="espacio">
</p>
<p>¿Qué función liga se utiliza en regresión logística?</p>
<ol style="list-style-type: lower-alpha">
<li><p><span class="math inline">\(g(x) = \dfrac{e^x}{1-e^x}\)</span>.</p></li>
<li><p><span class="math inline">\(g(x)= \mbox{logit}^{-1}(x)\)</span>.</p></li>
<li><p><span class="math inline">\(g(x)=\left(\dfrac{1}{1+e^{-x}}\right)^{-1}\)</span>.</p></li>
<li><p><span class="math inline">\(g(x)=x\)</span>.</p></li>
</ol>
<p class="espacio3">
</p>
</div>
<p><br></p>
<hr />
</div>
<div id="otros-modelos" class="section level2">
<h2><span class="header-section-number">10.2</span> Otros modelos</h2>
<p>Otros modelos que vamos a ver después son:</p>
<ol style="list-style-type: decimal">
<li><p>El <em>modelo Poisson</em> se utiliza para datos de <em>conteos</em>; es decir, donde cada dato observado <span class="math inline">\(y_i\)</span> puede ser igual a <span class="math inline">\(0, 1, 2,\dots\)</span>. La función liga que se utiliza habitualmente <span class="math inline">\(g\)</span> es logarítmica, de modo que <span class="math inline">\(g(x) = \mbox{exp}(x)\)</span> transforma un predictor lineal continuo <span class="math inline">\(X_i\beta\)</span> en un <span class="math inline">\(y_i\)</span> positivo. La distribución de datos es Poisson. A veces es buena idea agregar un parámetro a este modelo para capturar la <strong>sobredispersión</strong>, es decir, la variación en los datos más allá de la que captura el modelo.</p></li>
<li><p>El modelo <em>logístico-binomial</em> se utiliza en casos cuando los datos observados <span class="math inline">\(y_i\)</span> representan el número de éxitos en <span class="math inline">\(n_i\)</span> ensayos independientes. En este modelo la función liga es <span class="math inline">\(\mbox{logit}\)</span> y la distribución de los datos es binomial. Al igual que con la regresión Poisson, el modelo binomial típicamente se puede mejorar agregando un parámetro de sobredispersión.</p></li>
<li><p>El modelo <em>probit</em> es igual que regresión logística pero se reemplaza la función liga por la <em>distribución normal acumulada</em>. Se puede pensar como usar la distribución normal en los errores estimados del modelo.</p></li>
</ol>
<p class="espacio">
</p>

<div class="information">
<strong>Nota:</strong> Podemos usar <code>glm()</code> directamente para ajustar regresiones logísticas-binomiales, probit y Poisson, entre otras, y para corregir la sobredispersión cuando sea necesario.
</div>

<p><br></p>
<p><br></p>
</div>
<div id="ejemplo-accidentes-de-trafico" class="section level2">
<h2><span class="header-section-number">10.3</span> Ejemplo: accidentes de tráfico</h2>
<p>En el modelo de Poisson, cada observación <span class="math inline">\(i\)</span> corresponde a una situación (típicamente una ubicación espacial o un intervalo de tiempo) en la que se observan eventos <span class="math inline">\(y_i\)</span>. Por ejemplo, con <span class="math inline">\(i\)</span> se puede representar esquinas de calles en una ciudad y <span class="math inline">\(y_i\)</span> podría ser el número de accidentes de tráfico en la <span class="math inline">\(i\)</span>-ésima esquina en un año determinado.</p>
<p>Al igual que con la regresión lineal y logística, la variación en <span class="math inline">\(y\)</span> puede explicarse con predictores lineales <span class="math inline">\(X\)</span>. En el ejemplo de accidentes de tráfico, estos predictores podrían incluir: un término constante, una medida de la velocidad promedio del tráfico cerca de la esquina y un indicador para si la esquina tiene una señal de tráfico. El modelo básico de regresión de Poisson tiene la forma</p>
<p><span class="math display">\[
y_i \sim \mbox{Poisson}(\theta_i).
\]</span></p>
<p>El parámetro <span class="math inline">\(\theta_i\)</span> debe ser positivo, por lo que tiene sentido ajustar un predictor lineal en una escala logarítmica:</p>
<p><span class="math display">\[
\theta_i = \exp(X_i\beta).
\]</span></p>
</div>
<div id="interpretacion-de-coeficientes-poisson" class="section level2">
<h2><span class="header-section-number">10.4</span> Interpretación de coeficientes Poisson</h2>
<p>Los coeficientes <span class="math inline">\(\beta\)</span> pueden exponenciarse y tratarse como efectos multiplicativos. Por ejemplo, supongamos que el modelo de accidentes de tráfico es</p>
<p><span class="math display">\[
y_i ∼ \mbox{Poisson}(\exp(2.8 + 0.012X_{i1} − 0.20X_{i2})),
\]</span> donde <span class="math inline">\(X_{i1}\)</span> es la velocidad promedio (en millas por hora) en las calles cercanas y <span class="math inline">\(X_{i2} = 1\)</span> si la esquina (o intersección) tiene una señal de tráfico y <span class="math inline">\(0\)</span> en caso contrario.</p>
<p class="espacio">
</p>
<p>Entonces podemos interpretar cada coeficiente de la siguiente manera:</p>
<ul>
<li><p>El término constante es el intercepto, es decir, la predicción de si <span class="math inline">\(X_{i1} = 0\)</span> y <span class="math inline">\(X_{i2} = 0\)</span>. Como esto no es posible (ninguna calle tendrá una velocidad promedio de 0), entonces no intentaremos interpretar el término constante.</p></li>
<li><p>El coeficiente de <span class="math inline">\(X_{i1}\)</span> es la diferencia esperada en <span class="math inline">\(y\)</span> (en la escala logarítmica) para cada milla por hora adicional de velocidad de tráfico. Por lo tanto, el aumento multiplicativo esperado es <span class="math inline">\(e^{0.012} = 1.012\)</span>, o una diferencia positiva de 1.2% en la tasa de accidentes de tráfico por milla por hora. Dado que la velocidad del tráfico varía en decenas de milla por hora, en realidad tendría sentido definir <span class="math inline">\(X_{i1}\)</span> como velocidad en decenas de milla por hora, en cuyo caso su coeficiente sería 0.12, que corresponde a un aumento del 12% (más precisamente, <span class="math inline">\(e^{0.12} = 1.127\)</span>: a 12.7% de aumento) en la tasa de accidentes por diez milla por hora.</p></li>
<li><p>El coeficiente de <span class="math inline">\(X_{i2}\)</span> nos dice que la diferencia predictiva de tener una señal de tráfico se puede encontrar multiplicando la tasa de accidentes por <span class="math inline">\(\exp(-0.20) = 0.82\)</span> produciendo una reducción del 18%.</p></li>
</ul>
<p>Al igual que con los modelos de regresión en general, cada coeficiente se interpreta como una comparación en el que un predictor difiere en una unidad, mientras que todos los demás predictores permanecen constantes, lo cual no es necesariamente el supuesto más apropiado. Por ejemplo, no se debería esperar necesariamente que la instalación de señales de tráfico en todas las esquinas de la ciudad reduzca los accidentes en un 18%.</p>
</div>
<div id="diferencias-entre-el-modelo-binomial-y-poisson" class="section level2">
<h2><span class="header-section-number">10.5</span> Diferencias entre el modelo binomial y Poisson</h2>
<p>El modelo de Poisson es similar al modelo binomial para conteos pero se aplica en situaciones ligeramente diferentes:</p>
<ul>
<li><p>Si cada observación <span class="math inline">\(y_i\)</span> se puede interpretar como el número de “éxitos” de <span class="math inline">\(n_i\)</span> experimentos aleatorios, entonces es común usar el modelo Binomial-logístico.</p></li>
<li><p>Si cada observación <span class="math inline">\(y_i\)</span> no tiene un límite superior natural (no se basa en un número determinado de ensayos independientes) entonces es común usar el modelo Poisson-logarítmico.</p></li>
</ul>
<hr />
<p><br></p>
</div>
<div id="ejemplo-fertilidad-en-fiji" class="section level2">
<h2><span class="header-section-number">10.6</span> Ejemplo: fertilidad en Fiji</h2>
<p>La siguiente tabla adaptada de Little (1978) <span class="citation">(RJ <a href="#ref-rj1978generalized">1978</a>)</span>:, proviene de la Encuesta de Fertilidad de Fiji, publicada en los informes de World Fertility Survey. La tabla muestra datos sobre el número de hijos nacidos de mujeres casadas de raza de indios nativos clasificados por duración desde su primer matrimonio (agrupados en seis categorías), tipo de lugar de residencia (Suva, otro urbano y rural) y nivel educativo (cuatro categorías: ninguno, primaria inferior, primaria superior y secundaria o superior). Cada casilla de la tabla muestra la media, la varianza y el número de observaciones.</p>
<p class="espacio3">
</p>
<font size="1" face="Times New Roman">
<table class="tex-table" width="80%">
<tr class="bt">
<td class="ar">
Marr.
</td>
<td colspan="4" align="center">
Suva
</td>
<td colspan="4" align="center">
Otro urbano
</td>
<td colspan="4" align="center">
Rural
</td>
</tr>
<tr class="bb">
<td class="ar">
Dur.
</td>
<td class="ar">
N
</td>
<td class="ar">
LP
</td>
<td class="ar">
UP
</td>
<td class="ar">
S<span class="math inline">\(+\)</span>
</td>
<td class="ar">
N
</td>
<td class="ar">
LP
</td>
<td class="ar">
UP
</td>
<td class="ar">
S<span class="math inline">\(+\)</span>
</td>
<td class="ar">
N
</td>
<td class="ar">
LP
</td>
<td class="ar">
UP
</td>
<td class="ar">
S<span class="math inline">\(+\)</span>
</td>
</tr>
<tr class="bt">
<td class="ar">
0–4
</td>
<td class="ar">
0.50
</td>
<td class="ar">
1.14
</td>
<td class="ar">
0.90
</td>
<td class="ar">
0.73
</td>
<td class="ar">
1.17
</td>
<td class="ar">
0.85
</td>
<td class="ar">
1.05
</td>
<td class="ar">
0.69
</td>
<td class="ar">
0.97
</td>
<td class="ar">
0.96
</td>
<td class="ar">
0.97
</td>
<td class="ar">
0.74
</td>
</tr>
<tr>
<td class="ar">
</td>
<td class="ar">
1.14
</td>
<td class="ar">
0.73
</td>
<td class="ar">
0.67
</td>
<td class="ar">
0.48
</td>
<td class="ar">
1.06
</td>
<td class="ar">
1.59
</td>
<td class="ar">
0.73
</td>
<td class="ar">
0.54
</td>
<td class="ar">
0.88
</td>
<td class="ar">
0.81
</td>
<td class="ar">
0.80
</td>
<td class="ar">
0.59
</td>
</tr>
<tr>
<td class="ar">
</td>
<td class="ar">
8
</td>
<td class="ar">
21
</td>
<td class="ar">
42
</td>
<td class="ar">
51
</td>
<td class="ar">
12
</td>
<td class="ar">
27
</td>
<td class="ar">
39
</td>
<td class="ar">
51
</td>
<td class="ar">
62
</td>
<td class="ar">
102
</td>
<td class="ar">
107
</td>
<td class="ar">
47
</td>
</tr>
<tr>
<td class="ar">
5–9
</td>
<td class="ar">
3.10
</td>
<td class="ar">
2.67
</td>
<td class="ar">
2.04
</td>
<td class="ar">
1.73
</td>
<td class="ar">
4.54
</td>
<td class="ar">
2.65
</td>
<td class="ar">
2.68
</td>
<td class="ar">
2.29
</td>
<td class="ar">
2.44
</td>
<td class="ar">
2.71
</td>
<td class="ar">
2.47
</td>
<td class="ar">
2.24
</td>
</tr>
<tr>
<td class="ar">
</td>
<td class="ar">
1.66
</td>
<td class="ar">
0.99
</td>
<td class="ar">
1.87
</td>
<td class="ar">
0.68
</td>
<td class="ar">
3.44
</td>
<td class="ar">
1.51
</td>
<td class="ar">
0.97
</td>
<td class="ar">
0.81
</td>
<td class="ar">
1.93
</td>
<td class="ar">
1.36
</td>
<td class="ar">
1.30
</td>
<td class="ar">
1.19
</td>
</tr>
<tr>
<td class="ar">
</td>
<td class="ar">
10
</td>
<td class="ar">
30
</td>
<td class="ar">
24
</td>
<td class="ar">
22
</td>
<td class="ar">
13
</td>
<td class="ar">
37
</td>
<td class="ar">
44
</td>
<td class="ar">
21
</td>
<td class="ar">
70
</td>
<td class="ar">
117
</td>
<td class="ar">
81
</td>
<td class="ar">
21
</td>
</tr>
<tr>
<td class="ar">
10–14
</td>
<td class="ar">
4.08
</td>
<td class="ar">
3.67
</td>
<td class="ar">
2.90
</td>
<td class="ar">
2.00
</td>
<td class="ar">
4.17
</td>
<td class="ar">
3.33
</td>
<td class="ar">
3.62
</td>
<td class="ar">
3.33
</td>
<td class="ar">
4.14
</td>
<td class="ar">
4.14
</td>
<td class="ar">
3.94
</td>
<td class="ar">
3.33
</td>
</tr>
<tr>
<td class="ar">
</td>
<td class="ar">
1.72
</td>
<td class="ar">
2.31
</td>
<td class="ar">
1.57
</td>
<td class="ar">
1.82
</td>
<td class="ar">
2.97
</td>
<td class="ar">
2.99
</td>
<td class="ar">
1.96
</td>
<td class="ar">
1.52
</td>
<td class="ar">
3.52
</td>
<td class="ar">
3.31
</td>
<td class="ar">
3.28
</td>
<td class="ar">
2.50
</td>
</tr>
<tr>
<td class="ar">
</td>
<td class="ar">
12
</td>
<td class="ar">
27
</td>
<td class="ar">
20
</td>
<td class="ar">
12
</td>
<td class="ar">
18
</td>
<td class="ar">
43
</td>
<td class="ar">
29
</td>
<td class="ar">
15
</td>
<td class="ar">
88
</td>
<td class="ar">
132
</td>
<td class="ar">
50
</td>
<td class="ar">
9
</td>
</tr>
<tr>
<td class="ar">
15–19
</td>
<td class="ar">
4.21
</td>
<td class="ar">
4.94
</td>
<td class="ar">
3.15
</td>
<td class="ar">
2.75
</td>
<td class="ar">
4.70
</td>
<td class="ar">
5.36
</td>
<td class="ar">
4.60
</td>
<td class="ar">
3.80
</td>
<td class="ar">
5.06
</td>
<td class="ar">
5.59
</td>
<td class="ar">
4.50
</td>
<td class="ar">
2.00
</td>
</tr>
<tr>
<td class="ar">
</td>
<td class="ar">
2.03
</td>
<td class="ar">
1.46
</td>
<td class="ar">
0.81
</td>
<td class="ar">
0.92
</td>
<td class="ar">
7.40
</td>
<td class="ar">
2.97
</td>
<td class="ar">
3.83
</td>
<td class="ar">
0.70
</td>
<td class="ar">
4.91
</td>
<td class="ar">
3.23
</td>
<td class="ar">
3.29
</td>
<td class="ar">
–
</td>
</tr>
<tr>
<td class="ar">
</td>
<td class="ar">
14
</td>
<td class="ar">
31
</td>
<td class="ar">
13
</td>
<td class="ar">
4
</td>
<td class="ar">
23
</td>
<td class="ar">
42
</td>
<td class="ar">
20
</td>
<td class="ar">
5
</td>
<td class="ar">
114
</td>
<td class="ar">
86
</td>
<td class="ar">
30
</td>
<td class="ar">
1
</td>
</tr>
<tr>
<td class="ar">
20–24
</td>
<td class="ar">
5.62
</td>
<td class="ar">
5.06
</td>
<td class="ar">
3.92
</td>
<td class="ar">
2.60
</td>
<td class="ar">
5.36
</td>
<td class="ar">
5.88
</td>
<td class="ar">
5.00
</td>
<td class="ar">
5.33
</td>
<td class="ar">
6.46
</td>
<td class="ar">
6.34
</td>
<td class="ar">
5.74
</td>
<td class="ar">
2.50
</td>
</tr>
<tr>
<td class="ar">
</td>
<td class="ar">
4.15
</td>
<td class="ar">
4.64
</td>
<td class="ar">
4.08
</td>
<td class="ar">
4.30
</td>
<td class="ar">
7.19
</td>
<td class="ar">
4.44
</td>
<td class="ar">
4.33
</td>
<td class="ar">
0.33
</td>
<td class="ar">
8.20
</td>
<td class="ar">
5.72
</td>
<td class="ar">
5.20
</td>
<td class="ar">
0.50
</td>
</tr>
<tr>
<td class="ar">
</td>
<td class="ar">
21
</td>
<td class="ar">
18
</td>
<td class="ar">
12
</td>
<td class="ar">
5
</td>
<td class="ar">
22
</td>
<td class="ar">
25
</td>
<td class="ar">
13
</td>
<td class="ar">
3
</td>
<td class="ar">
117
</td>
<td class="ar">
68
</td>
<td class="ar">
23
</td>
<td class="ar">
2
</td>
</tr>
<tr>
<td class="ar">
25–29
</td>
<td class="ar">
6.60
</td>
<td class="ar">
6.74
</td>
<td class="ar">
5.38
</td>
<td class="ar">
2.00
</td>
<td class="ar">
6.52
</td>
<td class="ar">
7.51
</td>
<td class="ar">
7.54
</td>
<td class="ar">
–
</td>
<td class="ar">
7.48
</td>
<td class="ar">
7.81
</td>
<td class="ar">
5.80
</td>
<td class="ar">
–
</td>
</tr>
<tr>
<td class="ar">
</td>
<td class="ar">
12.40
</td>
<td class="ar">
11.66
</td>
<td class="ar">
4.27
</td>
<td class="ar">
–
</td>
<td class="ar">
11.45
</td>
<td class="ar">
10.53
</td>
<td class="ar">
12.60
</td>
<td class="ar">
–
</td>
<td class="ar">
11.34
</td>
<td class="ar">
7.57
</td>
<td class="ar">
7.07
</td>
<td class="ar">
–
</td>
</tr>
<tr class="bb">
<td class="ar">
</td>
<td class="ar">
47
</td>
<td class="ar">
27
</td>
<td class="ar">
8
</td>
<td class="ar">
1
</td>
<td class="ar">
46
</td>
<td class="ar">
45
</td>
<td class="ar">
13
</td>
<td class="ar">
–
</td>
<td class="ar">
195
</td>
<td class="ar">
59
</td>
<td class="ar">
10
</td>
<td class="ar">
–
</td>
</tr>
</table>
<p></font></p>
<p class="espacio3">
</p>
<p>En nuestro análisis, trataremos el número de hijos nacidos de cada mujer como la variable respuesta, y la duración de su matrimonio, el tipo de lugar de residencia y el nivel educativo como predictores.</p>
<p>Consideremos:</p>
<ul>
<li><p>Las unidades <span class="math inline">\(i\)</span> son mujeres en un lugar de residencia, para un nivel educativo, y una duración de matrimonio dados</p></li>
<li><p>La respuesta <span class="math inline">\(y_i\)</span> es el número de nacimientos de mujeres en dicho grupo</p></li>
<li><p>Los predictores son la duración de su matrimonio, el tipo de lugar de residencia y el nivel educativo.</p></li>
</ul>
<p>Ajustamos el modelo únicamente con el intercepto:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(tidyverse)
ceb &lt;-<span class="st"> </span><span class="kw">read_csv</span>(<span class="st">&quot;datos/ceb.csv&quot;</span>)
ceb<span class="op">$</span>educ &lt;-<span class="st"> </span><span class="kw">ordered</span>(ceb<span class="op">$</span>educ, <span class="dt">levels=</span><span class="kw">c</span>(<span class="st">&quot;none&quot;</span>,<span class="st">&quot;lower&quot;</span>,<span class="st">&quot;sec+&quot;</span>,<span class="st">&quot;upper&quot;</span>))
ceb<span class="op">$</span>dur &lt;-<span class="st"> </span><span class="kw">ordered</span>(ceb<span class="op">$</span>dur, 
                   <span class="dt">levels=</span><span class="kw">c</span>(<span class="st">&quot;0-4&quot;</span>,<span class="st">&quot;9-May&quot;</span>,<span class="st">&quot;14-Oct&quot;</span>,<span class="st">&quot;15-19&quot;</span>,<span class="st">&quot;20-24&quot;</span>,<span class="st">&quot;25-29&quot;</span>), 
                   <span class="dt">labels=</span><span class="kw">c</span>(<span class="st">&quot;0-4&quot;</span>, <span class="st">&quot;5-9&quot;</span>, <span class="st">&quot;10-14&quot;</span>,<span class="st">&quot;15-19&quot;</span>,<span class="st">&quot;20-24&quot;</span>,<span class="st">&quot;25-29&quot;</span>))
ceb<span class="op">$</span>res &lt;-<span class="st"> </span><span class="kw">ordered</span>(ceb<span class="op">$</span>res, <span class="dt">levels=</span><span class="kw">c</span>(<span class="st">&quot;rural&quot;</span>, <span class="st">&quot;urban&quot;</span>, <span class="st">&quot;Suva&quot;</span>))
mod_<span class="dv">1</span> &lt;-<span class="st"> </span><span class="kw">glm</span>(<span class="dt">formula =</span> n <span class="op">~</span><span class="st"> </span><span class="dv">1</span>, <span class="dt">family=</span>poisson, <span class="dt">data =</span> ceb)
<span class="kw">summary</span>(mod_<span class="dv">1</span>)
<span class="co">#&gt; </span>
<span class="co">#&gt; Call:</span>
<span class="co">#&gt; glm(formula = n ~ 1, family = poisson, data = ceb)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Deviance Residuals: </span>
<span class="co">#&gt;    Min      1Q  Median      3Q     Max  </span>
<span class="co">#&gt;  -8.20   -4.74   -2.38    1.37   17.94  </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Coefficients:</span>
<span class="co">#&gt;             Estimate Std. Error z value Pr(&gt;|z|)    </span>
<span class="co">#&gt; (Intercept)   3.6440     0.0193     189   &lt;2e-16 ***</span>
<span class="co">#&gt; ---</span>
<span class="co">#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; (Dispersion parameter for poisson family taken to be 1)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;     Null deviance: 2059.5  on 69  degrees of freedom</span>
<span class="co">#&gt; Residual deviance: 2059.5  on 69  degrees of freedom</span>
<span class="co">#&gt; AIC: 2414</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Number of Fisher Scoring iterations: 5</span></code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mod_<span class="dv">11</span> &lt;-<span class="st"> </span><span class="kw">glm</span>(<span class="dt">formula =</span> n <span class="op">~</span><span class="st"> </span>res <span class="op">+</span><span class="st"> </span>educ <span class="op">+</span><span class="st"> </span>dur, <span class="dt">family=</span>poisson, <span class="dt">data =</span> ceb)
<span class="kw">summary</span>(mod_<span class="dv">11</span>)
<span class="co">#&gt; </span>
<span class="co">#&gt; Call:</span>
<span class="co">#&gt; glm(formula = n ~ res + educ + dur, family = poisson, data = ceb)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Deviance Residuals: </span>
<span class="co">#&gt;    Min      1Q  Median      3Q     Max  </span>
<span class="co">#&gt; -8.332  -2.688  -0.175   1.429   8.685  </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Coefficients:</span>
<span class="co">#&gt;             Estimate Std. Error z value Pr(&gt;|z|)    </span>
<span class="co">#&gt; (Intercept)  3.38686    0.02442  138.70  &lt; 2e-16 ***</span>
<span class="co">#&gt; res.L       -0.86262    0.03684  -23.41  &lt; 2e-16 ***</span>
<span class="co">#&gt; res.Q        0.29008    0.03940    7.36  1.8e-13 ***</span>
<span class="co">#&gt; educ.L      -0.53272    0.03905  -13.64  &lt; 2e-16 ***</span>
<span class="co">#&gt; educ.Q       0.27420    0.04382    6.26  3.9e-10 ***</span>
<span class="co">#&gt; educ.C       0.62796    0.04813   13.05  &lt; 2e-16 ***</span>
<span class="co">#&gt; dur.L       -0.24192    0.04642   -5.21  1.9e-07 ***</span>
<span class="co">#&gt; dur.Q        0.27477    0.04659    5.90  3.7e-09 ***</span>
<span class="co">#&gt; dur.C        0.21025    0.04866    4.32  1.6e-05 ***</span>
<span class="co">#&gt; dur^4        0.13639    0.04963    2.75    0.006 ** </span>
<span class="co">#&gt; dur^5        0.00868    0.04928    0.18    0.860    </span>
<span class="co">#&gt; ---</span>
<span class="co">#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; (Dispersion parameter for poisson family taken to be 1)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;     Null deviance: 2059.53  on 69  degrees of freedom</span>
<span class="co">#&gt; Residual deviance:  787.98  on 59  degrees of freedom</span>
<span class="co">#&gt; AIC: 1162</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Number of Fisher Scoring iterations: 5</span></code></pre></div>
<p>Ahora agregamos primero la variable de lugar de residencia:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">ceb<span class="op">$</span>res &lt;-<span class="st"> </span><span class="kw">C</span>(ceb<span class="op">$</span>res, treatment) <span class="co"># modelo con grupo control</span>
mod_<span class="dv">2</span> &lt;-<span class="st"> </span><span class="kw">glm</span>(<span class="dt">formula =</span> n <span class="op">~</span><span class="st"> </span>res, <span class="dt">family=</span>poisson, <span class="dt">data =</span> ceb, <span class="dt">contrasts =</span> <span class="ot">NULL</span>)
<span class="kw">summary</span>(mod_<span class="dv">2</span>)
<span class="co">#&gt; </span>
<span class="co">#&gt; Call:</span>
<span class="co">#&gt; glm(formula = n ~ res, family = poisson, data = ceb, contrasts = NULL)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Deviance Residuals: </span>
<span class="co">#&gt;    Min      1Q  Median      3Q     Max  </span>
<span class="co">#&gt; -11.31   -2.87   -0.36    2.25   12.35  </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Coefficients:</span>
<span class="co">#&gt;             Estimate Std. Error z value Pr(&gt;|z|)    </span>
<span class="co">#&gt; (Intercept)   4.2366     0.0251   169.0   &lt;2e-16 ***</span>
<span class="co">#&gt; resurban     -0.9652     0.0477   -20.2   &lt;2e-16 ***</span>
<span class="co">#&gt; resSuva      -1.2409     0.0521   -23.8   &lt;2e-16 ***</span>
<span class="co">#&gt; ---</span>
<span class="co">#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; (Dispersion parameter for poisson family taken to be 1)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;     Null deviance: 2059.5  on 69  degrees of freedom</span>
<span class="co">#&gt; Residual deviance: 1247.5  on 67  degrees of freedom</span>
<span class="co">#&gt; AIC: 1605</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Number of Fisher Scoring iterations: 5</span></code></pre></div>
<p>Vemos que la devianza disminuye significativamente. Ahora agregamos los otros predictores y evaluamos el modelo nuevamente:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">ceb<span class="op">$</span>dur &lt;-<span class="st"> </span>forcats<span class="op">::</span><span class="kw">fct_rev</span>(ceb<span class="op">$</span>dur)
ceb<span class="op">$</span>dur &lt;-<span class="st"> </span><span class="kw">C</span>(ceb<span class="op">$</span>dur,treatment)
ceb<span class="op">$</span>educ &lt;-<span class="st"> </span><span class="kw">C</span>(ceb<span class="op">$</span>educ,treatment)
mod_<span class="dv">3</span> &lt;-<span class="st"> </span><span class="kw">glm</span>(<span class="dt">formula =</span> n <span class="op">~</span><span class="st"> </span>res <span class="op">+</span><span class="st"> </span>dur <span class="op">+</span><span class="st"> </span>educ, <span class="dt">family=</span>poisson, <span class="dt">data =</span> ceb)
<span class="kw">summary</span>(mod_<span class="dv">3</span>)
<span class="co">#&gt; </span>
<span class="co">#&gt; Call:</span>
<span class="co">#&gt; glm(formula = n ~ res + dur + educ, family = poisson, data = ceb)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Deviance Residuals: </span>
<span class="co">#&gt;    Min      1Q  Median      3Q     Max  </span>
<span class="co">#&gt; -8.332  -2.688  -0.175   1.429   8.685  </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Coefficients:</span>
<span class="co">#&gt;             Estimate Std. Error z value Pr(&gt;|z|)    </span>
<span class="co">#&gt; (Intercept)   4.5793     0.0565   81.03  &lt; 2e-16 ***</span>
<span class="co">#&gt; resurban     -0.9652     0.0477  -20.22  &lt; 2e-16 ***</span>
<span class="co">#&gt; resSuva      -1.2199     0.0521  -23.41  &lt; 2e-16 ***</span>
<span class="co">#&gt; dur20-24     -0.4165     0.0728   -5.72  1.0e-08 ***</span>
<span class="co">#&gt; dur15-19     -0.2645     0.0698   -3.79  0.00015 ***</span>
<span class="co">#&gt; dur10-14     -0.0922     0.0667   -1.38  0.16689    </span>
<span class="co">#&gt; dur5-9       -0.0181     0.0655   -0.28  0.78204    </span>
<span class="co">#&gt; dur0-4        0.1313     0.0633    2.07  0.03814 *  </span>
<span class="co">#&gt; educlower     0.0492     0.0468    1.05  0.29275    </span>
<span class="co">#&gt; educsec+     -1.0315     0.0699  -14.76  &lt; 2e-16 ***</span>
<span class="co">#&gt; educupper    -0.4339     0.0534   -8.13  4.4e-16 ***</span>
<span class="co">#&gt; ---</span>
<span class="co">#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; (Dispersion parameter for poisson family taken to be 1)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;     Null deviance: 2059.53  on 69  degrees of freedom</span>
<span class="co">#&gt; Residual deviance:  787.98  on 59  degrees of freedom</span>
<span class="co">#&gt; AIC: 1162</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Number of Fisher Scoring iterations: 5</span></code></pre></div>
<p>La devianza disminuyó significativamente.</p>
<p>Vemos cómo se comportan las predicciones:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">preds &lt;-<span class="st"> </span><span class="kw">predict</span>(mod_<span class="dv">3</span>, ceb)
<span class="co">#&gt; Warning: contrasts dropped from factor res</span>
<span class="co">#&gt; Warning: contrasts dropped from factor dur</span>
<span class="co">#&gt; Warning: contrasts dropped from factor educ</span>
ceb<span class="op">$</span>pred &lt;-<span class="st"> </span>preds
ceb_larga &lt;-<span class="st"> </span>ceb <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">gather</span>(clase, valor, n, pred)
<span class="kw">ggplot</span>(ceb_larga, <span class="kw">aes</span>(<span class="dt">x =</span> dur, <span class="dt">y =</span> valor<span class="op">/</span><span class="kw">sum</span>(ceb<span class="op">$</span>n), <span class="dt">colour =</span> clase)) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">facet_grid</span>(educ <span class="op">~</span><span class="st"> </span>res) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">axis.text.x =</span> <span class="kw">element_text</span>(<span class="dt">angle =</span> <span class="dv">25</span>))</code></pre></div>
<p><img src="10-glm_files/figure-html/unnamed-chunk-8-1.png" width="100%" style="display: block; margin: auto;" /></p>
</div>
<div id="variable-de-expuestos-offset" class="section level2">
<h2><span class="header-section-number">10.7</span> Variable de expuestos (offset)</h2>
<p>En la mayoría de las aplicaciones de regresión de Poisson, los conteos pueden interpretarse relativos a un número, por ejemplo, el número de vehículos que cruzan la esquina. En el modelo general de regresión de Poisson, pensamos en <span class="math inline">\(y_i\)</span> como el número de casos en un proceso con tasa <span class="math inline">\(\theta_i\)</span> y expuestos <span class="math inline">\(u_i\)</span>:</p>
<p><span class="math display">\[
y_i \sim \mbox{Poisson}(u_i\theta_i),
\]</span> donde, como antes, <span class="math inline">\(\theta_i = \exp(X_i\beta)\)</span>. El logaritmo de expuestos, <span class="math inline">\(\log(u_i)\)</span>, se denomina <em>offset</em> (o desplazamiento) en la terminología del modelo lineal generalizado.</p>
<p>Observaciones:</p>
<ul>
<li><p>Los coeficientes de regresión <span class="math inline">\(\beta\)</span> resumen las asociaciones entre los predictores y <span class="math inline">\(θ_i\)</span> (en nuestro ejemplo, la tasa de accidentes de tráfico por vehículo).</p></li>
<li><p>Poner el logaritmo de expuestos en el modelo es equivalente a incluirlo como un predictor de regresión, pero con coeficiente fijado en <span class="math inline">\(1\)</span>. Otra opción es incluirlo como un predictor y permitir que su coeficiente sea estimado a partir de los datos, pero a veces es más simple mantenerlo como un desplazamiento para que la tasa estimada <span class="math inline">\(\theta\)</span> tenga una interpretación más directa.</p></li>
</ul>
</div>
<div id="ejemplos-seguros" class="section level2">
<h2><span class="header-section-number">10.8</span> Ejemplos: seguros</h2>
<p>Los datos <code>Insurance</code> en el paquete <code>MASS</code> consisten del número de asegurados de una compañía de seguros de autos que estuvieron expuestos a riesgo por accidente y el número de reclamos realizados por los asegurados en el tercer trimestre de 1973.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(MASS)
<span class="kw">data</span>(Insurance)
Insurance <span class="op">%&gt;%</span><span class="st"> </span>head <span class="op">%&gt;%</span><span class="st"> </span>knitr<span class="op">::</span><span class="kw">kable</span>()</code></pre></div>
<table>
<thead>
<tr class="header">
<th align="left">District</th>
<th align="left">Group</th>
<th align="left">Age</th>
<th align="right">Holders</th>
<th align="right">Claims</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">1</td>
<td align="left">&lt;1l</td>
<td align="left">&lt;25</td>
<td align="right">197</td>
<td align="right">38</td>
</tr>
<tr class="even">
<td align="left">1</td>
<td align="left">&lt;1l</td>
<td align="left">25-29</td>
<td align="right">264</td>
<td align="right">35</td>
</tr>
<tr class="odd">
<td align="left">1</td>
<td align="left">&lt;1l</td>
<td align="left">30-35</td>
<td align="right">246</td>
<td align="right">20</td>
</tr>
<tr class="even">
<td align="left">1</td>
<td align="left">&lt;1l</td>
<td align="left">&gt;35</td>
<td align="right">1680</td>
<td align="right">156</td>
</tr>
<tr class="odd">
<td align="left">1</td>
<td align="left">1-1.5l</td>
<td align="left">&lt;25</td>
<td align="right">284</td>
<td align="right">63</td>
</tr>
<tr class="even">
<td align="left">1</td>
<td align="left">1-1.5l</td>
<td align="left">25-29</td>
<td align="right">536</td>
<td align="right">84</td>
</tr>
</tbody>
</table>
<p>Las variables son:</p>
<ol style="list-style-type: decimal">
<li><p>Distrito. residencia del que tiene la póliza 1 a 4 (ciudades importantes)</p></li>
<li><p>Grupo. tipo de coche: &lt;1 litro, 1-1.5 litros, 1.5-2 litros, &gt;2 litros</p></li>
<li><p>Edad. grupo de edad: &lt;25, 25-29, 30-35, &gt;35.</p></li>
<li><p>Holders. número de asegurados.</p></li>
<li><p>Reclamos. número de reclamos.</p></li>
</ol>
<p>Esta vez tenemos:</p>
<ul>
<li><p>cada observación <span class="math inline">\(i\)</span> corresponde a un grupo de asegurados de acuerdo a su distrito, tipo de coche, y edad.</p></li>
<li><p>el resultado <span class="math inline">\(y_i\)</span> es el número de reclamos en dicho grupo</p></li>
<li><p>los expuestos <span class="math inline">\(u_i\)</span> son el número de asegurados</p></li>
<li><p>las entradas son los índices de precinto y etnicidad</p></li>
<li><p>los predictores son: distrito, grupo y edad</p></li>
</ul>
<p>Ilustramos el ajuste del modelo en tres pasos. Primero, ajustamos un modelo con los expuestos y un término constante solo:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mod_<span class="dv">1</span> &lt;-<span class="st"> </span><span class="kw">glm</span>(<span class="dt">formula =</span> Claims <span class="op">~</span><span class="st"> </span><span class="dv">1</span>, <span class="dt">family=</span>poisson, <span class="dt">offset=</span><span class="kw">log</span>(Holders), <span class="dt">data =</span> Insurance)
<span class="kw">summary</span>(mod_<span class="dv">1</span>)
<span class="co">#&gt; </span>
<span class="co">#&gt; Call:</span>
<span class="co">#&gt; glm(formula = Claims ~ 1, family = poisson, data = Insurance, </span>
<span class="co">#&gt;     offset = log(Holders))</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Deviance Residuals: </span>
<span class="co">#&gt;    Min      1Q  Median      3Q     Max  </span>
<span class="co">#&gt; -4.973  -0.325   0.790   1.976   4.073  </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Coefficients:</span>
<span class="co">#&gt;             Estimate Std. Error z value Pr(&gt;|z|)    </span>
<span class="co">#&gt; (Intercept)  -2.0033     0.0178    -112   &lt;2e-16 ***</span>
<span class="co">#&gt; ---</span>
<span class="co">#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; (Dispersion parameter for poisson family taken to be 1)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;     Null deviance: 236.26  on 63  degrees of freedom</span>
<span class="co">#&gt; Residual deviance: 236.26  on 63  degrees of freedom</span>
<span class="co">#&gt; AIC: 555.6</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Number of Fisher Scoring iterations: 4</span></code></pre></div>
<p>Ahora agregamos el predictor de distrito:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mod_<span class="dv">2</span> &lt;-<span class="st"> </span><span class="kw">glm</span>(<span class="dt">formula =</span> Claims <span class="op">~</span><span class="st"> </span>District, <span class="dt">family=</span>poisson, <span class="dt">offset=</span><span class="kw">log</span>(Holders), <span class="dt">data =</span> Insurance)
<span class="kw">summary</span>(mod_<span class="dv">2</span>)
<span class="co">#&gt; </span>
<span class="co">#&gt; Call:</span>
<span class="co">#&gt; glm(formula = Claims ~ District, family = poisson, data = Insurance, </span>
<span class="co">#&gt;     offset = log(Holders))</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Deviance Residuals: </span>
<span class="co">#&gt;    Min      1Q  Median      3Q     Max  </span>
<span class="co">#&gt; -4.556  -0.486   0.847   1.703   4.112  </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Coefficients:</span>
<span class="co">#&gt;             Estimate Std. Error z value Pr(&gt;|z|)    </span>
<span class="co">#&gt; (Intercept)  -2.0328     0.0269  -75.54  &lt; 2e-16 ***</span>
<span class="co">#&gt; District2     0.0224     0.0430    0.52  0.60273    </span>
<span class="co">#&gt; District3     0.0133     0.0503    0.26  0.79232    </span>
<span class="co">#&gt; District4     0.2218     0.0616    3.60  0.00031 ***</span>
<span class="co">#&gt; ---</span>
<span class="co">#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; (Dispersion parameter for poisson family taken to be 1)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;     Null deviance: 236.26  on 63  degrees of freedom</span>
<span class="co">#&gt; Residual deviance: 223.53  on 60  degrees of freedom</span>
<span class="co">#&gt; AIC: 548.9</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Number of Fisher Scoring iterations: 4</span></code></pre></div>
<p>Nota:</p>
<ol style="list-style-type: decimal">
<li><p>El AIC disminuye de 555.58 a 548.85.</p></li>
<li><p>Se puede ver que solamente District4 tiene un coeficiente significativo. Se puede interpretar como que aquellos que son del Distrito 4 tiene 22% más reclamos comparado con el Distrito control, el Distrito 1.</p></li>
</ol>
<p>Ahora agregamos el predictor de edad:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">Insurance<span class="op">$</span>Age &lt;-<span class="st"> </span><span class="kw">C</span>(Insurance<span class="op">$</span>Age,treatment)
mod_<span class="dv">3</span> &lt;-<span class="st"> </span><span class="kw">glm</span>(<span class="dt">formula =</span> Claims <span class="op">~</span><span class="st"> </span>District <span class="op">+</span><span class="st"> </span>Age, 
             <span class="dt">family=</span>poisson, 
             <span class="dt">offset=</span><span class="kw">log</span>(Holders), 
             <span class="dt">data =</span> Insurance)
<span class="kw">summary</span>(mod_<span class="dv">3</span>)
<span class="co">#&gt; </span>
<span class="co">#&gt; Call:</span>
<span class="co">#&gt; glm(formula = Claims ~ District + Age, family = poisson, data = Insurance, </span>
<span class="co">#&gt;     offset = log(Holders))</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Deviance Residuals: </span>
<span class="co">#&gt;    Min      1Q  Median      3Q     Max  </span>
<span class="co">#&gt; -3.024  -0.988  -0.126   1.227   3.403  </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Coefficients:</span>
<span class="co">#&gt;             Estimate Std. Error z value Pr(&gt;|z|)    </span>
<span class="co">#&gt; (Intercept)  -1.6351     0.0681  -24.00  &lt; 2e-16 ***</span>
<span class="co">#&gt; District2     0.0345     0.0430    0.80  0.42278    </span>
<span class="co">#&gt; District3     0.0468     0.0505    0.93  0.35381    </span>
<span class="co">#&gt; District4     0.2470     0.0617    4.01  6.2e-05 ***</span>
<span class="co">#&gt; Age25-29     -0.1563     0.0828   -1.89  0.05890 .  </span>
<span class="co">#&gt; Age30-35     -0.2986     0.0812   -3.68  0.00023 ***</span>
<span class="co">#&gt; Age&gt;35       -0.5089     0.0698   -7.29  3.2e-13 ***</span>
<span class="co">#&gt; ---</span>
<span class="co">#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; (Dispersion parameter for poisson family taken to be 1)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;     Null deviance: 236.26  on 63  degrees of freedom</span>
<span class="co">#&gt; Residual deviance: 140.09  on 57  degrees of freedom</span>
<span class="co">#&gt; AIC: 471.4</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Number of Fisher Scoring iterations: 4</span></code></pre></div>
<p>Notamos que:</p>
<ol style="list-style-type: decimal">
<li><p>El AIC disminuye nuevamente de 548.85 a 471.41, una reducción mucho más significativa. Esto nos dice que la variable de edad mejora considerablemente el ajuste del modelo.</p></li>
<li><p>El coeficiente de Distrito 4 aumentó de 22% a 24% cuando controlamos por el grupo de edad. Comparando con el grupo base (grupo control) Distrito 1, el número de reclamos es <span class="math inline">\(\exp(0.22)=1.24\)</span> veces más en el Distrito 4.</p></li>
<li><p>El grupo de edad L (25-29) tiene un coeficiente significativo de -0.37 que podemos interpretar como que pertenecer a ese grupo de edad tiene 37% menos reclamos comparado con el grupo de edad control (&lt;25).</p></li>
</ol>
<p>Por último incluyendo todos los predictores el modelo ajustado es:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">Insurance<span class="op">$</span>Group &lt;-<span class="st"> </span><span class="kw">C</span>(Insurance<span class="op">$</span>Group, treatment)
mod_<span class="dv">4</span> &lt;-<span class="st"> </span><span class="kw">glm</span>(<span class="dt">formula =</span> Claims <span class="op">~</span><span class="st"> </span>District <span class="op">+</span><span class="st"> </span>Age <span class="op">+</span><span class="st"> </span>Group, 
             <span class="dt">family=</span>poisson, 
             <span class="dt">offset=</span><span class="kw">log</span>(Holders), 
             <span class="dt">data =</span> Insurance)
<span class="kw">summary</span>(mod_<span class="dv">4</span>)
<span class="co">#&gt; </span>
<span class="co">#&gt; Call:</span>
<span class="co">#&gt; glm(formula = Claims ~ District + Age + Group, family = poisson, </span>
<span class="co">#&gt;     data = Insurance, offset = log(Holders))</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Deviance Residuals: </span>
<span class="co">#&gt;    Min      1Q  Median      3Q     Max  </span>
<span class="co">#&gt; -2.466  -0.508  -0.032   0.556   1.940  </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Coefficients:</span>
<span class="co">#&gt;             Estimate Std. Error z value Pr(&gt;|z|)    </span>
<span class="co">#&gt; (Intercept)  -1.8217     0.0768  -23.72  &lt; 2e-16 ***</span>
<span class="co">#&gt; District2     0.0259     0.0430    0.60  0.54760    </span>
<span class="co">#&gt; District3     0.0385     0.0505    0.76  0.44566    </span>
<span class="co">#&gt; District4     0.2342     0.0617    3.80  0.00015 ***</span>
<span class="co">#&gt; Age25-29     -0.1910     0.0829   -2.31  0.02115 *  </span>
<span class="co">#&gt; Age30-35     -0.3450     0.0814   -4.24  2.2e-05 ***</span>
<span class="co">#&gt; Age&gt;35       -0.5367     0.0700   -7.67  1.7e-14 ***</span>
<span class="co">#&gt; Group1-1.5l   0.1613     0.0505    3.19  0.00141 ** </span>
<span class="co">#&gt; Group1.5-2l   0.3928     0.0550    7.14  9.2e-13 ***</span>
<span class="co">#&gt; Group&gt;2l      0.5634     0.0723    7.79  6.6e-15 ***</span>
<span class="co">#&gt; ---</span>
<span class="co">#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; (Dispersion parameter for poisson family taken to be 1)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;     Null deviance: 236.26  on 63  degrees of freedom</span>
<span class="co">#&gt; Residual deviance:  51.42  on 54  degrees of freedom</span>
<span class="co">#&gt; AIC: 388.7</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Number of Fisher Scoring iterations: 4</span></code></pre></div>
<p>Observamos que controlando por el grupo de auto los coeficientes de las otras variables no cambian mucho.</p>
<div id="numero-de-expuestos-interpretacion" class="section level3 unnumbered">
<h3>Número de expuestos (interpretación)</h3>
<p>Interpretamos que los asegurados con coches de 1-1.5 litros tienen 16.1% más reclamos que los asegurados con autos de &lt;1 litro. Además, veamos que en este ejemplo el número de reclamos se compara con el número de asegurados, de modo que como el coeficiente para el indicador de edad entre 25 y 29 es menor que 1, entonces las personas de este grupo de edad tienen un número desproporcionadamente menor en sus tasas de reclamos, en comparación con las personas del grupo de edad menor a 25 años.</p>
</div>
</div>
<div id="ejemplo-arboles" class="section level2">
<h2><span class="header-section-number">10.9</span> Ejemplo: árboles</h2>
<p>Veamos un ejemplo con datos de árboles.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dat &lt;-<span class="st"> </span><span class="kw">read_csv</span>(<span class="st">&quot;datos/treedata.csv&quot;</span>)
dat <span class="op">%&gt;%</span><span class="st"> </span>head <span class="op">%&gt;%</span><span class="st"> </span>knitr<span class="op">::</span><span class="kw">kable</span>()</code></pre></div>
<table>
<thead>
<tr class="header">
<th align="left">plotID</th>
<th align="left">date</th>
<th align="right">plotsize</th>
<th align="left">spcode</th>
<th align="left">species</th>
<th align="right">cover</th>
<th align="right">utme</th>
<th align="right">utmn</th>
<th align="right">elev</th>
<th align="right">tci</th>
<th align="right">streamdist</th>
<th align="left">disturb</th>
<th align="right">beers</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">ATBN-01-0403</td>
<td align="left">08-28-2001</td>
<td align="right">1000</td>
<td align="left">ABIEFRA</td>
<td align="left">Abies fraseri</td>
<td align="right">1</td>
<td align="right">275736</td>
<td align="right">3942439</td>
<td align="right">1660</td>
<td align="right">5.70</td>
<td align="right">491</td>
<td align="left">CORPLOG</td>
<td align="right">0.224</td>
</tr>
<tr class="even">
<td align="left">ATBN-01-0532</td>
<td align="left">07-24-2002</td>
<td align="right">1000</td>
<td align="left">ABIEFRA</td>
<td align="left">Abies fraseri</td>
<td align="right">8</td>
<td align="right">302847</td>
<td align="right">3942772</td>
<td align="right">1712</td>
<td align="right">3.82</td>
<td align="right">454</td>
<td align="left">VIRGIN</td>
<td align="right">0.834</td>
</tr>
<tr class="odd">
<td align="left">ATBN-01-0533</td>
<td align="left">07-24-2002</td>
<td align="right">1000</td>
<td align="left">ABIEFRA</td>
<td align="left">Abies fraseri</td>
<td align="right">3</td>
<td align="right">303037</td>
<td align="right">3943039</td>
<td align="right">1722</td>
<td align="right">3.89</td>
<td align="right">453</td>
<td align="left">LT-SEL</td>
<td align="right">1.333</td>
</tr>
<tr class="even">
<td align="left">ATBN-01-0536</td>
<td align="left">07-25-2002</td>
<td align="right">1000</td>
<td align="left">ABIEFRA</td>
<td align="left">Abies fraseri</td>
<td align="right">3</td>
<td align="right">273927</td>
<td align="right">3935488</td>
<td align="right">1754</td>
<td align="right">3.15</td>
<td align="right">492</td>
<td align="left">SETTLE</td>
<td align="right">1.471</td>
</tr>
<tr class="odd">
<td align="left">ATBP-01-0001</td>
<td align="left">05-11-1999</td>
<td align="right">10000</td>
<td align="left">ABIEFRA</td>
<td align="left">Abies fraseri</td>
<td align="right">8</td>
<td align="right">273857</td>
<td align="right">3937870</td>
<td align="right">1945</td>
<td align="right">5.68</td>
<td align="right">492</td>
<td align="left">VIRGIN</td>
<td align="right">1.644</td>
</tr>
<tr class="even">
<td align="left">ATBP-01-0005</td>
<td align="left">08-25-1999</td>
<td align="right">10000</td>
<td align="left">ABIEFRA</td>
<td align="left">Abies fraseri</td>
<td align="right">4</td>
<td align="right">273876</td>
<td align="right">3935462</td>
<td align="right">1751</td>
<td align="right">5.42</td>
<td align="right">546</td>
<td align="left">SETTLE</td>
<td align="right">0.000</td>
</tr>
</tbody>
</table>
<p>La variable <code>cover</code> de cobertura es un número entero entre mayor o igual a 1 y representa la presencia de árboles de determinada especie en una parcela.</p>
<p>Las variables en los datos son:</p>
<ul>
<li><p><strong>plotID</strong>: unique code for each spatial unit (note some sampled more than once)</p></li>
<li><p><strong>date</strong>: when species occurrence recorded plotsize: size of quadrat in m2</p></li>
<li><p><strong>spcode</strong>: unique 7-letter code for each species species: species name</p></li>
<li><p><strong>cover</strong>: local abundance measured as estimated horizontal cover (ie, relative area of shadow if sun is directly above) classes 1-10 are: 1=trace, 2=0-1%, 3=1-2%, 4=2-5%, 5=5-10%, 6=10-25%, 7=25-50%, 8=50-75%, 9=75-95%, 10=95-100%</p></li>
<li><p><strong>utme</strong>: plot UTM Easting, zone 17 (NAD27 Datum) utmn: plot UTM Northing, zone 17 (NAD27 Datum) elev: elevation in meters from a digital elevation model (10 m res)</p></li>
<li><p><strong>tci</strong>: topographic convergence index, or site “water potential”; measured as the upslope contributing area divided by the tangent of the slope angle (Beven and Kirkby 1979) streamdist: distance of plot from the nearest permanent stream (meters)</p></li>
<li><p><strong>disturb</strong>: plot disturbance history (from a Park report); CORPLOG=corporate logging; SETTLE=concentrated settlement, VIRGIN=“high in virgin attributes”, LT-SEL=light or selective logging</p></li>
<li><p><strong>beers</strong>: transformed slope aspect (‘heat load index’); 0 is SW (hottest), 2 is NE (coolest)</p></li>
</ul>
<p>Cumple dos criterios comunes:</p>
<ol style="list-style-type: decimal">
<li><p>la variable respuesta es discreta y entera</p></li>
<li><p>tiene una variación que generalmente aumenta con la media (se puede considerar esto desde los primeros principios: si una especie tiene una abundancia media alrededor de 1, la varianza tiene que ser baja porque no se puede obtener más baja que esto dados nuestros datos, una media de 5, sin embargo, podría tener una gran varianza).</p></li>
</ol>
<p>Tomemos como ejemplo primero el <em>abeto oriental</em>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dat_<span class="dv">2</span> &lt;-<span class="st"> </span>dat <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">filter</span>(species <span class="op">==</span><span class="st"> &quot;Tsuga canadensis&quot;</span>)</code></pre></div>
<p>Veamos media y varianza:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">mean</span>(dat_<span class="dv">2</span><span class="op">$</span>cover)
<span class="co">#&gt; [1] 4.66</span></code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">var</span>(dat_<span class="dv">2</span><span class="op">$</span>cover)
<span class="co">#&gt; [1] 4.47</span></code></pre></div>
<p>Veamos la distribución:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(dat_<span class="dv">2</span>, <span class="kw">aes</span>(<span class="dt">x=</span>cover)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_bar</span>(<span class="dt">stat=</span><span class="st">&#39;count&#39;</span>)</code></pre></div>
<p><img src="10-glm_files/figure-html/unnamed-chunk-18-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>Si los datos tuvieran una distribución Poisson:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dat_sim &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">cover.sim=</span> <span class="kw">rpois</span>(<span class="dv">700</span>,<span class="fl">4.66</span>))
<span class="kw">ggplot</span>(dat_sim, <span class="kw">aes</span>(<span class="dt">x=</span>cover.sim)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_bar</span>(<span class="dt">stat=</span><span class="st">&#39;count&#39;</span>)</code></pre></div>
<p><img src="10-glm_files/figure-html/unnamed-chunk-19-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>Ajustamos primero el modelo únicamente con el intercepto:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mod_<span class="dv">1</span> &lt;-<span class="st"> </span><span class="kw">glm</span>(cover<span class="op">~</span><span class="dv">1</span>,<span class="dt">data=</span>dat_<span class="dv">2</span>,<span class="dt">family=</span>poisson)
<span class="kw">summary</span>(mod_<span class="dv">1</span>)
<span class="co">#&gt; </span>
<span class="co">#&gt; Call:</span>
<span class="co">#&gt; glm(formula = cover ~ 1, family = poisson, data = dat_2)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Deviance Residuals: </span>
<span class="co">#&gt;    Min      1Q  Median      3Q     Max  </span>
<span class="co">#&gt; -2.059  -0.823  -0.313   1.008   2.143  </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Coefficients:</span>
<span class="co">#&gt;             Estimate Std. Error z value Pr(&gt;|z|)    </span>
<span class="co">#&gt; (Intercept)    1.539      0.017    90.7   &lt;2e-16 ***</span>
<span class="co">#&gt; ---</span>
<span class="co">#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; (Dispersion parameter for poisson family taken to be 1)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;     Null deviance: 749.25  on 745  degrees of freedom</span>
<span class="co">#&gt; Residual deviance: 749.25  on 745  degrees of freedom</span>
<span class="co">#&gt; AIC: 3212</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Number of Fisher Scoring iterations: 4</span></code></pre></div>
<p>La salida es similar a la salida de <code>lm</code>. Una diferencia importante es cómo se ajustan los coeficientes: esperábamos una media de 4.66, pero en lugar de eso obtuvimos 1.54.</p>

<div class="information">
<strong>Nota:</strong> Aquí y en todos los demás casos donde la función liga no es la identidad, los coeficientes ajustados están en la escala de la función liga, no en la escala de los datos originales. Para recuperar el coeficiente apropiadamente escalado aplicamos la inversa de la función liga.
</div>

<p>Aplicamos la función exponencial:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">exp</span>(<span class="kw">coefficients</span>(mod_<span class="dv">1</span>))
<span class="co">#&gt; (Intercept) </span>
<span class="co">#&gt;        4.66</span></code></pre></div>
<p>Agregamos un predictor continuo <code>elev</code> de elevación:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(dat_<span class="dv">2</span>, <span class="kw">aes</span>(<span class="dt">x=</span>elev,<span class="dt">y=</span>cover)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_jitter</span>(<span class="dt">width =</span> <span class="dv">0</span>, <span class="dt">height =</span> <span class="fl">0.3</span>, <span class="dt">size=</span><span class="fl">0.8</span>, <span class="dt">alpha =</span> <span class="fl">0.8</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_smooth</span>()
<span class="co">#&gt; `geom_smooth()` using method = &#39;loess&#39;</span></code></pre></div>
<p><img src="10-glm_files/figure-html/unnamed-chunk-23-1.png" width="70%" style="display: block; margin: auto;" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mod_<span class="dv">2</span> &lt;-<span class="st"> </span><span class="kw">glm</span>(cover<span class="op">~</span>tci<span class="op">+</span>elev<span class="op">+</span>beers<span class="op">+</span>streamdist,<span class="dt">data=</span>dat_<span class="dv">2</span>,<span class="dt">family=</span>poisson)
<span class="kw">summary</span>(mod_<span class="dv">2</span>)
<span class="co">#&gt; </span>
<span class="co">#&gt; Call:</span>
<span class="co">#&gt; glm(formula = cover ~ tci + elev + beers + streamdist, family = poisson, </span>
<span class="co">#&gt;     data = dat_2)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Deviance Residuals: </span>
<span class="co">#&gt;     Min       1Q   Median       3Q      Max  </span>
<span class="co">#&gt; -2.3035  -0.7929  -0.0869   0.6952   2.6517  </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Coefficients:</span>
<span class="co">#&gt;              Estimate Std. Error z value Pr(&gt;|z|)    </span>
<span class="co">#&gt; (Intercept)  1.45e+00   7.99e-02   18.16  &lt; 2e-16 ***</span>
<span class="co">#&gt; tci          1.49e-02   6.90e-03    2.16    0.031 *  </span>
<span class="co">#&gt; elev         8.97e-05   5.71e-05    1.57    0.116    </span>
<span class="co">#&gt; beers        6.21e-02   2.48e-02    2.51    0.012 *  </span>
<span class="co">#&gt; streamdist  -8.14e-04   1.21e-04   -6.73  1.7e-11 ***</span>
<span class="co">#&gt; ---</span>
<span class="co">#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; (Dispersion parameter for poisson family taken to be 1)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;     Null deviance: 748.23  on 744  degrees of freedom</span>
<span class="co">#&gt; Residual deviance: 677.39  on 740  degrees of freedom</span>
<span class="co">#&gt;   (1 observation deleted due to missingness)</span>
<span class="co">#&gt; AIC: 3145</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Number of Fisher Scoring iterations: 4</span></code></pre></div>
<p>Nota:</p>
<ul>
<li><p>la prueba de <span class="math inline">\(\chi^2\)</span> generalmente se “recomienda” para los modelos con “varianza conocida” (Poisson y Binomial).</p></li>
<li><p>el modelo con elevación no le añade al modelo ningún poder explicativo</p></li>
</ul>
<p>Usamos ahora la variable <code>disturb</code> de <em>disturbance</em> (o perturbación), que es un cambio temporal en las condiciones ambientales que puede causar un cambio pronunciado en un ecosistema.</p>
<p>Ajustamos el modelo:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mod_<span class="dv">3</span> &lt;-<span class="st"> </span><span class="kw">glm</span>(cover<span class="op">~</span>tci<span class="op">+</span>elev<span class="op">+</span>beers<span class="op">+</span>disturb<span class="op">+</span>streamdist,<span class="dt">data=</span>dat_<span class="dv">2</span>,<span class="dt">family=</span>poisson)
<span class="kw">summary</span>(mod_<span class="dv">3</span>)
<span class="co">#&gt; </span>
<span class="co">#&gt; Call:</span>
<span class="co">#&gt; glm(formula = cover ~ tci + elev + beers + disturb + streamdist, </span>
<span class="co">#&gt;     family = poisson, data = dat_2)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Deviance Residuals: </span>
<span class="co">#&gt;    Min      1Q  Median      3Q     Max  </span>
<span class="co">#&gt; -2.187  -0.776  -0.105   0.721   2.500  </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Coefficients:</span>
<span class="co">#&gt;                Estimate Std. Error z value Pr(&gt;|z|)    </span>
<span class="co">#&gt; (Intercept)    1.39e+00   1.07e-01   13.02  &lt; 2e-16 ***</span>
<span class="co">#&gt; tci            1.57e-02   6.91e-03    2.28   0.0228 *  </span>
<span class="co">#&gt; elev           6.77e-05   7.45e-05    0.91   0.3638    </span>
<span class="co">#&gt; beers          6.44e-02   2.51e-02    2.56   0.0103 *  </span>
<span class="co">#&gt; disturbLT-SEL  5.66e-02   5.26e-02    1.07   0.2824    </span>
<span class="co">#&gt; disturbSETTLE  7.99e-02   6.34e-02    1.26   0.2079    </span>
<span class="co">#&gt; disturbVIRGIN  1.52e-01   5.32e-02    2.85   0.0044 ** </span>
<span class="co">#&gt; streamdist    -8.18e-04   1.22e-04   -6.72  1.8e-11 ***</span>
<span class="co">#&gt; ---</span>
<span class="co">#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; (Dispersion parameter for poisson family taken to be 1)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;     Null deviance: 748.23  on 744  degrees of freedom</span>
<span class="co">#&gt; Residual deviance: 668.92  on 737  degrees of freedom</span>
<span class="co">#&gt;   (1 observation deleted due to missingness)</span>
<span class="co">#&gt; AIC: 3142</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Number of Fisher Scoring iterations: 4</span></code></pre></div>
<p>Parece haber relación con que el bosque sea “virgen”, pero el modelo realmente no es muy bueno (el AIC es similar).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">AIC</span>(mod_<span class="dv">1</span>, mod_<span class="dv">2</span>, mod_<span class="dv">3</span>)
<span class="co">#&gt; Warning in AIC.default(mod_1, mod_2, mod_3): models are not all fitted to</span>
<span class="co">#&gt; the same number of observations</span>
<span class="co">#&gt;       df  AIC</span>
<span class="co">#&gt; mod_1  1 3212</span>
<span class="co">#&gt; mod_2  5 3145</span>
<span class="co">#&gt; mod_3  8 3142</span></code></pre></div>
<p>La función <code>step</code> nos dice qué variables disminuyen mayor el AIC.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">step</span>(mod_<span class="dv">3</span>)
<span class="co">#&gt; Start:  AIC=3142</span>
<span class="co">#&gt; cover ~ tci + elev + beers + disturb + streamdist</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;              Df Deviance  AIC</span>
<span class="co">#&gt; - elev        1      670 3141</span>
<span class="co">#&gt; &lt;none&gt;               669 3142</span>
<span class="co">#&gt; - disturb     3      677 3145</span>
<span class="co">#&gt; - tci         1      674 3145</span>
<span class="co">#&gt; - beers       1      676 3147</span>
<span class="co">#&gt; - streamdist  1      716 3187</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Step:  AIC=3141</span>
<span class="co">#&gt; cover ~ tci + beers + disturb + streamdist</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;              Df Deviance  AIC</span>
<span class="co">#&gt; &lt;none&gt;               670 3141</span>
<span class="co">#&gt; - tci         1      674 3144</span>
<span class="co">#&gt; - disturb     3      680 3145</span>
<span class="co">#&gt; - beers       1      677 3146</span>
<span class="co">#&gt; - streamdist  1      716 3185</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Call:  glm(formula = cover ~ tci + beers + disturb + streamdist, family = poisson, </span>
<span class="co">#&gt;     data = dat_2)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Coefficients:</span>
<span class="co">#&gt;   (Intercept)            tci          beers  disturbLT-SEL  disturbSETTLE  </span>
<span class="co">#&gt;      1.464757       0.015326       0.065147       0.035010       0.052524  </span>
<span class="co">#&gt; disturbVIRGIN     streamdist  </span>
<span class="co">#&gt;      0.156454      -0.000799  </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Degrees of Freedom: 744 Total (i.e. Null);  738 Residual</span>
<span class="co">#&gt;   (1 observation deleted due to missingness)</span>
<span class="co">#&gt; Null Deviance:       748 </span>
<span class="co">#&gt; Residual Deviance: 670   AIC: 3140</span></code></pre></div>
<p>Tomemos en cuenta el modelo con una interacción entre <code>streamdist</code> y <code>disturb</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mod_<span class="dv">4</span> =<span class="st"> </span><span class="kw">glm</span>(cover<span class="op">~</span>disturb<span class="op">*</span>streamdist,<span class="dt">data=</span>dat_<span class="dv">2</span>,<span class="dt">family=</span>poisson)
<span class="kw">summary</span>(mod_<span class="dv">4</span>)
<span class="co">#&gt; </span>
<span class="co">#&gt; Call:</span>
<span class="co">#&gt; glm(formula = cover ~ disturb * streamdist, family = poisson, </span>
<span class="co">#&gt;     data = dat_2)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Deviance Residuals: </span>
<span class="co">#&gt;     Min       1Q   Median       3Q      Max  </span>
<span class="co">#&gt; -2.4084  -0.7680  -0.0713   0.6472   2.3969  </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Coefficients:</span>
<span class="co">#&gt;                           Estimate Std. Error z value Pr(&gt;|z|)    </span>
<span class="co">#&gt; (Intercept)               1.515210   0.062617   24.20  &lt; 2e-16 ***</span>
<span class="co">#&gt; disturbLT-SEL             0.257633   0.074157    3.47  0.00051 ***</span>
<span class="co">#&gt; disturbSETTLE             0.097346   0.083845    1.16  0.24563    </span>
<span class="co">#&gt; disturbVIRGIN             0.262322   0.088359    2.97  0.00299 ** </span>
<span class="co">#&gt; streamdist               -0.000165   0.000262   -0.63  0.52771    </span>
<span class="co">#&gt; disturbLT-SEL:streamdist -0.001261   0.000317   -3.98  6.8e-05 ***</span>
<span class="co">#&gt; disturbSETTLE:streamdist -0.000132   0.000402   -0.33  0.74289    </span>
<span class="co">#&gt; disturbVIRGIN:streamdist -0.000630   0.000358   -1.76  0.07883 .  </span>
<span class="co">#&gt; ---</span>
<span class="co">#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; (Dispersion parameter for poisson family taken to be 1)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;     Null deviance: 748.23  on 744  degrees of freedom</span>
<span class="co">#&gt; Residual deviance: 659.54  on 737  degrees of freedom</span>
<span class="co">#&gt;   (1 observation deleted due to missingness)</span>
<span class="co">#&gt; AIC: 3133</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Number of Fisher Scoring iterations: 4</span></code></pre></div>
<p><br></p>
<p><img src="figuras/manicule.jpg" /> ¿Cómo interpretarías los coeficientes del término de interacción? Veamos la distribución de <code>streamdist</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(<span class="dt">data =</span> dat_<span class="dv">2</span>, <span class="kw">aes</span>(<span class="dt">x =</span> streamdist)) <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_histogram</span>(<span class="dt">binwidth =</span> <span class="dv">20</span>)</code></pre></div>
<p><img src="10-glm_files/figure-html/unnamed-chunk-29-1.png" width="50%" style="display: block; margin: auto;" /></p>
<p class="espacio">
</p>
<p><br></p>
<p class="espacio3">
</p>
<img src="figuras/manicule2.jpg" />
<div class="centered">
<p class="espacio">
</p>
<p>El modelo de regresión anterior</p>
<ol style="list-style-type: lower-alpha">
<li><p>presenta sobredispersión.</p></li>
<li><p><span class="math inline">\(g(x)=\alpha + \beta x\)</span>.</p></li>
<li><p><span class="math inline">\(g(x)=\dfrac{1}{\sqrt{2\pi\sigma^2}}\,e^{-\frac{1}{2\sigma^2}(x-\mu)^2}\)</span>.</p></li>
<li><p><span class="math inline">\(g(x)=x\)</span>.</p></li>
</ol>
<p class="espacio3">
</p>
</div>
<p><br></p>
<hr />
</div>
<div id="sobredispersion" class="section level2">
<h2><span class="header-section-number">10.10</span> Sobredispersión</h2>
<p>Sobredispersión: Una peculiaridad de la distribución de Poisson es que su media es igual a su varianza. Sin embargo, en ciertos conjuntos de datos se observa una varianza superior a la esperada. El fenómeno se conoce como sobredispersión e indica que el modelo no es adecuado. Un motivo frecuente es la omisión de alguna variable relevante. En algunos casos se aconseja recurrir a la distribución binomial negativa.</p>
<p>En el modelo</p>
<p><span class="math display">\[
E(y_i)=u_i \theta_i,\qquad \sqrt{V(y_i)} = \sqrt{u_i \theta_i}
\]</span></p>
<p>Definimos los residuales estandarizados como</p>
<p><span class="math display">\[
\begin{eqnarray*}
z_i &amp;=&amp; \dfrac{y_i -\hat{y}_i}{\sqrt{V(\hat{y}_i)} } \\
&amp;=&amp; \dfrac{y_i - u_i\hat{\theta}_i}{\sqrt{u_i \hat{\theta}_i}}
\end{eqnarray*}
\]</span></p>
<p>donde</p>
<p><span class="math display">\[
\hat{\theta}_i = e^{X_i\hat{\beta}}
\]</span></p>
<p>Si el modelo de Poisson es verdadero, entonces las <span class="math inline">\(z_i\)</span>’s deben ser aproximadamente independientes (no exactamente independiente, ya que se utiliza la misma estimación <span class="math inline">\(\beta\)</span> para calcularlos todos), cada uno con media 0 y desviación estándar 1. Sin embargo, si hay sobredispersión, esperaríamos que las <span class="math inline">\(z_i\)</span>’s fueran más grandes, en valor absoluto, reflejando la variación adicional más allá de lo que predice el modelo.</p>
<p>Podemos probar la sobredispersión en una regresión Poisson calculando la suma de cuadrados de los <span class="math inline">\(n\)</span> residuos estandarizados</p>
<p><span class="math display">\[
\sum_{i=1}^n{z_i^2}
\]</span></p>
<p>y comparando esta cantidad con la distribución <span class="math inline">\(\chi^2_{n-k}\)</span>, que es lo que esperaríamos bajo el modelo (usando <span class="math inline">\(n-k\)</span> en lugar de <span class="math inline">\(n\)</span> grados de libertad para explicar la estimación de <span class="math inline">\(k\)</span> coeficientes en la regresión).</p>
<p>La distribución de una <span class="math inline">\(\chi^2_{n-k}\)</span> tiene media <span class="math inline">\(n-k\)</span>, por lo que se define la sobredispersión como</p>
<p><span class="math display">\[
\mbox{sobredispersión estimada} = \dfrac{1}{n-k}\sum_{i=1}^n{z_i^2}.
\]</span></p>
</div>
<div id="ejemplo-numero-de-publicaciones" class="section level2">
<h2><span class="header-section-number">10.11</span> Ejemplo: número de publicaciones</h2>
<p>Usamos datos de Long (1990) sobre la cantidad de publicaciones producidas por Ph.D. bioquímicos para ilustrar la aplicación de Poisson con sobredispersión <span class="citation">(Long, Freese, and others <a href="#ref-long2001predicted">2001</a>)</span>.</p>
<p>Las variables en el conjunto de datos son:</p>
<ul>
<li><strong>art</strong>: articles in last three years of Ph.D.</li>
<li><strong>fem</strong>: coded one for females</li>
<li><strong>mar</strong>: coded one if married</li>
<li><strong>kid5</strong>: number of children under age six</li>
<li><strong>phd</strong>: prestige of Ph.D. program</li>
<li><strong>ment</strong>: articles by mentor in last three years</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(foreign)
ab &lt;-<span class="st"> </span><span class="kw">read.dta</span>(<span class="st">&quot;http://www.stata-press.com/data/lf2/couart2.dta&quot;</span>)
ab <span class="op">%&gt;%</span><span class="st"> </span>head <span class="op">%&gt;%</span><span class="st"> </span>knitr<span class="op">::</span><span class="kw">kable</span>()</code></pre></div>
<table>
<thead>
<tr class="header">
<th align="right">art</th>
<th align="left">fem</th>
<th align="left">mar</th>
<th align="right">kid5</th>
<th align="right">phd</th>
<th align="right">ment</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">0</td>
<td align="left">Men</td>
<td align="left">Married</td>
<td align="right">0</td>
<td align="right">2.52</td>
<td align="right">7</td>
</tr>
<tr class="even">
<td align="right">0</td>
<td align="left">Women</td>
<td align="left">Single</td>
<td align="right">0</td>
<td align="right">2.05</td>
<td align="right">6</td>
</tr>
<tr class="odd">
<td align="right">0</td>
<td align="left">Women</td>
<td align="left">Single</td>
<td align="right">0</td>
<td align="right">3.75</td>
<td align="right">6</td>
</tr>
<tr class="even">
<td align="right">0</td>
<td align="left">Men</td>
<td align="left">Married</td>
<td align="right">1</td>
<td align="right">1.18</td>
<td align="right">3</td>
</tr>
<tr class="odd">
<td align="right">0</td>
<td align="left">Women</td>
<td align="left">Single</td>
<td align="right">0</td>
<td align="right">3.75</td>
<td align="right">26</td>
</tr>
<tr class="even">
<td align="right">0</td>
<td align="left">Women</td>
<td align="left">Married</td>
<td align="right">2</td>
<td align="right">3.59</td>
<td align="right">2</td>
</tr>
</tbody>
</table>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">r &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="kw">mean</span>(ab<span class="op">$</span>art), <span class="kw">var</span>(ab<span class="op">$</span>art))
<span class="kw">c</span>(<span class="dt">mean=</span>r[<span class="dv">1</span>], <span class="dt">var=</span>r[<span class="dv">2</span>], r[<span class="dv">2</span>]<span class="op">/</span>r[<span class="dv">1</span>])
<span class="co">#&gt; mean  var      </span>
<span class="co">#&gt; 1.69 3.71 2.19</span></code></pre></div>
<p>La cantidad media de artículos es 1.69 y la varianza es 3.71, un poco más que el doble de la media. Los datos están muy dispersos, pero por supuesto no hemos considerado ninguna covariable todavía.</p>
<p>Vamos a ajustar el modelo utilizado por Long y Freese (2001), un modelo aditivo simple que utiliza los cinco predictores.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mp &lt;-<span class="st"> </span><span class="kw">glm</span>(art<span class="op">~</span>fem<span class="op">+</span>mar<span class="op">+</span>kid5<span class="op">+</span>phd<span class="op">+</span>ment, <span class="dt">family=</span>poisson, <span class="dt">data=</span>ab)
<span class="kw">summary</span>(mp)
<span class="co">#&gt; </span>
<span class="co">#&gt; Call:</span>
<span class="co">#&gt; glm(formula = art ~ fem + mar + kid5 + phd + ment, family = poisson, </span>
<span class="co">#&gt;     data = ab)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Deviance Residuals: </span>
<span class="co">#&gt;    Min      1Q  Median      3Q     Max  </span>
<span class="co">#&gt; -3.567  -1.540  -0.366   0.572   5.447  </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Coefficients:</span>
<span class="co">#&gt;             Estimate Std. Error z value Pr(&gt;|z|)    </span>
<span class="co">#&gt; (Intercept)  0.30462    0.10298    2.96   0.0031 ** </span>
<span class="co">#&gt; femWomen    -0.22459    0.05461   -4.11  3.9e-05 ***</span>
<span class="co">#&gt; marMarried   0.15524    0.06137    2.53   0.0114 *  </span>
<span class="co">#&gt; kid5        -0.18488    0.04013   -4.61  4.1e-06 ***</span>
<span class="co">#&gt; phd          0.01282    0.02640    0.49   0.6271    </span>
<span class="co">#&gt; ment         0.02554    0.00201   12.73  &lt; 2e-16 ***</span>
<span class="co">#&gt; ---</span>
<span class="co">#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; (Dispersion parameter for poisson family taken to be 1)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;     Null deviance: 1817.4  on 914  degrees of freedom</span>
<span class="co">#&gt; Residual deviance: 1634.4  on 909  degrees of freedom</span>
<span class="co">#&gt; AIC: 3314</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Number of Fisher Scoring iterations: 5</span></code></pre></div>
<p>Vemos que el modelo obviamente no se ajusta a los datos.</p>
<p>Calculamos la sobredispersión estimada:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">yhat &lt;-<span class="st"> </span><span class="kw">predict</span>(mp, <span class="dt">type=</span><span class="st">&quot;response&quot;</span>)
z &lt;-<span class="st"> </span>(ab<span class="op">$</span>art<span class="op">-</span>yhat)<span class="op">/</span><span class="kw">sqrt</span>(yhat)
k &lt;-<span class="st"> </span><span class="kw">length</span>(mp<span class="op">$</span>coefficients)
n &lt;-<span class="st"> </span><span class="kw">nrow</span>(ab)
<span class="kw">cat</span>(<span class="st">&quot;la sobredispersión estimada es &quot;</span>, <span class="kw">sum</span>(z<span class="op">^</span><span class="dv">2</span>)<span class="op">/</span>(n<span class="op">-</span>k), <span class="st">&quot;</span><span class="ch">\n</span><span class="st">&quot;</span>)
<span class="co">#&gt; la sobredispersión estimada es  1.83</span>
<span class="kw">cat</span>(<span class="st">&quot;valor p de la prueba de sobredispersión&quot;, pchisq(sum(z^2), n-k), &quot;</span>\n<span class="st">&quot;)</span>
<span class="st">#&gt; valor p de la prueba de sobredispersión 1</span></code></pre></div>
<p>El valor p es 1, lo que indica que la probabilidad de que una variable aleatoria con distribución <span class="math inline">\(\chi^2_{909}\)</span> tome un valor tan grande como 1662.547 es esencialmente cero.</p>
<p>También podemos hacer una gráfica de residuales estandarizados vs ajustados:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">ab<span class="op">$</span>ajustados &lt;-<span class="st"> </span><span class="kw">predict</span>(mp, <span class="dt">type=</span><span class="st">&quot;response&quot;</span>)
ab<span class="op">$</span>residuales &lt;-<span class="st"> </span>(ab<span class="op">$</span>art<span class="op">-</span>ab<span class="op">$</span>ajustados)
ab<span class="op">$</span>residuales_est &lt;-<span class="st"> </span>(ab<span class="op">$</span>art<span class="op">-</span>ab<span class="op">$</span>ajustados)<span class="op">/</span><span class="kw">sqrt</span>(ab<span class="op">$</span>ajustados)
<span class="kw">ggplot</span>(ab, <span class="kw">aes</span>(<span class="dt">x=</span>ajustados, <span class="dt">y=</span>residuales_est)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_jitter</span>(<span class="dt">width =</span> .<span class="dv">5</span>, <span class="dt">height =</span> .<span class="dv">5</span>, <span class="dt">alpha =</span> <span class="fl">0.3</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_abline</span>(<span class="dt">slope =</span> <span class="dv">0</span>, <span class="dt">intercept =</span> <span class="dv">0</span>, <span class="dt">color =</span><span class="st">&#39;red&#39;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_abline</span>(<span class="dt">slope =</span> <span class="dv">0</span>, <span class="dt">intercept =</span> <span class="dv">2</span>, <span class="dt">color =</span><span class="st">&#39;navyblue&#39;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_abline</span>(<span class="dt">slope =</span> <span class="dv">0</span>, <span class="dt">intercept =</span> <span class="op">-</span><span class="dv">2</span>, <span class="dt">color =</span><span class="st">&#39;navyblue&#39;</span>)</code></pre></div>
<p><img src="10-glm_files/figure-html/unnamed-chunk-34-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>La gráfica de residuales vs ajustados:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(ab, <span class="kw">aes</span>(<span class="dt">x=</span>ajustados, <span class="dt">y=</span>residuales)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_jitter</span>(<span class="dt">width =</span> <span class="dv">1</span>, <span class="dt">height =</span> <span class="dv">1</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_abline</span>(<span class="dt">slope =</span> <span class="dv">0</span>, <span class="dt">intercept =</span> <span class="dv">0</span>, <span class="dt">color =</span><span class="st">&#39;red&#39;</span>)</code></pre></div>
<p><img src="10-glm_files/figure-html/unnamed-chunk-35-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>Para ajustar la inferencia por sobredispersión en <code>glm</code> utilizamos la familia <code>quasipoisson</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mq &lt;-<span class="st"> </span><span class="kw">glm</span>(art<span class="op">~</span>fem<span class="op">+</span>mar<span class="op">+</span>kid5<span class="op">+</span>phd<span class="op">+</span>ment, <span class="dt">family=</span>quasipoisson, <span class="dt">data=</span>ab)
<span class="kw">summary</span>(mq)
<span class="co">#&gt; </span>
<span class="co">#&gt; Call:</span>
<span class="co">#&gt; glm(formula = art ~ fem + mar + kid5 + phd + ment, family = quasipoisson, </span>
<span class="co">#&gt;     data = ab)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Deviance Residuals: </span>
<span class="co">#&gt;    Min      1Q  Median      3Q     Max  </span>
<span class="co">#&gt; -3.567  -1.540  -0.366   0.572   5.447  </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Coefficients:</span>
<span class="co">#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    </span>
<span class="co">#&gt; (Intercept)  0.30462    0.13927    2.19  0.02898 *  </span>
<span class="co">#&gt; femWomen    -0.22459    0.07386   -3.04  0.00243 ** </span>
<span class="co">#&gt; marMarried   0.15524    0.08300    1.87  0.06176 .  </span>
<span class="co">#&gt; kid5        -0.18488    0.05427   -3.41  0.00069 ***</span>
<span class="co">#&gt; phd          0.01282    0.03570    0.36  0.71954    </span>
<span class="co">#&gt; ment         0.02554    0.00271    9.41  &lt; 2e-16 ***</span>
<span class="co">#&gt; ---</span>
<span class="co">#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; (Dispersion parameter for quasipoisson family taken to be 1.83)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;     Null deviance: 1817.4  on 914  degrees of freedom</span>
<span class="co">#&gt; Residual deviance: 1634.4  on 909  degrees of freedom</span>
<span class="co">#&gt; AIC: NA</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Number of Fisher Scoring iterations: 5</span></code></pre></div>
<p>Escribimos este modelo como</p>
<p><span class="math display">\[
y_i \sim \mbox{Poisson sobredispersado }(u_i \exp(X_i\beta), \omega),
\]</span> donde <span class="math inline">\(\omega\)</span> es el parámetro de sobredispersión. Estrictamente hablando, “Poisson sobredispersado” no es un modelo único, sino que describe cualquier modelo de recuento de datos para el cual la varianza de los datos es <span class="math inline">\(\omega\)</span> veces la media, reduciéndose al Poisson si <span class="math inline">\(\omega = 1\)</span>.</p>
<p>Un modelo específico común mente utilizado en este escenario es la distribución llamada binomial negativa: <span class="math display">\[
y_i \sim \mbox{Negativo-binomial} (\mbox{media} = u_i \exp (X_i\beta), \mbox{sobredispersión} = \omega).
\]</span></p>
<p>Ahora ajustamos un modelo binomial negativo con los mismos predictores. Para hacer esto, necesitamos la función <code>glm.nb()</code> del paquete <code>MASS</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(MASS)
mnb &lt;-<span class="st"> </span><span class="kw">glm.nb</span>(art <span class="op">~</span><span class="st"> </span>fem <span class="op">+</span><span class="st"> </span>kid5 <span class="op">+</span><span class="st"> </span>ment, <span class="dt">data =</span> ab)
<span class="kw">summary</span>(mnb)
<span class="co">#&gt; </span>
<span class="co">#&gt; Call:</span>
<span class="co">#&gt; glm.nb(formula = art ~ fem + kid5 + ment, data = ab, init.theta = 2.240577103, </span>
<span class="co">#&gt;     link = log)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Deviance Residuals: </span>
<span class="co">#&gt;    Min      1Q  Median      3Q     Max  </span>
<span class="co">#&gt; -2.174  -1.377  -0.284   0.422   3.449  </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Coefficients:</span>
<span class="co">#&gt;             Estimate Std. Error z value Pr(&gt;|z|)    </span>
<span class="co">#&gt; (Intercept)  0.39102    0.06453    6.06  1.4e-09 ***</span>
<span class="co">#&gt; femWomen    -0.23270    0.07218   -3.22   0.0013 ** </span>
<span class="co">#&gt; kid5        -0.13775    0.04815   -2.86   0.0042 ** </span>
<span class="co">#&gt; ment         0.02937    0.00312    9.42  &lt; 2e-16 ***</span>
<span class="co">#&gt; ---</span>
<span class="co">#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; (Dispersion parameter for Negative Binomial(2.24) family taken to be 1)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;     Null deviance: 1105.0  on 914  degrees of freedom</span>
<span class="co">#&gt; Residual deviance: 1004.2  on 911  degrees of freedom</span>
<span class="co">#&gt; AIC: 3135</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Number of Fisher Scoring iterations: 1</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; </span>
<span class="co">#&gt;               Theta:  2.241 </span>
<span class="co">#&gt;           Std. Err.:  0.267 </span>
<span class="co">#&gt; </span>
<span class="co">#&gt;  2 x log-likelihood:  -3125.329</span></code></pre></div>
<p>Podemos ver el parámetro <span class="math inline">\(1/\omega\)</span>, que interpretamos como la varianza estimada:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mnb<span class="op">$</span>theta
<span class="co">#&gt; [1] 2.24</span></code></pre></div>
<p>Se puede ajustar el modelo usando <code>glm</code> indicando que se trata de una familia binomial negativa usando el mismo parámetro de sobredispersión utilizando únicamente los 3 predictores más explicativos:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mnbg &lt;-<span class="st"> </span><span class="kw">glm</span>(art <span class="op">~</span><span class="st"> </span>fem <span class="op">+</span><span class="st"> </span>kid5 <span class="op">+</span><span class="st"> </span>ment,
            <span class="dt">family=</span><span class="kw">negative.binomial</span>(mnb<span class="op">$</span>theta), <span class="dt">data =</span> ab)
<span class="kw">summary</span>(mnbg)
<span class="co">#&gt; </span>
<span class="co">#&gt; Call:</span>
<span class="co">#&gt; glm(formula = art ~ fem + kid5 + ment, family = negative.binomial(mnb$theta), </span>
<span class="co">#&gt;     data = ab)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Deviance Residuals: </span>
<span class="co">#&gt;    Min      1Q  Median      3Q     Max  </span>
<span class="co">#&gt; -2.174  -1.377  -0.284   0.422   3.449  </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Coefficients:</span>
<span class="co">#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    </span>
<span class="co">#&gt; (Intercept)  0.39103    0.06562    5.96  3.6e-09 ***</span>
<span class="co">#&gt; femWomen    -0.23270    0.07340   -3.17   0.0016 ** </span>
<span class="co">#&gt; kid5        -0.13776    0.04897   -2.81   0.0050 ** </span>
<span class="co">#&gt; ment         0.02937    0.00317    9.27  &lt; 2e-16 ***</span>
<span class="co">#&gt; ---</span>
<span class="co">#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; (Dispersion parameter for Negative Binomial(2.24) family taken to be 1.03)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;     Null deviance: 1105.0  on 914  degrees of freedom</span>
<span class="co">#&gt; Residual deviance: 1004.2  on 911  degrees of freedom</span>
<span class="co">#&gt; AIC: 3133</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Number of Fisher Scoring iterations: 6</span></code></pre></div>
<p>El ajuste del modelo es similar. Sin embargo, la varianza es varias veces la media en este modelo, y dado que los errores estándar se basan en el supuesto de que la varianza es igual a la media, esto crea un problema esn las estimaciones. La varianza real es varias veces más de lo que debería ser, y los errores estándar estimados con el modelo Poisson estaban claramente subestimados.</p>
</div>
<div id="tarea-8" class="section level2">
<h2><span class="header-section-number">10.12</span> Tarea</h2>
<p>Se tienen datos de una prueba controlada aleatorizada (en inglés se la llama RCT por randomized controlled trial) dirigida a parejas con alto riesgo de infección por VIH. La intervención brindó sesiones de asesoramiento sobre prácticas que podrían reducir la probabilidad de contraer el VIH. Las parejas se asignaron al azar a un grupo control (en el que solo participó la mujer) o un grupo en el que participaron los dos miembros de la pareja. Después de tres meses se registró como resultado el “número de actos sexuales sin protección”.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">risky_behaviors &lt;-<span class="st"> </span><span class="kw">read_csv</span>(<span class="st">&quot;datos/risky_behaviors.csv&quot;</span>)
risky_behaviors <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">sample_n</span>(<span class="dv">10</span>) <span class="op">%&gt;%</span><span class="st"> </span>knitr<span class="op">::</span><span class="kw">kable</span>()</code></pre></div>
<table>
<thead>
<tr class="header">
<th align="left">sex</th>
<th align="right">couples</th>
<th align="right">women_alone</th>
<th align="left">bs_hiv</th>
<th align="right">bupacts</th>
<th align="right">fupacts</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">woman</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="left">negative</td>
<td align="right">28</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="left">woman</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="left">negative</td>
<td align="right">9</td>
<td align="right">4</td>
</tr>
<tr class="odd">
<td align="left">man</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="left">negative</td>
<td align="right">3</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="left">woman</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="left">negative</td>
<td align="right">3</td>
<td align="right">3</td>
</tr>
<tr class="odd">
<td align="left">man</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="left">negative</td>
<td align="right">87</td>
<td align="right">6</td>
</tr>
<tr class="even">
<td align="left">man</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="left">negative</td>
<td align="right">30</td>
<td align="right">3</td>
</tr>
<tr class="odd">
<td align="left">man</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="left">positive</td>
<td align="right">50</td>
<td align="right">28</td>
</tr>
<tr class="even">
<td align="left">man</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="left">negative</td>
<td align="right">16</td>
<td align="right">8</td>
</tr>
<tr class="odd">
<td align="left">man</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="left">positive</td>
<td align="right">20</td>
<td align="right">5</td>
</tr>
<tr class="even">
<td align="left">woman</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="left">negative</td>
<td align="right">5</td>
<td align="right">25</td>
</tr>
</tbody>
</table>
<ol style="list-style-type: lower-alpha">
<li><p>Modela este resultado (<code>fupacts</code>) como una función de la asignación del tratamiento (<code>women_alone</code>) usando una regresión Poisson. ¿El modelo se ajusta bien? ¿Hay evidencia de sobredispersión?</p></li>
<li><p>A continuación, añade al modelo las variables restantes. ¿El modelo se ajusta mejor? ¿Hay evidencia de sobredispersión? Compara el AIC con el del inciso anterior.</p></li>
<li><p>Ajusta un modelo Poisson sobredispersado. ¿Qué puedes concluir con respecto a la efectividad de la intervención?</p></li>
<li><p>Estos datos incluyen respuestas tanto de hombrescomo de mujeres de las parejas participantes. ¿Esto nos dice algo con respecto a los supuestos del modelado?</p></li>
</ol>

</div>
</div>
<h3>Referencias</h3>
<div id="refs" class="references">
<div id="ref-rj1978generalized">
<p>RJ, LITTLE. 1978. “Generalized Linear Models for Cross-Classified Data from the Wfs.”</p>
</div>
<div id="ref-long2001predicted">
<p>Long, J Scott, Jeremy Freese, and others. 2001. “Predicted Probabilities for Count Models.” <em>Stata Journal</em> 1 (1). StataCorp LP: 51–57.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="regularizacion.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="analisis-de-discriminante-lineal-1.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
