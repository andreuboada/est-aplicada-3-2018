<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Estadística Aplicada III</title>
  <meta name="description" content="Notas y material para el curso de Estadística Aplicada III, 2018 (ITAM)">
  <meta name="generator" content="bookdown 0.7.10 and GitBook 2.6.7">

  <meta property="og:title" content="Estadística Aplicada III" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Notas y material para el curso de Estadística Aplicada III, 2018 (ITAM)" />
  <meta name="github-repo" content="andreuboada/est-aplicada-3-2018" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Estadística Aplicada III" />
  
  <meta name="twitter:description" content="Notas y material para el curso de Estadística Aplicada III, 2018 (ITAM)" />
  

<meta name="author" content="Andreu Boada de Atela">


<meta name="date" content="2018-05-21">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="modelos-lineales-generalizados.html">
<link rel="next" href="discriminante-lineal-lda-2.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
<link rel="stylesheet" href="toc.css" type="text/css" />
<link rel="stylesheet" href="font-awesome.min.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Estadística Aplicada III</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Temario y referencias</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#evaluacion"><i class="fa fa-check"></i>Evaluación</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#software-r-y-rstudio"><i class="fa fa-check"></i>Software: R y Rstudio</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#referencias-principales"><i class="fa fa-check"></i>Referencias principales</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#otras-referencias"><i class="fa fa-check"></i>Otras referencias</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#tareas"><i class="fa fa-check"></i>Tareas</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introducción</a><ul>
<li class="chapter" data-level="1.1" data-path="intro.html"><a href="intro.html#por-que-un-analisis-multivariado"><i class="fa fa-check"></i><b>1.1</b> ¿Por qué un análisis multivariado?</a></li>
<li class="chapter" data-level="1.2" data-path="intro.html"><a href="intro.html#la-paradoja-de-simpson"><i class="fa fa-check"></i><b>1.2</b> La paradoja de Simpson</a></li>
<li class="chapter" data-level="1.3" data-path="intro.html"><a href="intro.html#modelos-log-lineales"><i class="fa fa-check"></i><b>1.3</b> Modelos log-lineales</a></li>
<li class="chapter" data-level="1.4" data-path="intro.html"><a href="intro.html#interpretacion-de-parametros"><i class="fa fa-check"></i><b>1.4</b> Interpretación de parámetros</a><ul>
<li class="chapter" data-level="1.4.1" data-path="intro.html"><a href="intro.html#ejemplo-dos-monedas"><i class="fa fa-check"></i><b>1.4.1</b> Ejemplo: dos monedas</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="intro.html"><a href="intro.html#otros-ejemplos"><i class="fa fa-check"></i><b>1.5</b> Otros ejemplos</a><ul>
<li class="chapter" data-level="1.5.1" data-path="intro.html"><a href="intro.html#discriminacion-de-residentes-hispanos-con-discapacidades"><i class="fa fa-check"></i><b>1.5.1</b> Discriminación de residentes hispanos con discapacidades</a></li>
<li class="chapter" data-level="1.5.2" data-path="intro.html"><a href="intro.html#consumo-de-chocolate-y-premios-nobel"><i class="fa fa-check"></i><b>1.5.2</b> Consumo de chocolate y premios Nobel</a></li>
</ul></li>
<li class="chapter" data-level="1.6" data-path="intro.html"><a href="intro.html#tarea"><i class="fa fa-check"></i><b>1.6</b> Tarea</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="Rintro.html"><a href="Rintro.html"><i class="fa fa-check"></i><b>2</b> Temas selectos de R</a><ul>
<li class="chapter" data-level="2.1" data-path="Rintro.html"><a href="Rintro.html#que-ventajas-tiene-r"><i class="fa fa-check"></i><b>2.1</b> ¿Qué ventajas tiene R?</a><ul>
<li class="chapter" data-level="2.1.1" data-path="Rintro.html"><a href="Rintro.html#r-es-gratuito-y-de-codigo-abierto"><i class="fa fa-check"></i><b>2.1.1</b> R es gratuito y de código abierto</a></li>
<li class="chapter" data-level="2.1.2" data-path="Rintro.html"><a href="Rintro.html#r-tiene-una-comunidad-comprometida"><i class="fa fa-check"></i><b>2.1.2</b> R tiene una comunidad comprometida</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="Rintro.html"><a href="Rintro.html#flujo-basico-de-trabajo-para-el-analisis-de-datos-en-r."><i class="fa fa-check"></i><b>2.2</b> Flujo básico de trabajo para el análisis de datos en R.</a></li>
<li class="chapter" data-level="2.3" data-path="Rintro.html"><a href="Rintro.html#introduccion-a-r-como-lenguaje-de-programacion-y-la-plataforma-interactiva-de-rstudio."><i class="fa fa-check"></i><b>2.3</b> Introducción a R como lenguaje de programación, y la plataforma interactiva de RStudio.</a><ul>
<li class="chapter" data-level="2.3.1" data-path="Rintro.html"><a href="Rintro.html#como-entender-r"><i class="fa fa-check"></i><b>2.3.1</b> ¿Cómo entender R?</a></li>
<li class="chapter" data-level="2.3.2" data-path="Rintro.html"><a href="Rintro.html#por-que-r"><i class="fa fa-check"></i><b>2.3.2</b> ¿Por qué R?</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="Rintro.html"><a href="Rintro.html#estructuras-de-datos"><i class="fa fa-check"></i><b>2.4</b> Estructuras de datos</a><ul>
<li class="chapter" data-level="2.4.1" data-path="Rintro.html"><a href="Rintro.html#vectores"><i class="fa fa-check"></i><b>2.4.1</b> Vectores</a></li>
<li class="chapter" data-level="2.4.2" data-path="Rintro.html"><a href="Rintro.html#data-frames"><i class="fa fa-check"></i><b>2.4.2</b> Data Frames</a></li>
<li class="chapter" data-level="2.4.3" data-path="Rintro.html"><a href="Rintro.html#listas"><i class="fa fa-check"></i><b>2.4.3</b> Listas</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="Rintro.html"><a href="Rintro.html#r-markdown"><i class="fa fa-check"></i><b>2.5</b> R Markdown</a><ul>
<li class="chapter" data-level="2.5.1" data-path="Rintro.html"><a href="Rintro.html#que-es-r-markdown"><i class="fa fa-check"></i><b>2.5.1</b> ¿Qué es R Markdown?</a></li>
<li class="chapter" data-level="2.5.2" data-path="Rintro.html"><a href="Rintro.html#estructura-basica-de-r-markdown"><i class="fa fa-check"></i><b>2.5.2</b> Estructura básica de R Markdown</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="Rintro.html"><a href="Rintro.html#proyectos-de-rstudio"><i class="fa fa-check"></i><b>2.6</b> Proyectos de RStudio</a></li>
<li class="chapter" data-level="2.7" data-path="Rintro.html"><a href="Rintro.html#otros-aspectos-importantes-de-r"><i class="fa fa-check"></i><b>2.7</b> Otros aspectos importantes de R</a><ul>
<li class="chapter" data-level="2.7.1" data-path="Rintro.html"><a href="Rintro.html#valores-faltantes"><i class="fa fa-check"></i><b>2.7.1</b> Valores faltantes</a></li>
<li class="chapter" data-level="2.7.2" data-path="Rintro.html"><a href="Rintro.html#funciones"><i class="fa fa-check"></i><b>2.7.2</b> Funciones</a></li>
<li class="chapter" data-level="2.7.3" data-path="Rintro.html"><a href="Rintro.html#funcionales"><i class="fa fa-check"></i><b>2.7.3</b> Funcionales</a></li>
<li class="chapter" data-level="2.7.4" data-path="Rintro.html"><a href="Rintro.html#rendimiento-en-r"><i class="fa fa-check"></i><b>2.7.4</b> Rendimiento en R</a></li>
</ul></li>
<li class="chapter" data-level="2.8" data-path="Rintro.html"><a href="Rintro.html#tarea-1"><i class="fa fa-check"></i><b>2.8</b> Tarea</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="manipulacion-y-visualizacion-de-datos.html"><a href="manipulacion-y-visualizacion-de-datos.html"><i class="fa fa-check"></i><b>3</b> Manipulación y visualización de datos</a><ul>
<li class="chapter" data-level="3.1" data-path="manipulacion-y-visualizacion-de-datos.html"><a href="manipulacion-y-visualizacion-de-datos.html#el-principio-de-datos-limpios"><i class="fa fa-check"></i><b>3.1</b> El principio de datos limpios</a></li>
<li class="chapter" data-level="3.2" data-path="manipulacion-y-visualizacion-de-datos.html"><a href="manipulacion-y-visualizacion-de-datos.html#limpieza-de-datos"><i class="fa fa-check"></i><b>3.2</b> Limpieza de datos</a></li>
<li class="chapter" data-level="3.3" data-path="manipulacion-y-visualizacion-de-datos.html"><a href="manipulacion-y-visualizacion-de-datos.html#separa-aplica-combina"><i class="fa fa-check"></i><b>3.3</b> <em>Separa-aplica-combina</em></a></li>
<li class="chapter" data-level="3.4" data-path="manipulacion-y-visualizacion-de-datos.html"><a href="manipulacion-y-visualizacion-de-datos.html#muertes-por-armas-de-fuego-en-eua"><i class="fa fa-check"></i><b>3.4</b> Muertes por armas de fuego en EUA</a></li>
<li class="chapter" data-level="3.5" data-path="manipulacion-y-visualizacion-de-datos.html"><a href="manipulacion-y-visualizacion-de-datos.html#el-cuarteto-de-anscombe"><i class="fa fa-check"></i><b>3.5</b> El Cuarteto de Anscombe</a></li>
<li class="chapter" data-level="3.6" data-path="manipulacion-y-visualizacion-de-datos.html"><a href="manipulacion-y-visualizacion-de-datos.html#the-grammar-of-graphics-de-leland-wilkinson"><i class="fa fa-check"></i><b>3.6</b> The <em>Grammar of Graphics</em> de Leland Wilkinson</a></li>
<li class="chapter" data-level="3.7" data-path="manipulacion-y-visualizacion-de-datos.html"><a href="manipulacion-y-visualizacion-de-datos.html#ggplot"><i class="fa fa-check"></i><b>3.7</b> ggplot</a></li>
<li class="chapter" data-level="3.8" data-path="manipulacion-y-visualizacion-de-datos.html"><a href="manipulacion-y-visualizacion-de-datos.html#un-histograma-de-las-muertes-en-iraq"><i class="fa fa-check"></i><b>3.8</b> Un histograma de las muertes en Iraq</a></li>
<li class="chapter" data-level="3.9" data-path="manipulacion-y-visualizacion-de-datos.html"><a href="manipulacion-y-visualizacion-de-datos.html#inglehartwelzel-un-mapa-cultural-del-mundo"><i class="fa fa-check"></i><b>3.9</b> Inglehart–Welzel: un mapa cultural del mundo</a><ul>
<li class="chapter" data-level="3.9.1" data-path="manipulacion-y-visualizacion-de-datos.html"><a href="manipulacion-y-visualizacion-de-datos.html#creando-un-ggplot"><i class="fa fa-check"></i><b>3.9.1</b> Creando un ggplot</a></li>
<li class="chapter" data-level="3.9.2" data-path="manipulacion-y-visualizacion-de-datos.html"><a href="manipulacion-y-visualizacion-de-datos.html#mapeos-aesthetics"><i class="fa fa-check"></i><b>3.9.2</b> Mapeos: Aesthetics</a></li>
</ul></li>
<li class="chapter" data-level="3.10" data-path="manipulacion-y-visualizacion-de-datos.html"><a href="manipulacion-y-visualizacion-de-datos.html#poniendo-todo-junto"><i class="fa fa-check"></i><b>3.10</b> Poniendo todo junto</a></li>
<li class="chapter" data-level="3.11" data-path="manipulacion-y-visualizacion-de-datos.html"><a href="manipulacion-y-visualizacion-de-datos.html#tarea-2"><i class="fa fa-check"></i><b>3.11</b> Tarea</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="teorema-del-limite-central.html"><a href="teorema-del-limite-central.html"><i class="fa fa-check"></i><b>4</b> Teorema del Límite Central</a><ul>
<li class="chapter" data-level="4.1" data-path="teorema-del-limite-central.html"><a href="teorema-del-limite-central.html#la-distribucion-de-la-media"><i class="fa fa-check"></i><b>4.1</b> La distribución de la media</a></li>
<li class="chapter" data-level="4.2" data-path="teorema-del-limite-central.html"><a href="teorema-del-limite-central.html#de-donde-proviene-la-distribucion-normal"><i class="fa fa-check"></i><b>4.2</b> ¿De dónde proviene la distribución normal?</a><ul>
<li class="chapter" data-level="4.2.1" data-path="teorema-del-limite-central.html"><a href="teorema-del-limite-central.html#que-signo-tiene-c"><i class="fa fa-check"></i><b>4.2.1</b> ¿Qué signo tiene c?</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="teorema-del-limite-central.html"><a href="teorema-del-limite-central.html#otras-observaciones"><i class="fa fa-check"></i><b>4.3</b> Otras observaciones</a></li>
<li class="chapter" data-level="4.4" data-path="teorema-del-limite-central.html"><a href="teorema-del-limite-central.html#diagramas-de-caja-y-brazos"><i class="fa fa-check"></i><b>4.4</b> Diagramas de caja y brazos</a><ul>
<li class="chapter" data-level="" data-path="teorema-del-limite-central.html"><a href="teorema-del-limite-central.html#ejemplo"><i class="fa fa-check"></i>Ejemplo</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="teorema-del-limite-central.html"><a href="teorema-del-limite-central.html#graficas-de-cuantiles-teoricos"><i class="fa fa-check"></i><b>4.5</b> Gráficas de cuantiles teóricos</a><ul>
<li class="chapter" data-level="" data-path="teorema-del-limite-central.html"><a href="teorema-del-limite-central.html#ejemplo-normal"><i class="fa fa-check"></i>Ejemplo: normal</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="teorema-del-limite-central.html"><a href="teorema-del-limite-central.html#graficas-de-cuantiles-para-un-conjunto-de-datos"><i class="fa fa-check"></i><b>4.6</b> Gráficas de cuantiles para un conjunto de datos</a><ul>
<li class="chapter" data-level="4.6.1" data-path="teorema-del-limite-central.html"><a href="teorema-del-limite-central.html#que-buscar-en-una-grafica-de-cuantiles"><i class="fa fa-check"></i><b>4.6.1</b> ¿Qué buscar en una gráfica de cuantiles?</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="teorema-del-limite-central.html"><a href="teorema-del-limite-central.html#graficas-qq-normales"><i class="fa fa-check"></i><b>4.7</b> Gráficas qq-normales</a><ul>
<li class="chapter" data-level="" data-path="teorema-del-limite-central.html"><a href="teorema-del-limite-central.html#ejemplo-cantantes"><i class="fa fa-check"></i>Ejemplo: cantantes</a></li>
</ul></li>
<li class="chapter" data-level="4.8" data-path="teorema-del-limite-central.html"><a href="teorema-del-limite-central.html#el-tlc-y-errores-estandar"><i class="fa fa-check"></i><b>4.8</b> El TLC y errores estándar</a></li>
<li class="chapter" data-level="4.9" data-path="teorema-del-limite-central.html"><a href="teorema-del-limite-central.html#ejemplo-1"><i class="fa fa-check"></i><b>4.9</b> Ejemplo</a></li>
<li class="chapter" data-level="4.10" data-path="teorema-del-limite-central.html"><a href="teorema-del-limite-central.html#tarea-3"><i class="fa fa-check"></i><b>4.10</b> Tarea</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="analisis-de-datos-categoricos.html"><a href="analisis-de-datos-categoricos.html"><i class="fa fa-check"></i><b>5</b> Análisis de datos categóricos</a><ul>
<li class="chapter" data-level="5.1" data-path="analisis-de-datos-categoricos.html"><a href="analisis-de-datos-categoricos.html#repaso-y-algunos-conceptos"><i class="fa fa-check"></i><b>5.1</b> Repaso y algunos conceptos</a><ul>
<li class="chapter" data-level="5.1.1" data-path="analisis-de-datos-categoricos.html"><a href="analisis-de-datos-categoricos.html#caso-binomial"><i class="fa fa-check"></i><b>5.1.1</b> Caso binomial</a></li>
<li class="chapter" data-level="" data-path="analisis-de-datos-categoricos.html"><a href="analisis-de-datos-categoricos.html#estimacion-de-parametros-multinomiales"><i class="fa fa-check"></i>Estimación de parámetros multinomiales</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="analisis-de-datos-categoricos.html"><a href="analisis-de-datos-categoricos.html#la-chi2-de-pearson-de-una-multinomial"><i class="fa fa-check"></i><b>5.2</b> La <span class="math inline">\(\chi^2\)</span> de Pearson de una multinomial</a><ul>
<li class="chapter" data-level="5.2.1" data-path="analisis-de-datos-categoricos.html"><a href="analisis-de-datos-categoricos.html#cociente-de-verosimilitud-de-una-multinomial"><i class="fa fa-check"></i><b>5.2.1</b> Cociente de verosimilitud de una multinomial</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="analisis-de-datos-categoricos.html"><a href="analisis-de-datos-categoricos.html#definiciones"><i class="fa fa-check"></i><b>5.3</b> Definiciones</a><ul>
<li class="chapter" data-level="5.3.1" data-path="analisis-de-datos-categoricos.html"><a href="analisis-de-datos-categoricos.html#notacion"><i class="fa fa-check"></i><b>5.3.1</b> Notación</a></li>
<li class="chapter" data-level="5.3.2" data-path="analisis-de-datos-categoricos.html"><a href="analisis-de-datos-categoricos.html#razon-de-momios"><i class="fa fa-check"></i><b>5.3.2</b> Razón de momios</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="analisis-de-datos-categoricos.html"><a href="analisis-de-datos-categoricos.html#asociacion-en-tablas-de-tamano-itimes-j"><i class="fa fa-check"></i><b>5.4</b> Asociación en tablas de tamaño <span class="math inline">\(I\times J\)</span></a><ul>
<li class="chapter" data-level="5.4.1" data-path="analisis-de-datos-categoricos.html"><a href="analisis-de-datos-categoricos.html#razones-de-momios-en-tablas-itimes-j"><i class="fa fa-check"></i><b>5.4.1</b> Razones de momios en tablas <span class="math inline">\(I\times J\)</span></a></li>
<li class="chapter" data-level="5.4.2" data-path="analisis-de-datos-categoricos.html"><a href="analisis-de-datos-categoricos.html#ejemplo-mushrooms"><i class="fa fa-check"></i><b>5.4.2</b> Ejemplo: mushrooms</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="analisis-de-datos-categoricos.html"><a href="analisis-de-datos-categoricos.html#intervalos-de-confianza-para-los-parametros-de-asociacion"><i class="fa fa-check"></i><b>5.5</b> Intervalos de confianza para los parámetros de asociación</a><ul>
<li class="chapter" data-level="5.5.1" data-path="analisis-de-datos-categoricos.html"><a href="analisis-de-datos-categoricos.html#error-estandar-de-la-razon-de-momios"><i class="fa fa-check"></i><b>5.5.1</b> Error estándar de la razón de momios</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="analisis-de-datos-categoricos.html"><a href="analisis-de-datos-categoricos.html#prueba-de-independencia"><i class="fa fa-check"></i><b>5.6</b> Prueba de independencia</a><ul>
<li class="chapter" data-level="5.6.1" data-path="analisis-de-datos-categoricos.html"><a href="analisis-de-datos-categoricos.html#la-prueba-chi2-de-pearson"><i class="fa fa-check"></i><b>5.6.1</b> La prueba <span class="math inline">\(\chi^2\)</span> de Pearson</a></li>
<li class="chapter" data-level="5.6.2" data-path="analisis-de-datos-categoricos.html"><a href="analisis-de-datos-categoricos.html#ejemplo-brecha-de-genero"><i class="fa fa-check"></i><b>5.6.2</b> Ejemplo: brecha de género</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="analisis-de-datos-categoricos.html"><a href="analisis-de-datos-categoricos.html#general-social-survey-1972---2016"><i class="fa fa-check"></i><b>5.7</b> General Social Survey 1972 - 2016</a></li>
<li class="chapter" data-level="5.8" data-path="analisis-de-datos-categoricos.html"><a href="analisis-de-datos-categoricos.html#la-catadora-de-te"><i class="fa fa-check"></i><b>5.8</b> La catadora de té</a></li>
<li class="chapter" data-level="5.9" data-path="analisis-de-datos-categoricos.html"><a href="analisis-de-datos-categoricos.html#modelos-multinomiales-para-conteos"><i class="fa fa-check"></i><b>5.9</b> Modelos multinomiales para conteos</a></li>
<li class="chapter" data-level="5.10" data-path="analisis-de-datos-categoricos.html"><a href="analisis-de-datos-categoricos.html#modelos-log-lineales-con-tres-variables-categoricas"><i class="fa fa-check"></i><b>5.10</b> Modelos log lineales con tres variables categóricas</a><ul>
<li class="chapter" data-level="5.10.1" data-path="analisis-de-datos-categoricos.html"><a href="analisis-de-datos-categoricos.html#tipos-de-independencia"><i class="fa fa-check"></i><b>5.10.1</b> Tipos de independencia</a></li>
<li class="chapter" data-level="5.10.2" data-path="analisis-de-datos-categoricos.html"><a href="analisis-de-datos-categoricos.html#asociacion-homogenea-e-interacciones-de-3-factores"><i class="fa fa-check"></i><b>5.10.2</b> Asociación homogénea e interacciones de 3 factores</a></li>
</ul></li>
<li class="chapter" data-level="5.11" data-path="analisis-de-datos-categoricos.html"><a href="analisis-de-datos-categoricos.html#ejemplo-sensitividad-y-especificidad"><i class="fa fa-check"></i><b>5.11</b> Ejemplo: sensitividad y especificidad</a></li>
<li class="chapter" data-level="5.12" data-path="analisis-de-datos-categoricos.html"><a href="analisis-de-datos-categoricos.html#ejemplo-horoscopos"><i class="fa fa-check"></i><b>5.12</b> Ejemplo: horóscopos</a></li>
<li class="chapter" data-level="5.13" data-path="analisis-de-datos-categoricos.html"><a href="analisis-de-datos-categoricos.html#tarea-opcional"><i class="fa fa-check"></i><b>5.13</b> Tarea (opcional)</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="regresion-logistica-1.html"><a href="regresion-logistica-1.html"><i class="fa fa-check"></i><b>6</b> Regresión logística 1</a><ul>
<li class="chapter" data-level="6.1" data-path="regresion-logistica-1.html"><a href="regresion-logistica-1.html#regresion-logistica-con-un-solo-predictor"><i class="fa fa-check"></i><b>6.1</b> Regresión logística con un solo predictor</a></li>
<li class="chapter" data-level="6.2" data-path="regresion-logistica-1.html"><a href="regresion-logistica-1.html#el-modelo-de-regresion-logistica"><i class="fa fa-check"></i><b>6.2</b> El modelo de regresión logística</a><ul>
<li class="chapter" data-level="6.2.1" data-path="regresion-logistica-1.html"><a href="regresion-logistica-1.html#funcion-logistica"><i class="fa fa-check"></i><b>6.2.1</b> Función logística</a></li>
<li class="chapter" data-level="" data-path="regresion-logistica-1.html"><a href="regresion-logistica-1.html#ejemplo-2"><i class="fa fa-check"></i>Ejemplo</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="regresion-logistica-1.html"><a href="regresion-logistica-1.html#tarea-4"><i class="fa fa-check"></i><b>6.3</b> Tarea</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="regresion-logistica-2.html"><a href="regresion-logistica-2.html"><i class="fa fa-check"></i><b>7</b> Regresión logística 2</a><ul>
<li class="chapter" data-level="7.1" data-path="regresion-logistica-2.html"><a href="regresion-logistica-2.html#incertidumbre-en-la-estimacion"><i class="fa fa-check"></i><b>7.1</b> Incertidumbre en la estimación</a></li>
<li class="chapter" data-level="7.2" data-path="regresion-logistica-2.html"><a href="regresion-logistica-2.html#funcion-logistica-1"><i class="fa fa-check"></i><b>7.2</b> Función logística</a></li>
<li class="chapter" data-level="7.3" data-path="regresion-logistica-2.html"><a href="regresion-logistica-2.html#interpretacion-de-los-coeficientes"><i class="fa fa-check"></i><b>7.3</b> Interpretación de los coeficientes</a><ul>
<li class="chapter" data-level="7.3.1" data-path="regresion-logistica-2.html"><a href="regresion-logistica-2.html#evaluar-en-o-alrededor-de-la-media"><i class="fa fa-check"></i><b>7.3.1</b> Evaluar en (o alrededor de) la media</a></li>
<li class="chapter" data-level="7.3.2" data-path="regresion-logistica-2.html"><a href="regresion-logistica-2.html#la-regla-de-dividir-entre-4"><i class="fa fa-check"></i><b>7.3.2</b> La regla de “dividir entre 4”</a></li>
<li class="chapter" data-level="7.3.3" data-path="regresion-logistica-2.html"><a href="regresion-logistica-2.html#interpretacion-de-los-coeficientes-como-cocientes-de-momios"><i class="fa fa-check"></i><b>7.3.3</b> Interpretación de los coeficientes como cocientes de momios</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="regresion-logistica-2.html"><a href="regresion-logistica-2.html#ejemplo-pozos-en-bangladesh"><i class="fa fa-check"></i><b>7.4</b> Ejemplo: pozos en Bangladesh</a><ul>
<li class="chapter" data-level="7.4.1" data-path="regresion-logistica-2.html"><a href="regresion-logistica-2.html#descripcion-del-problema"><i class="fa fa-check"></i><b>7.4.1</b> Descripción del problema</a></li>
<li class="chapter" data-level="7.4.2" data-path="regresion-logistica-2.html"><a href="regresion-logistica-2.html#antecedentes-del-problema"><i class="fa fa-check"></i><b>7.4.2</b> Antecedentes del problema</a></li>
<li class="chapter" data-level="7.4.3" data-path="regresion-logistica-2.html"><a href="regresion-logistica-2.html#metodologia-para-abordar-el-problema"><i class="fa fa-check"></i><b>7.4.3</b> Metodología para abordar el problema</a></li>
<li class="chapter" data-level="7.4.4" data-path="regresion-logistica-2.html"><a href="regresion-logistica-2.html#ajuste-y-resultados-del-modelo"><i class="fa fa-check"></i><b>7.4.4</b> Ajuste y resultados del modelo</a></li>
<li class="chapter" data-level="7.4.5" data-path="regresion-logistica-2.html"><a href="regresion-logistica-2.html#interpretacion-de-los-coeficientes-1"><i class="fa fa-check"></i><b>7.4.5</b> Interpretación de los coeficientes</a></li>
<li class="chapter" data-level="7.4.6" data-path="regresion-logistica-2.html"><a href="regresion-logistica-2.html#agregamos-una-segunda-variable-de-entrada"><i class="fa fa-check"></i><b>7.4.6</b> Agregamos una segunda variable de entrada</a></li>
<li class="chapter" data-level="7.4.7" data-path="regresion-logistica-2.html"><a href="regresion-logistica-2.html#comparacion-de-coeficientes-cuando-anades-un-predictor"><i class="fa fa-check"></i><b>7.4.7</b> Comparación de coeficientes cuando añades un predictor</a></li>
<li class="chapter" data-level="7.4.8" data-path="regresion-logistica-2.html"><a href="regresion-logistica-2.html#graficar-el-modelo-ajustado-con-dos-predictores"><i class="fa fa-check"></i><b>7.4.8</b> Graficar el modelo ajustado con dos predictores</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="regresion-logistica-2.html"><a href="regresion-logistica-2.html#ajuste-de-coeficientes-para-regresion-logistica-binomial."><i class="fa fa-check"></i><b>7.5</b> Ajuste de coeficientes para regresión logística (binomial).</a></li>
<li class="chapter" data-level="7.6" data-path="regresion-logistica-2.html"><a href="regresion-logistica-2.html#descenso-en-gradiente"><i class="fa fa-check"></i><b>7.6</b> Descenso en gradiente</a><ul>
<li class="chapter" data-level="7.6.1" data-path="regresion-logistica-2.html"><a href="regresion-logistica-2.html#seleccion-de-tamano-de-paso-eta"><i class="fa fa-check"></i><b>7.6.1</b> Selección de tamaño de paso <span class="math inline">\(\eta\)</span></a></li>
<li class="chapter" data-level="7.6.2" data-path="regresion-logistica-2.html"><a href="regresion-logistica-2.html#funciones-de-varias-variables"><i class="fa fa-check"></i><b>7.6.2</b> Funciones de varias variables</a></li>
</ul></li>
<li class="chapter" data-level="7.7" data-path="regresion-logistica-2.html"><a href="regresion-logistica-2.html#ejemplo-diabetes"><i class="fa fa-check"></i><b>7.7</b> Ejemplo: diabetes</a></li>
<li class="chapter" data-level="7.8" data-path="regresion-logistica-2.html"><a href="regresion-logistica-2.html#observaciones-adicionales"><i class="fa fa-check"></i><b>7.8</b> Observaciones adicionales</a></li>
<li class="chapter" data-level="7.9" data-path="regresion-logistica-2.html"><a href="regresion-logistica-2.html#regresion-logistica-para-problemas-de-mas-de-2-clases"><i class="fa fa-check"></i><b>7.9</b> Regresión logística para problemas de más de 2 clases</a></li>
<li class="chapter" data-level="7.10" data-path="regresion-logistica-2.html"><a href="regresion-logistica-2.html#regresion-logistica-multinomial"><i class="fa fa-check"></i><b>7.10</b> Regresión logística multinomial</a></li>
<li class="chapter" data-level="7.11" data-path="regresion-logistica-2.html"><a href="regresion-logistica-2.html#identificabilidad-y-separacion"><i class="fa fa-check"></i><b>7.11</b> Identificabilidad y separación</a></li>
<li class="chapter" data-level="7.12" data-path="regresion-logistica-2.html"><a href="regresion-logistica-2.html#tarea-5"><i class="fa fa-check"></i><b>7.12</b> Tarea</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="regresion-logistica-3.html"><a href="regresion-logistica-3.html"><i class="fa fa-check"></i><b>8</b> Regresión logística 3</a><ul>
<li class="chapter" data-level="8.1" data-path="regresion-logistica-3.html"><a href="regresion-logistica-3.html#ejemplo-oscares"><i class="fa fa-check"></i><b>8.1</b> Ejemplo óscares</a></li>
<li class="chapter" data-level="8.2" data-path="regresion-logistica-3.html"><a href="regresion-logistica-3.html#repaso-de-regresion-logistica"><i class="fa fa-check"></i><b>8.2</b> Repaso de regresión logística</a></li>
<li class="chapter" data-level="8.3" data-path="regresion-logistica-3.html"><a href="regresion-logistica-3.html#regresion-logistica-con-interacciones"><i class="fa fa-check"></i><b>8.3</b> Regresión logística con interacciones</a></li>
<li class="chapter" data-level="8.4" data-path="regresion-logistica-3.html"><a href="regresion-logistica-3.html#graficas-del-modelo-con-interacciones"><i class="fa fa-check"></i><b>8.4</b> Gráficas del modelo con interacciones</a></li>
<li class="chapter" data-level="8.5" data-path="regresion-logistica-3.html"><a href="regresion-logistica-3.html#agregar-mas-predictores"><i class="fa fa-check"></i><b>8.5</b> Agregar más predictores</a></li>
<li class="chapter" data-level="8.6" data-path="regresion-logistica-3.html"><a href="regresion-logistica-3.html#evaluacion-de-modelos-de-regresion-logistica"><i class="fa fa-check"></i><b>8.6</b> Evaluación de modelos de regresión logística</a><ul>
<li class="chapter" data-level="8.6.1" data-path="regresion-logistica-3.html"><a href="regresion-logistica-3.html#graficas-de-residuales-agrupados-vs-predictores"><i class="fa fa-check"></i><b>8.6.1</b> Gráficas de residuales agrupados vs predictores</a></li>
<li class="chapter" data-level="8.6.2" data-path="regresion-logistica-3.html"><a href="regresion-logistica-3.html#transformaciones"><i class="fa fa-check"></i><b>8.6.2</b> Transformaciones</a></li>
<li class="chapter" data-level="8.6.3" data-path="regresion-logistica-3.html"><a href="regresion-logistica-3.html#tasa-de-error-y-comparacion-contra-el-modelo-nulo"><i class="fa fa-check"></i><b>8.6.3</b> Tasa de error y comparación contra el modelo nulo</a></li>
</ul></li>
<li class="chapter" data-level="8.7" data-path="regresion-logistica-3.html"><a href="regresion-logistica-3.html#diferencias-predictivas-promedio-en-la-escala-de-probabilidad"><i class="fa fa-check"></i><b>8.7</b> Diferencias predictivas promedio en la escala de probabilidad</a><ul>
<li class="chapter" data-level="" data-path="regresion-logistica-3.html"><a href="regresion-logistica-3.html#diferencias-predictivas-promedio-en-presencia-de-interacciones"><i class="fa fa-check"></i>Diferencias predictivas promedio en presencia de interacciones</a></li>
<li class="chapter" data-level="" data-path="regresion-logistica-3.html"><a href="regresion-logistica-3.html#notacion-general-para-diferencias-predictivas"><i class="fa fa-check"></i>Notación general para diferencias predictivas</a></li>
</ul></li>
<li class="chapter" data-level="8.8" data-path="regresion-logistica-3.html"><a href="regresion-logistica-3.html#tarea-6"><i class="fa fa-check"></i><b>8.8</b> Tarea</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="regularizacion.html"><a href="regularizacion.html"><i class="fa fa-check"></i><b>9</b> Regularización</a><ul>
<li class="chapter" data-level="9.1" data-path="regularizacion.html"><a href="regularizacion.html#repaso"><i class="fa fa-check"></i><b>9.1</b> Repaso</a></li>
<li class="chapter" data-level="9.2" data-path="regularizacion.html"><a href="regularizacion.html#otras-medidas-de-clasificacion"><i class="fa fa-check"></i><b>9.2</b> Otras medidas de clasificación</a></li>
<li class="chapter" data-level="9.3" data-path="regularizacion.html"><a href="regularizacion.html#analisis-de-error-en-clasificacion-binaria"><i class="fa fa-check"></i><b>9.3</b> Análisis de error en clasificación binaria</a><ul>
<li class="chapter" data-level="9.3.1" data-path="regularizacion.html"><a href="regularizacion.html#punto-de-corte-para-un-clasificador-binario"><i class="fa fa-check"></i><b>9.3.1</b> Punto de corte para un clasificador binario</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="regularizacion.html"><a href="regularizacion.html#curvas-roc"><i class="fa fa-check"></i><b>9.4</b> Curvas ROC</a><ul>
<li class="chapter" data-level="9.4.1" data-path="regularizacion.html"><a href="regularizacion.html#espacio-roc"><i class="fa fa-check"></i><b>9.4.1</b> Espacio ROC</a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="regularizacion.html"><a href="regularizacion.html#regularizacion-1"><i class="fa fa-check"></i><b>9.5</b> Regularización</a><ul>
<li class="chapter" data-level="9.5.1" data-path="regularizacion.html"><a href="regularizacion.html#reduciendo-varianza-de-los-coeficientes"><i class="fa fa-check"></i><b>9.5.1</b> Reduciendo varianza de los coeficientes</a></li>
</ul></li>
<li class="chapter" data-level="9.6" data-path="regularizacion.html"><a href="regularizacion.html#regularizacion-ridge"><i class="fa fa-check"></i><b>9.6</b> Regularización Ridge</a><ul>
<li class="chapter" data-level="9.6.1" data-path="regularizacion.html"><a href="regularizacion.html#seleccion-de-coeficiente-de-regularizacion"><i class="fa fa-check"></i><b>9.6.1</b> Selección de coeficiente de regularización</a></li>
</ul></li>
<li class="chapter" data-level="9.7" data-path="regularizacion.html"><a href="regularizacion.html#regularizacion-lasso"><i class="fa fa-check"></i><b>9.7</b> Regularización Lasso</a></li>
<li class="chapter" data-level="9.8" data-path="regularizacion.html"><a href="regularizacion.html#tarea-7"><i class="fa fa-check"></i><b>9.8</b> Tarea</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="modelos-lineales-generalizados.html"><a href="modelos-lineales-generalizados.html"><i class="fa fa-check"></i><b>10</b> Modelos lineales generalizados</a><ul>
<li class="chapter" data-level="10.1" data-path="modelos-lineales-generalizados.html"><a href="modelos-lineales-generalizados.html#regresion-lineal-y-logistica"><i class="fa fa-check"></i><b>10.1</b> Regresión lineal y logística</a></li>
<li class="chapter" data-level="10.2" data-path="modelos-lineales-generalizados.html"><a href="modelos-lineales-generalizados.html#otros-modelos"><i class="fa fa-check"></i><b>10.2</b> Otros modelos</a></li>
<li class="chapter" data-level="10.3" data-path="modelos-lineales-generalizados.html"><a href="modelos-lineales-generalizados.html#ejemplo-accidentes-de-trafico"><i class="fa fa-check"></i><b>10.3</b> Ejemplo: accidentes de tráfico</a></li>
<li class="chapter" data-level="10.4" data-path="modelos-lineales-generalizados.html"><a href="modelos-lineales-generalizados.html#interpretacion-de-coeficientes-poisson"><i class="fa fa-check"></i><b>10.4</b> Interpretación de coeficientes Poisson</a></li>
<li class="chapter" data-level="10.5" data-path="modelos-lineales-generalizados.html"><a href="modelos-lineales-generalizados.html#diferencias-entre-el-modelo-binomial-y-poisson"><i class="fa fa-check"></i><b>10.5</b> Diferencias entre el modelo binomial y Poisson</a></li>
<li class="chapter" data-level="10.6" data-path="modelos-lineales-generalizados.html"><a href="modelos-lineales-generalizados.html#ejemplo-fertilidad-en-fiji"><i class="fa fa-check"></i><b>10.6</b> Ejemplo: fertilidad en Fiji</a></li>
<li class="chapter" data-level="10.7" data-path="modelos-lineales-generalizados.html"><a href="modelos-lineales-generalizados.html#variable-de-expuestos-offset"><i class="fa fa-check"></i><b>10.7</b> Variable de expuestos (offset)</a></li>
<li class="chapter" data-level="10.8" data-path="modelos-lineales-generalizados.html"><a href="modelos-lineales-generalizados.html#ejemplos-seguros"><i class="fa fa-check"></i><b>10.8</b> Ejemplos: seguros</a><ul>
<li class="chapter" data-level="" data-path="modelos-lineales-generalizados.html"><a href="modelos-lineales-generalizados.html#numero-de-expuestos-interpretacion"><i class="fa fa-check"></i>Número de expuestos (interpretación)</a></li>
</ul></li>
<li class="chapter" data-level="10.9" data-path="modelos-lineales-generalizados.html"><a href="modelos-lineales-generalizados.html#ejemplo-arboles"><i class="fa fa-check"></i><b>10.9</b> Ejemplo: árboles</a></li>
<li class="chapter" data-level="10.10" data-path="modelos-lineales-generalizados.html"><a href="modelos-lineales-generalizados.html#sobredispersion"><i class="fa fa-check"></i><b>10.10</b> Sobredispersión</a></li>
<li class="chapter" data-level="10.11" data-path="modelos-lineales-generalizados.html"><a href="modelos-lineales-generalizados.html#ejemplo-numero-de-publicaciones"><i class="fa fa-check"></i><b>10.11</b> Ejemplo: número de publicaciones</a></li>
<li class="chapter" data-level="10.12" data-path="modelos-lineales-generalizados.html"><a href="modelos-lineales-generalizados.html#tarea-8"><i class="fa fa-check"></i><b>10.12</b> Tarea</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="discriminante-lineal-lda-1.html"><a href="discriminante-lineal-lda-1.html"><i class="fa fa-check"></i><b>11</b> Discriminante Lineal (LDA) 1</a><ul>
<li class="chapter" data-level="11.1" data-path="discriminante-lineal-lda-1.html"><a href="discriminante-lineal-lda-1.html#problemas-de-clasificacion"><i class="fa fa-check"></i><b>11.1</b> Problemas de clasificación</a></li>
<li class="chapter" data-level="11.2" data-path="discriminante-lineal-lda-1.html"><a href="discriminante-lineal-lda-1.html#funciones-de-discriminante"><i class="fa fa-check"></i><b>11.2</b> Funciones de discriminante</a></li>
<li class="chapter" data-level="11.3" data-path="discriminante-lineal-lda-1.html"><a href="discriminante-lineal-lda-1.html#regresion-lineal-en-una-matriz-indicadora"><i class="fa fa-check"></i><b>11.3</b> Regresión lineal en una matriz indicadora</a></li>
<li class="chapter" data-level="11.4" data-path="discriminante-lineal-lda-1.html"><a href="discriminante-lineal-lda-1.html#discriminante-lineal-de-fisher"><i class="fa fa-check"></i><b>11.4</b> Discriminante lineal de Fisher</a><ul>
<li class="chapter" data-level="11.4.1" data-path="discriminante-lineal-lda-1.html"><a href="discriminante-lineal-lda-1.html#ejemplo-separacion-entre-clases"><i class="fa fa-check"></i><b>11.4.1</b> Ejemplo: separación entre clases</a></li>
<li class="chapter" data-level="11.4.2" data-path="discriminante-lineal-lda-1.html"><a href="discriminante-lineal-lda-1.html#ejemplo-iris-de-fisher"><i class="fa fa-check"></i><b>11.4.2</b> Ejemplo: iris de Fisher</a></li>
</ul></li>
<li class="chapter" data-level="11.5" data-path="discriminante-lineal-lda-1.html"><a href="discriminante-lineal-lda-1.html#tarea-9"><i class="fa fa-check"></i><b>11.5</b> Tarea</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="discriminante-lineal-lda-2.html"><a href="discriminante-lineal-lda-2.html"><i class="fa fa-check"></i><b>12</b> Discriminante Lineal (LDA) 2</a><ul>
<li class="chapter" data-level="12.1" data-path="discriminante-lineal-lda-2.html"><a href="discriminante-lineal-lda-2.html#aplicaciones"><i class="fa fa-check"></i><b>12.1</b> Aplicaciones</a></li>
<li class="chapter" data-level="12.2" data-path="discriminante-lineal-lda-2.html"><a href="discriminante-lineal-lda-2.html#ejemplo-vinos"><i class="fa fa-check"></i><b>12.2</b> Ejemplo: vinos</a></li>
<li class="chapter" data-level="12.3" data-path="discriminante-lineal-lda-2.html"><a href="discriminante-lineal-lda-2.html#ejemplo-admisiones-al-mba"><i class="fa fa-check"></i><b>12.3</b> Ejemplo: admisiones al MBA</a></li>
<li class="chapter" data-level="12.4" data-path="discriminante-lineal-lda-2.html"><a href="discriminante-lineal-lda-2.html#repaso-1"><i class="fa fa-check"></i><b>12.4</b> Repaso</a><ul>
<li><a href="discriminante-lineal-lda-2.html#caso-k2">Caso <span class="math inline">\(k=2\)</span></a></li>
</ul></li>
<li class="chapter" data-level="12.5" data-path="discriminante-lineal-lda-2.html"><a href="discriminante-lineal-lda-2.html#supuestos-probabilisticos"><i class="fa fa-check"></i><b>12.5</b> Supuestos probabilísticos</a></li>
<li class="chapter" data-level="12.6" data-path="discriminante-lineal-lda-2.html"><a href="discriminante-lineal-lda-2.html#relacion-con-minimos-cuadrados"><i class="fa fa-check"></i><b>12.6</b> Relación con mínimos cuadrados</a></li>
<li class="chapter" data-level="12.7" data-path="discriminante-lineal-lda-2.html"><a href="discriminante-lineal-lda-2.html#tarea-10"><i class="fa fa-check"></i><b>12.7</b> Tarea</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="componentes-principales-1.html"><a href="componentes-principales-1.html"><i class="fa fa-check"></i><b>13</b> Componentes Principales 1</a><ul>
<li class="chapter" data-level="13.1" data-path="componentes-principales-1.html"><a href="componentes-principales-1.html#motivacion"><i class="fa fa-check"></i><b>13.1</b> Motivación</a></li>
<li class="chapter" data-level="13.2" data-path="componentes-principales-1.html"><a href="componentes-principales-1.html#formulacion-de-maxima-varianza"><i class="fa fa-check"></i><b>13.2</b> Formulación de máxima varianza</a></li>
<li class="chapter" data-level="13.3" data-path="componentes-principales-1.html"><a href="componentes-principales-1.html#formulacion-de-error-minimo"><i class="fa fa-check"></i><b>13.3</b> Formulación de error mínimo</a></li>
<li class="chapter" data-level="13.4" data-path="componentes-principales-1.html"><a href="componentes-principales-1.html#aplicaciones-de-pca"><i class="fa fa-check"></i><b>13.4</b> Aplicaciones de PCA</a><ul>
<li class="chapter" data-level="13.4.1" data-path="componentes-principales-1.html"><a href="componentes-principales-1.html#compresion-de-datos"><i class="fa fa-check"></i><b>13.4.1</b> Compresión de datos</a></li>
<li class="chapter" data-level="13.4.2" data-path="componentes-principales-1.html"><a href="componentes-principales-1.html#ejemplo-compresion-de-una-imagen"><i class="fa fa-check"></i><b>13.4.2</b> Ejemplo: compresión de una imagen</a></li>
</ul></li>
<li class="chapter" data-level="13.5" data-path="componentes-principales-1.html"><a href="componentes-principales-1.html#tarea-11"><i class="fa fa-check"></i><b>13.5</b> Tarea</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="componentes-principales-2.html"><a href="componentes-principales-2.html"><i class="fa fa-check"></i><b>14</b> Componentes Principales 2</a><ul>
<li class="chapter" data-level="14.1" data-path="componentes-principales-2.html"><a href="componentes-principales-2.html#pca-probabilistico-y-analisis-de-factores"><i class="fa fa-check"></i><b>14.1</b> PCA probabilístico y Análisis de Factores</a><ul>
<li class="chapter" data-level="14.1.1" data-path="componentes-principales-2.html"><a href="componentes-principales-2.html#analisis-de-factores"><i class="fa fa-check"></i><b>14.1.1</b> Análisis de factores</a></li>
</ul></li>
<li class="chapter" data-level="14.2" data-path="componentes-principales-2.html"><a href="componentes-principales-2.html#analisis-de-factores-descripcion-tradicional"><i class="fa fa-check"></i><b>14.2</b> Análisis de factores (descripción tradicional)</a><ul>
<li class="chapter" data-level="14.2.1" data-path="componentes-principales-2.html"><a href="componentes-principales-2.html#el-modelo"><i class="fa fa-check"></i><b>14.2.1</b> El modelo</a></li>
<li class="chapter" data-level="14.2.2" data-path="componentes-principales-2.html"><a href="componentes-principales-2.html#estimacion-del-modelo"><i class="fa fa-check"></i><b>14.2.2</b> Estimación del modelo</a></li>
<li class="chapter" data-level="14.2.3" data-path="componentes-principales-2.html"><a href="componentes-principales-2.html#analisis-de-factores-de-maxima-verosimilitud"><i class="fa fa-check"></i><b>14.2.3</b> Análisis de factores de máxima verosimilitud</a></li>
<li class="chapter" data-level="14.2.4" data-path="componentes-principales-2.html"><a href="componentes-principales-2.html#evaluacion-del-modelo"><i class="fa fa-check"></i><b>14.2.4</b> Evaluación del modelo</a></li>
<li class="chapter" data-level="14.2.5" data-path="componentes-principales-2.html"><a href="componentes-principales-2.html#visualizacion"><i class="fa fa-check"></i><b>14.2.5</b> Visualización</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="componentes-principales-2.html"><a href="componentes-principales-2.html#tarea-12"><i class="fa fa-check"></i><b>14.3</b> Tarea</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="correlacion-canonica-cca.html"><a href="correlacion-canonica-cca.html"><i class="fa fa-check"></i><b>15</b> Correlación Canónica (CCA)</a><ul>
<li class="chapter" data-level="15.1" data-path="correlacion-canonica-cca.html"><a href="correlacion-canonica-cca.html#cca-vs-pca"><i class="fa fa-check"></i><b>15.1</b> CCA vs PCA</a></li>
<li class="chapter" data-level="15.2" data-path="correlacion-canonica-cca.html"><a href="correlacion-canonica-cca.html#variables-y-correlaciones-canonicas"><i class="fa fa-check"></i><b>15.2</b> Variables y correlaciones canónicas</a><ul>
<li class="chapter" data-level="15.2.1" data-path="correlacion-canonica-cca.html"><a href="correlacion-canonica-cca.html#combinaciones-lineaes-de-factores"><i class="fa fa-check"></i><b>15.2.1</b> Combinaciones lineaes de factores</a></li>
<li class="chapter" data-level="15.2.2" data-path="correlacion-canonica-cca.html"><a href="correlacion-canonica-cca.html#ejemplo-simple"><i class="fa fa-check"></i><b>15.2.2</b> Ejemplo simple</a></li>
</ul></li>
<li class="chapter" data-level="15.3" data-path="correlacion-canonica-cca.html"><a href="correlacion-canonica-cca.html#ejemplo-test-psicologico"><i class="fa fa-check"></i><b>15.3</b> Ejemplo: test psicológico</a></li>
<li class="chapter" data-level="15.4" data-path="correlacion-canonica-cca.html"><a href="correlacion-canonica-cca.html#ejemplo-fenomenos-meteorologicos"><i class="fa fa-check"></i><b>15.4</b> Ejemplo: fenómenos meteorológicos</a></li>
<li class="chapter" data-level="15.5" data-path="correlacion-canonica-cca.html"><a href="correlacion-canonica-cca.html#tarea-13"><i class="fa fa-check"></i><b>15.5</b> Tarea</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="conglomerados-clustering-1.html"><a href="conglomerados-clustering-1.html"><i class="fa fa-check"></i><b>16</b> Conglomerados (clustering) 1</a><ul>
<li class="chapter" data-level="16.1" data-path="conglomerados-clustering-1.html"><a href="conglomerados-clustering-1.html#introduccion"><i class="fa fa-check"></i><b>16.1</b> Introducción</a><ul>
<li class="chapter" data-level="" data-path="conglomerados-clustering-1.html"><a href="conglomerados-clustering-1.html#ejemplo-7"><i class="fa fa-check"></i>Ejemplo</a></li>
</ul></li>
<li class="chapter" data-level="16.2" data-path="conglomerados-clustering-1.html"><a href="conglomerados-clustering-1.html#enfoques-combinatorio-y-basado-en-modelos."><i class="fa fa-check"></i><b>16.2</b> Enfoques: combinatorio y basado en modelos.</a></li>
<li class="chapter" data-level="16.3" data-path="conglomerados-clustering-1.html"><a href="conglomerados-clustering-1.html#k-medias"><i class="fa fa-check"></i><b>16.3</b> K-medias</a><ul>
<li class="chapter" data-level="" data-path="conglomerados-clustering-1.html"><a href="conglomerados-clustering-1.html#algoritmo-de-k-medias"><i class="fa fa-check"></i>Algoritmo de k-medias</a></li>
<li class="chapter" data-level="" data-path="conglomerados-clustering-1.html"><a href="conglomerados-clustering-1.html#ejemplo-8"><i class="fa fa-check"></i>Ejemplo</a></li>
<li><a href="conglomerados-clustering-1.html#usando-la-funcion-kmeans">Usando la funcion <code>kmeans</code></a></li>
</ul></li>
<li class="chapter" data-level="16.4" data-path="conglomerados-clustering-1.html"><a href="conglomerados-clustering-1.html#seleccion-de-numero-de-clusters."><i class="fa fa-check"></i><b>16.4</b> Selección de número de clusters.</a><ul>
<li class="chapter" data-level="" data-path="conglomerados-clustering-1.html"><a href="conglomerados-clustering-1.html#variacion-dentro-de-clusters-para-distintas-soluciones"><i class="fa fa-check"></i>Variación dentro de clusters para distintas soluciones</a></li>
<li class="chapter" data-level="16.4.1" data-path="conglomerados-clustering-1.html"><a href="conglomerados-clustering-1.html#criterios-especificos"><i class="fa fa-check"></i><b>16.4.1</b> Criterios específicos</a></li>
</ul></li>
<li class="chapter" data-level="16.5" data-path="conglomerados-clustering-1.html"><a href="conglomerados-clustering-1.html#dificultades-en-segmentacionclustering."><i class="fa fa-check"></i><b>16.5</b> Dificultades en segmentación/clustering.</a><ul>
<li class="chapter" data-level="16.5.1" data-path="conglomerados-clustering-1.html"><a href="conglomerados-clustering-1.html#estructuras-no-compactas"><i class="fa fa-check"></i><b>16.5.1</b> Estructuras no compactas</a></li>
<li class="chapter" data-level="16.5.2" data-path="conglomerados-clustering-1.html"><a href="conglomerados-clustering-1.html#existencia-o-no-de-grupos-naturales"><i class="fa fa-check"></i><b>16.5.2</b> Existencia o no de grupos “naturales”</a></li>
<li class="chapter" data-level="" data-path="conglomerados-clustering-1.html"><a href="conglomerados-clustering-1.html#grupos-en-dimension-alta"><i class="fa fa-check"></i>Grupos en dimensión alta</a></li>
<li class="chapter" data-level="" data-path="conglomerados-clustering-1.html"><a href="conglomerados-clustering-1.html#dificultades-en-la-seleccion-de-metrica"><i class="fa fa-check"></i>Dificultades en la selección de métrica</a></li>
</ul></li>
<li class="chapter" data-level="16.6" data-path="conglomerados-clustering-1.html"><a href="conglomerados-clustering-1.html#tarea-14"><i class="fa fa-check"></i><b>16.6</b> Tarea</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="conglomerados-clustering-2.html"><a href="conglomerados-clustering-2.html"><i class="fa fa-check"></i><b>17</b> Conglomerados (clustering) 2</a><ul>
<li class="chapter" data-level="17.1" data-path="conglomerados-clustering-2.html"><a href="conglomerados-clustering-2.html#clustering-jerarquico"><i class="fa fa-check"></i><b>17.1</b> Clustering jerárquico</a></li>
<li class="chapter" data-level="17.2" data-path="conglomerados-clustering-2.html"><a href="conglomerados-clustering-2.html#metodos-de-enlace-cluster-linkage"><i class="fa fa-check"></i><b>17.2</b> Métodos de enlace (Cluster Linkage)</a><ul>
<li class="chapter" data-level="17.2.1" data-path="conglomerados-clustering-2.html"><a href="conglomerados-clustering-2.html#enlace-simple"><i class="fa fa-check"></i><b>17.2.1</b> Enlace simple</a></li>
<li class="chapter" data-level="17.2.2" data-path="conglomerados-clustering-2.html"><a href="conglomerados-clustering-2.html#enlace-completo"><i class="fa fa-check"></i><b>17.2.2</b> Enlace completo</a></li>
<li class="chapter" data-level="17.2.3" data-path="conglomerados-clustering-2.html"><a href="conglomerados-clustering-2.html#enlace-promedio"><i class="fa fa-check"></i><b>17.2.3</b> Enlace promedio</a></li>
</ul></li>
<li class="chapter" data-level="17.3" data-path="conglomerados-clustering-2.html"><a href="conglomerados-clustering-2.html#ejemplo-genes-de-tejidos"><i class="fa fa-check"></i><b>17.3</b> Ejemplo: genes de tejidos</a></li>
<li class="chapter" data-level="17.4" data-path="conglomerados-clustering-2.html"><a href="conglomerados-clustering-2.html#mapas-de-calor"><i class="fa fa-check"></i><b>17.4</b> Mapas de calor</a></li>
<li class="chapter" data-level="17.5" data-path="conglomerados-clustering-2.html"><a href="conglomerados-clustering-2.html#metodo-de-ward"><i class="fa fa-check"></i><b>17.5</b> Método de Ward</a></li>
<li class="chapter" data-level="17.6" data-path="conglomerados-clustering-2.html"><a href="conglomerados-clustering-2.html#tarea-15"><i class="fa fa-check"></i><b>17.6</b> Tarea</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="referencias.html"><a href="referencias.html"><i class="fa fa-check"></i>Referencias</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Publicado con bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Estadística Aplicada III</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="discriminante-lineal-lda-1" class="section level1">
<h1><span class="header-section-number">Clase 11</span> Discriminante Lineal (LDA) 1</h1>
<style>
  .espacio {
    margin-bottom: 1cm;
  }
</style>
<style>
  .espacio3 {
    margin-bottom: 3cm;
  }
</style>
<p class="espacio">
</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(tidyverse)</code></pre></div>
<div id="problemas-de-clasificacion" class="section level2">
<h2><span class="header-section-number">11.1</span> Problemas de clasificación</h2>
<p>En los problemas de clasificación deseamos predecir categorías de clase discretas, o más generalmente las probabilidades, que se encuentran entre 0 y 1.</p>
<p>Para lograr predecir probabilidades, consideramos una generalización del modelo linea en el cual transformamos la función lineal de <span class="math inline">\(\beta\)</span> usando una función no lineal <span class="math inline">\(g^{-1}\)</span> tal que <span class="math display">\[
y_i = g^{-1}(x_i^T\beta).
\]</span></p>
<p>A <span class="math inline">\(g\)</span> la conocemos como función liga.</p>
<p>Para clasificar utilizamos las <em>superficies de decisión</em> que corresponden a <span class="math display">\[
y_i(\beta) = \mbox{constante},
\]</span> de modo que <span class="math display">\[
x_i^T\beta = \mbox{constante}
\]</span> y, por lo tanto, las superficies de decisión son funciones lineales de <span class="math inline">\(x\)</span>, incluso si la función <span class="math inline">\(g\)</span> no es lineal. Por esta razón, los modelos descritos se llaman modelos lineales generalizados.</p>
</div>
<div id="funciones-de-discriminante" class="section level2">
<h2><span class="header-section-number">11.2</span> Funciones de discriminante</h2>
<p>Definimos un discriminante (clasificador) lineal así:</p>
<p><span class="math display">\[
y_i = x_i^T\beta
\]</span> lo denotaremos por <span class="math display">\[
y(x) = w^T x+ w_0
\]</span> porque vemos <span class="math inline">\(w_0\)</span> como el umbral de tal forma que un vector de entrada <span class="math inline">\(x\)</span> se asigna a la clase 1 cuando <span class="math inline">\(y(x)&gt;0\)</span> y a la clase 2 en otro caso.</p>
<p class="espacio">
</p>

<div class="information">
La <em>superficie de decisión</em> está definida, por lo tanto, por la ecuación <span class="math inline">\(y(x) = 0\)</span>, que corresponde a un hiperplano de <span class="math inline">\(D-1\)</span> dimensiones dentro del conjunto de entrada de <span class="math inline">\(D\)</span> dimensiones.
</div>

<p><br></p>
<p>Consideremos dos puntos <span class="math inline">\(x_A\)</span> y <span class="math inline">\(x_B\)</span> en la superficie de decisión.</p>
<p>Como <span class="math display">\[
y(x_A) = y(x_B) = 0, 
\]</span> entonces <span class="math display">\[
w^T(x_A −x_B) = 0.
\]</span> Por lo tanto, el vector <span class="math inline">\(w\)</span> es ortogonal a todo vector en la superficie de decisión, y así <span class="math inline">\(w\)</span> determina la orientación de la superficie.</p>
<p>Similarmente, si <span class="math inline">\(x\)</span> está en la superficie de decisión, entonces <span class="math inline">\(y(x)=0\)</span>, y entonces, la distancia del origen a la superficie de decisión es:</p>
<p><span class="math display">\[
\dfrac{w^Tx}{\|{w}\|} = -\dfrac{w_0}{\|{w}\|}.
\]</span></p>
<p><img src="figuras/lda_1.png" width="70%" style="display: block; margin: auto;" /></p>
</div>
<div id="regresion-lineal-en-una-matriz-indicadora" class="section level2">
<h2><span class="header-section-number">11.3</span> Regresión lineal en una matriz indicadora</h2>
<p>Supongamos que <span class="math inline">\(Y\)</span> es una matriz indicadora donde <span class="math inline">\(Y_{ij}\)</span> es <span class="math inline">\(1\)</span> si la <span class="math inline">\(i\)</span>-ésima obsevación pertenece a la categoría <span class="math inline">\(j\)</span> y <span class="math inline">\(0\)</span> en otro caso.</p>
<p><span class="math display">\[
\hat{W} = (X^TX)^{−1}X^TY.
\]</span></p>
<p>Si <span class="math inline">\(\tilde{x}\)</span> es un vector de entradas, entonces <span class="math display">\[
y(x) = \hat{W}^T\tilde{x}
\]</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(tidyverse)
<span class="kw">library</span>(matlib)

<span class="kw">set.seed</span>(<span class="dv">186923</span>)
n &lt;-<span class="st"> </span><span class="dv">300</span>

x1 &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="kw">rnorm</span>(n<span class="op">/</span><span class="dv">3</span>,<span class="op">-</span><span class="dv">5</span>), <span class="kw">rnorm</span>(n<span class="op">/</span><span class="dv">3</span>, <span class="dv">0</span>, <span class="fl">1.5</span>), <span class="kw">rnorm</span>(n<span class="op">/</span><span class="dv">3</span>, <span class="dv">5</span>))
x2 &lt;-<span class="st"> </span>x1 <span class="op">+</span><span class="st"> </span><span class="kw">rnorm</span>(n, <span class="dt">sd =</span> <span class="dv">2</span>) <span class="op">+</span><span class="st"> </span><span class="kw">c</span>(<span class="kw">rep</span>(<span class="op">-</span><span class="dv">5</span>, n<span class="op">/</span><span class="dv">3</span>), <span class="kw">rep</span>(<span class="dv">0</span>, n<span class="op">/</span><span class="dv">3</span>), <span class="kw">rep</span>(<span class="dv">5</span>, n<span class="op">/</span><span class="dv">3</span>))
y &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="kw">rep</span>(<span class="st">&quot;a&quot;</span>,n<span class="op">/</span><span class="dv">3</span>),<span class="kw">rep</span>(<span class="st">&quot;b&quot;</span>,n<span class="op">/</span><span class="dv">3</span>),<span class="kw">rep</span>(<span class="st">&quot;c&quot;</span>,n<span class="op">/</span><span class="dv">3</span>))
df &lt;-<span class="st"> </span><span class="kw">data.frame</span>(x1, x2, y)

Y &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="dt">nrow =</span> n, <span class="dt">ncol =</span> <span class="dv">3</span>)
Y[,<span class="dv">1</span>] &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="kw">rep</span>(<span class="dv">1</span>,n<span class="op">/</span><span class="dv">3</span>),<span class="kw">rep</span>(<span class="dv">0</span>,<span class="dv">2</span><span class="op">*</span>n<span class="op">/</span><span class="dv">3</span>))
Y[,<span class="dv">2</span>] &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="kw">rep</span>(<span class="dv">0</span>,n<span class="op">/</span><span class="dv">3</span>),<span class="kw">rep</span>(<span class="dv">1</span>,n<span class="op">/</span><span class="dv">3</span>),<span class="kw">rep</span>(<span class="dv">0</span>,n<span class="op">/</span><span class="dv">3</span>))
Y[,<span class="dv">3</span>] &lt;-<span class="st"> </span><span class="dv">1</span> <span class="op">-</span><span class="st"> </span>Y[,<span class="dv">1</span>] <span class="op">-</span><span class="st"> </span>Y[,<span class="dv">2</span>]
df<span class="op">$</span>y1 &lt;-<span class="st"> </span>Y[,<span class="dv">1</span>]
df<span class="op">$</span>y2 &lt;-<span class="st"> </span>Y[,<span class="dv">2</span>]
df<span class="op">$</span>y3 &lt;-<span class="st"> </span>Y[,<span class="dv">3</span>]

X &lt;-<span class="st"> </span><span class="kw">as.matrix</span>(df[,<span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>)])
p &lt;-<span class="st"> </span>X <span class="op">%*%</span><span class="st"> </span><span class="kw">inv</span>(<span class="kw">t</span>(X) <span class="op">%*%</span><span class="st"> </span>X) <span class="op">%*%</span><span class="st"> </span><span class="kw">t</span>(X) <span class="op">%*%</span><span class="st"> </span>Y
df<span class="op">$</span>p1 &lt;-<span class="st"> </span>p[,<span class="dv">1</span>]
df<span class="op">$</span>p2 &lt;-<span class="st"> </span>p[,<span class="dv">2</span>]
df<span class="op">$</span>p3 &lt;-<span class="st"> </span>p[,<span class="dv">3</span>]

<span class="kw">ggplot</span>(df, <span class="kw">aes</span>(<span class="dt">x =</span> x1, <span class="dt">y =</span> x2))<span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">color =</span> y)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">y =</span> p1), <span class="dt">color =</span> <span class="st">&#39;red&#39;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">y =</span> p2), <span class="dt">color =</span> <span class="st">&#39;green&#39;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">y =</span> p3), <span class="dt">color =</span> <span class="st">&#39;blue&#39;</span>)</code></pre></div>
<p><img src="11-lda-1_files/figure-html/unnamed-chunk-5-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>Hay un problema serio con el enfoque de regresión cuando el número de clases <span class="math inline">\(K \geq3\)</span>, y en especial si <span class="math inline">\(K\)</span> es grande. Debido a la naturaleza rígida del modelo de regresión, unas clases pueden enmascarar a otras. Esto lo vemos en la gráfica de arriba con <span class="math inline">\(K = 3\)</span>. Las tres clases están perfectamente separadas por límites de decisión lineales, sin embargo, la regresión lineal pierde por completo a la clase de en medio.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lm_<span class="dv">1</span> &lt;-<span class="st"> </span><span class="kw">lm</span>(y1 <span class="op">~</span><span class="st"> </span>x1 <span class="op">+</span><span class="st"> </span>x2, <span class="dt">data =</span> df)
lm_<span class="dv">2</span> &lt;-<span class="st"> </span><span class="kw">lm</span>(y2 <span class="op">~</span><span class="st"> </span>x1 <span class="op">+</span><span class="st"> </span>x2, <span class="dt">data =</span> df)
df<span class="op">$</span>pred_<span class="dv">1</span> &lt;-<span class="st"> </span><span class="kw">predict</span>(lm_<span class="dv">1</span>)
df<span class="op">$</span>pred_<span class="dv">2</span> &lt;-<span class="st"> </span><span class="kw">predict</span>(lm_<span class="dv">2</span>)
df<span class="op">$</span>pred_<span class="dv">3</span> &lt;-<span class="st"> </span><span class="dv">1</span> <span class="op">-</span><span class="st"> </span>df<span class="op">$</span>pred_<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>df<span class="op">$</span>pred_<span class="dv">2</span></code></pre></div>
<p>Obtenemos la predicción tomando el máximo de cada renglón:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">df<span class="op">$</span>pred &lt;-<span class="st"> </span><span class="kw">ifelse</span>(df<span class="op">$</span>pred_<span class="dv">1</span> <span class="op">&gt;</span><span class="st"> </span>df<span class="op">$</span>pred_<span class="dv">2</span> <span class="op">&amp;</span><span class="st"> </span>df<span class="op">$</span>pred_<span class="dv">1</span> <span class="op">&gt;</span><span class="st"> </span>df<span class="op">$</span>pred_<span class="dv">3</span>, <span class="st">&#39;a&#39;</span>, 
                  <span class="kw">ifelse</span>(df<span class="op">$</span>pred_<span class="dv">2</span> <span class="op">&gt;</span><span class="st"> </span>df<span class="op">$</span>pred_<span class="dv">1</span> <span class="op">&amp;</span><span class="st"> </span>df<span class="op">$</span>pred_<span class="dv">2</span> <span class="op">&gt;</span><span class="st"> </span>df<span class="op">$</span>pred_<span class="dv">3</span>, <span class="st">&#39;b&#39;</span>, <span class="st">&#39;c&#39;</span>))</code></pre></div>
<p>Podemos hacer una gráfica de las predicciones en este caso de <span class="math inline">\(x_1\)</span> contra los ajustados por el modelo lineal:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(df, <span class="kw">aes</span>(<span class="dt">x=</span>x1, <span class="dt">y =</span> pred_<span class="dv">1</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">color =</span> <span class="st">&#39;red&#39;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">x=</span>x1, <span class="dt">y =</span> pred_<span class="dv">2</span>), <span class="dt">color =</span> <span class="st">&#39;green&#39;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">x=</span>x1, <span class="dt">y =</span> pred_<span class="dv">3</span>), <span class="dt">color =</span> <span class="st">&#39;blue&#39;</span>)</code></pre></div>
<p><img src="11-lda-1_files/figure-html/unnamed-chunk-8-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>Comparamos contra los observados y calculamos el error:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(df<span class="op">$</span>pred <span class="op">==</span><span class="st"> </span>df<span class="op">$</span>y)
<span class="co">#&gt; [1] 0.24</span></code></pre></div>
<p><br></p>
<p>Si utilizamos un modelo lineal con términos cuadráticos entonces el ajuste lo haríamos de esta manera:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lm_1_q &lt;-<span class="st"> </span><span class="kw">lm</span>(y1 <span class="op">~</span><span class="st"> </span><span class="kw">poly</span>(x1 <span class="op">+</span><span class="st"> </span>x2, <span class="dv">2</span>), <span class="dt">data =</span> df)
lm_2_q &lt;-<span class="st"> </span><span class="kw">lm</span>(y2 <span class="op">~</span><span class="st"> </span><span class="kw">poly</span>(x1 <span class="op">+</span><span class="st"> </span>x2, <span class="dv">2</span>), <span class="dt">data =</span> df)
lm_3_q &lt;-<span class="st"> </span><span class="kw">lm</span>(y3 <span class="op">~</span><span class="st"> </span><span class="kw">poly</span>(x1 <span class="op">+</span><span class="st"> </span>x2, <span class="dv">2</span>), <span class="dt">data =</span> df)
df<span class="op">$</span>pred_1_q &lt;-<span class="st"> </span><span class="kw">predict</span>(lm_1_q)
df<span class="op">$</span>pred_2_q &lt;-<span class="st"> </span><span class="kw">predict</span>(lm_2_q)
df<span class="op">$</span>pred_3_q &lt;-<span class="st"> </span><span class="kw">predict</span>(lm_3_q)</code></pre></div>
<p>Obtenemos nuevamente la predicción tomando el máximo de cada renglón:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">df<span class="op">$</span>pred_q &lt;-<span class="st"> </span><span class="kw">ifelse</span>(df<span class="op">$</span>pred_1_q <span class="op">&gt;</span><span class="st"> </span>df<span class="op">$</span>pred_2_q <span class="op">&amp;</span><span class="st"> </span>df<span class="op">$</span>pred_1_q <span class="op">&gt;</span><span class="st"> </span>df<span class="op">$</span>pred_3_q, <span class="st">&#39;a&#39;</span>, 
                  <span class="kw">ifelse</span>(df<span class="op">$</span>pred_2_q <span class="op">&gt;</span><span class="st"> </span>df<span class="op">$</span>pred_1_q <span class="op">&amp;</span><span class="st"> </span>df<span class="op">$</span>pred_2_q <span class="op">&gt;</span><span class="st"> </span>df<span class="op">$</span>pred_3_q, <span class="st">&#39;b&#39;</span>, <span class="st">&#39;c&#39;</span>))</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(df, <span class="kw">aes</span>(<span class="dt">x=</span>x2, <span class="dt">y =</span> pred_1_q)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">color =</span> <span class="st">&#39;red&#39;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">x=</span>x2, <span class="dt">y =</span> pred_2_q), <span class="dt">color =</span> <span class="st">&#39;green&#39;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">x=</span>x2, <span class="dt">y =</span> pred_3_q), <span class="dt">color =</span> <span class="st">&#39;blue&#39;</span>)</code></pre></div>
<p><img src="11-lda-1_files/figure-html/unnamed-chunk-12-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>Comparamos contra los observados y calculamos el error:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(df<span class="op">$</span>pred_q <span class="op">==</span><span class="st"> </span>df<span class="op">$</span>y)
<span class="co">#&gt; [1] 0.02</span></code></pre></div>
<p><br></p>
<p>Repetimos una tercera vez pero ahora utilizando regresión logística:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">glm_<span class="dv">1</span> &lt;-<span class="st"> </span><span class="kw">glm</span>(<span class="kw">I</span>(y<span class="op">==</span><span class="st">&#39;a&#39;</span>) <span class="op">~</span><span class="st"> </span>x1 <span class="op">+</span><span class="st"> </span>x2, <span class="dt">family =</span> binomial, <span class="dt">data =</span> df)
<span class="co">#&gt; Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred</span>
glm_<span class="dv">2</span> &lt;-<span class="st"> </span><span class="kw">glm</span>(<span class="kw">I</span>(y<span class="op">==</span><span class="st">&#39;b&#39;</span>) <span class="op">~</span><span class="st"> </span>x1 <span class="op">+</span><span class="st"> </span>x2, <span class="dt">family =</span> binomial, <span class="dt">data =</span> df)
glm_<span class="dv">3</span> &lt;-<span class="st"> </span><span class="kw">glm</span>(<span class="kw">I</span>(y<span class="op">==</span><span class="st">&#39;c&#39;</span>) <span class="op">~</span><span class="st"> </span>x1 <span class="op">+</span><span class="st"> </span>x2, <span class="dt">family =</span> binomial, <span class="dt">data =</span> df)
<span class="co">#&gt; Warning: glm.fit: algorithm did not converge</span>

<span class="co">#&gt; Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred</span>
df<span class="op">$</span>pred1_glm &lt;-<span class="st"> </span><span class="kw">predict</span>(glm_<span class="dv">1</span>, <span class="dt">type =</span> <span class="st">&#39;response&#39;</span>)
df<span class="op">$</span>pred2_glm &lt;-<span class="st"> </span><span class="kw">predict</span>(glm_<span class="dv">2</span>, <span class="dt">type =</span> <span class="st">&#39;response&#39;</span>)
df<span class="op">$</span>pred3_glm &lt;-<span class="st"> </span><span class="kw">predict</span>(glm_<span class="dv">3</span>, <span class="dt">type =</span> <span class="st">&#39;response&#39;</span>)</code></pre></div>
<p>Calculamos las predicciones de acuerdo a este modelo logístico:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">df<span class="op">$</span>pred_glm &lt;-<span class="st"> </span><span class="kw">ifelse</span>(df<span class="op">$</span>pred1_glm <span class="op">&gt;</span><span class="st"> </span>df<span class="op">$</span>pred2_glm <span class="op">&amp;</span><span class="st"> </span>df<span class="op">$</span>pred1_glm <span class="op">&gt;</span><span class="st"> </span>df<span class="op">$</span>pred3_glm, <span class="st">&#39;a&#39;</span>, 
                  <span class="kw">ifelse</span>(df<span class="op">$</span>pred2_glm <span class="op">&gt;</span><span class="st"> </span>df<span class="op">$</span>pred1_glm <span class="op">&amp;</span><span class="st"> </span>df<span class="op">$</span>pred2_glm <span class="op">&gt;</span><span class="st"> </span>df<span class="op">$</span>pred3_glm, <span class="st">&#39;b&#39;</span>, <span class="st">&#39;c&#39;</span>))</code></pre></div>
<p>Calculamos el error:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(df<span class="op">$</span>pred_glm <span class="op">==</span><span class="st"> </span>df<span class="op">$</span>y)
<span class="co">#&gt; [1] 0.01</span></code></pre></div>
</div>
<div id="discriminante-lineal-de-fisher" class="section level2">
<h2><span class="header-section-number">11.4</span> Discriminante lineal de Fisher</h2>
<p>Una forma de ver un modelo de clasificación lineal es en términos de <em>reducción de dimensionalidad</em>. Esto se refiere a la extracción de características de los datos que los transforma de un espacio de dimensión alta a un espacio de dimensión baja, usualmente <span class="math inline">\(2\)</span> ó <span class="math inline">\(3\)</span>.</p>
<p>Consideremos primero el caso de dos clases, y supongamos que tomamos un vector de predictores de dimensión <span class="math inline">\(D\)</span> y lo proyectamos en una dimensión usando la misma función: <span class="math display">\[
y = w^Tx.
\]</span></p>
<p>Si colocamos un umbral y clasificamos como clase 1 si <span class="math inline">\(y\geq-w_0\)</span>, y clase 2 en otro caso, entonces obtenemos nuestro clasificador lineal estándar ya visto antes. En general, la proyección en una dimensión conduce a una pérdida considerable de información, y las clases que están bien separadas en el espacio original de dimensión <span class="math inline">\(D\)</span> pueden superponerse fuertemente en una dimensión.</p>
<p>Sin embargo, ajustando los componentes de <span class="math inline">\(w\)</span>, podemos seleccionar una proyección que maximiza la separación entre clases. Para empezar, consideremos un problema de dos clases en el que hay <span class="math inline">\(N_1\)</span> puntos en la clase 1 y <span class="math inline">\(N_2\)</span> puntos en la clase 2, de modo que los vectores de medias de las dos clases están dados por <span class="math display">\[
m_1 = \dfrac{1}{N_1}\sum_{i\in C_1}x_i,\qquad m_2=\dfrac{1}{N_2}\sum_{i\in C_2}x_i.
\]</span></p>
<p>Podríamos elegir <span class="math inline">\(w\)</span> para maximizar la <em>separación entre clases</em>: <span class="math display">\[
w^T(m_2 − m_1)
\]</span></p>
<p>Sin embargo, esta expresión se puede hacer arbitrariamente grande simplemente aumentando la magnitud de <span class="math inline">\(w\)</span>, entonces se utiliza la restricción <span class="math display">\[
\sum_i{w_i^2}=1
\]</span></p>
<p>Resolvemos usando multiplicadores de Lagrange. Vemos que <span class="math inline">\(w\)</span> es proporcional a <span class="math inline">\(m_2 - m_1\)</span>.</p>
<p>Sin embargo, todavía hay un problema con este enfoque. Esto muestra</p>
<p><img src="figuras/lda_2.png" width="70%" style="display: block; margin: auto;" /></p>
<p>Las dos clases de arriba que están bien separadas en el espacio bidimensional original <span class="math inline">\((x_1, x_2)\)</span> pero se sobrelapan considerablemente cuando se proyectan sobre la línea que une sus medios.</p>
<p>Esta dificultad surge por las covarianzas de las distribuciones de clase no son diagonales. La idea propuesta por Fisher es maximizar una función que:</p>
<ul>
<li><p>separe las observaciones por las medios de clase proyectadas, y al mismo tiempo</p></li>
<li><p>dé una variación pequeña dentro de cada clase.</p></li>
</ul>
<p>La varianza <em>dentro</em> de la clase de los datos transformados de la clase <span class="math inline">\(C_k\)</span> está dada por</p>
<p><span class="math display">\[
s_k = \sum_{i\in C_k}{(y_i - w^Tm_k)^2}.
\]</span> donde <span class="math inline">\(y_i = w^Tx_i\)</span>.</p>
<p>Para el caso de <span class="math inline">\(K=2\)</span> clases, la varianza total dentro de las clases se define como <span class="math inline">\(s_1^2 + s_2^2\)</span>. Se define una cantidad llamada “criterio de Fisher” <span class="math inline">\(J(w)\)</span> que se desea maximizar</p>
<p><span class="math display">\[
\begin{eqnarray*}
J(w) &amp;=&amp; \dfrac{m_2-m_1}{s_1^2+s_2^2} \\
&amp;=&amp; \dfrac{w^TS_Ww}{w^TS_Bw}
\end{eqnarray*}
\]</span> donde <span class="math inline">\(S_B\)</span> es la matriz de covarianzas <em>entre</em> clases <span class="math display">\[
S_B = (m_2 - m_1)(m_2-m_1)^T
\]</span> y <span class="math inline">\(S_W\)</span> es la matriz de covarianzas <em>dentro</em> de las clases <span class="math display">\[
S_W = \sum_{i \in C_1}{(x_i - m_1)(x_i-m_1)^T} + \sum_{i \in C_2}{(x_i - m_2)(x_i-m_2)^T}.
\]</span></p>
<p>Buscamos maximizar <span class="math inline">\(J(w)\)</span> con respecto a <span class="math inline">\(w\)</span> para encontrar los pesos <span class="math inline">\(w\)</span> para el discriminador lineal <span class="math inline">\(y(x)=w^Tx\)</span>.</p>

<div class="nota">
<p><strong>Notas:</strong></p>
<p class="espacio3">
</p>
<ul>
<li><p>Este se conoce como <em>discriminante lineal de Fisher</em>, aunque estrictamente no es un discriminante, sino más bien una elección de dirección específica para la proyección de los datos en una dimensión.</p></li>
<li><p>Sin embargo, los datos proyectados pueden usarse posteriormente para construir un discriminante, eligiendo un umbral <span class="math inline">\(y_0\)</span> para que clasifiquemos un nuevo punto como clase 1 si <span class="math inline">\(y(x)\geq y_0\)</span> y como clase 2 en caso contrario.</p></li>
<li>Podemos modelar las densidades condicionales de clase <span class="math inline">\(p(y|C_k)\)</span> usando distribuciones normales y estimar parámetros por máxima verosimilitud. El supuesto de normalidad se justifica por el teorema del límite central porque <span class="math inline">\(y = w^Tx\)</span> es una suma ponderada de variables aleatorias.
</div>
</li>
</ul>
<p><br></p>
<hr />
<div id="ejemplo-separacion-entre-clases" class="section level3">
<h3><span class="header-section-number">11.4.1</span> Ejemplo: separación entre clases</h3>
<p>Regresamos al ejemplo de arriba pero ahora hacemos el ajuste con discriminante lineal:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(MASS)
lda_<span class="dv">1</span> &lt;-<span class="st"> </span><span class="kw">lda</span>(y <span class="op">~</span><span class="st"> </span>x1 <span class="op">+</span><span class="st"> </span>x2, <span class="dt">data =</span> df)
df<span class="op">$</span>pred_lda &lt;-<span class="st"> </span><span class="kw">predict</span>(lda_<span class="dv">1</span>)<span class="op">$</span>class</code></pre></div>
<p>Vemos nuevamente el error:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(df<span class="op">$</span>pred_lda <span class="op">==</span><span class="st"> </span>df<span class="op">$</span>y)
<span class="co">#&gt; [1] 0.0167</span></code></pre></div>
</div>
<div id="ejemplo-iris-de-fisher" class="section level3">
<h3><span class="header-section-number">11.4.2</span> Ejemplo: iris de Fisher</h3>
<p>El estadístico y biólogo británico Ronald Fisher publicó su artículo de 1936 “El uso de mediciones múltiples en problemas taxonómicos como un ejemplo de análisis discriminante lineal”.</p>
<p>El conjunto de datos consiste de 50 observaciones de <em>cada</em> una de las tres especies de Iris (Iris setosa, Iris virginica e Iris versicolor). Se midieron cuatro características de cada muestra: la longitud y el ancho de los sépalos y pétalos, en centímetros.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">iris <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">sample_n</span>(<span class="dv">10</span>) <span class="op">%&gt;%</span><span class="st"> </span>knitr<span class="op">::</span><span class="kw">kable</span>()</code></pre></div>
<table>
<thead>
<tr class="header">
<th></th>
<th align="right">Sepal.Length</th>
<th align="right">Sepal.Width</th>
<th align="right">Petal.Length</th>
<th align="right">Petal.Width</th>
<th align="left">Species</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>21</td>
<td align="right">5.4</td>
<td align="right">3.4</td>
<td align="right">1.7</td>
<td align="right">0.2</td>
<td align="left">setosa</td>
</tr>
<tr class="even">
<td>113</td>
<td align="right">6.8</td>
<td align="right">3.0</td>
<td align="right">5.5</td>
<td align="right">2.1</td>
<td align="left">virginica</td>
</tr>
<tr class="odd">
<td>1</td>
<td align="right">5.1</td>
<td align="right">3.5</td>
<td align="right">1.4</td>
<td align="right">0.2</td>
<td align="left">setosa</td>
</tr>
<tr class="even">
<td>38</td>
<td align="right">4.9</td>
<td align="right">3.6</td>
<td align="right">1.4</td>
<td align="right">0.1</td>
<td align="left">setosa</td>
</tr>
<tr class="odd">
<td>5</td>
<td align="right">5.0</td>
<td align="right">3.6</td>
<td align="right">1.4</td>
<td align="right">0.2</td>
<td align="left">setosa</td>
</tr>
<tr class="even">
<td>23</td>
<td align="right">4.6</td>
<td align="right">3.6</td>
<td align="right">1.0</td>
<td align="right">0.2</td>
<td align="left">setosa</td>
</tr>
<tr class="odd">
<td>140</td>
<td align="right">6.9</td>
<td align="right">3.1</td>
<td align="right">5.4</td>
<td align="right">2.1</td>
<td align="left">virginica</td>
</tr>
<tr class="even">
<td>2</td>
<td align="right">4.9</td>
<td align="right">3.0</td>
<td align="right">1.4</td>
<td align="right">0.2</td>
<td align="left">setosa</td>
</tr>
<tr class="odd">
<td>145</td>
<td align="right">6.7</td>
<td align="right">3.3</td>
<td align="right">5.7</td>
<td align="right">2.5</td>
<td align="left">virginica</td>
</tr>
<tr class="even">
<td>99</td>
<td align="right">5.1</td>
<td align="right">2.5</td>
<td align="right">3.0</td>
<td align="right">1.1</td>
<td align="left">versicolor</td>
</tr>
</tbody>
</table>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(iris, <span class="kw">aes</span>(Sepal.Length, Sepal.Width, <span class="dt">color =</span> Species)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">shape =</span> Species), <span class="dt">size =</span> <span class="dv">3</span>)</code></pre></div>
<p><img src="11-lda-1_files/figure-html/unnamed-chunk-22-1.png" width="70%" style="display: block; margin: auto;" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(iris, <span class="kw">aes</span>(Petal.Length, Petal.Width, <span class="dt">color =</span> Species)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">shape =</span> Species), <span class="dt">size =</span> <span class="dv">3</span>)</code></pre></div>
<p><img src="11-lda-1_files/figure-html/unnamed-chunk-23-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>En resumen tenemos 4 variables y todas están relacionadas con la especie a la cual pertenece (hay 3 especies):</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(GGally)
<span class="kw">ggpairs</span>(iris, <span class="dt">columns =</span> <span class="dv">1</span><span class="op">:</span><span class="kw">ncol</span>(iris), <span class="dt">title =</span> <span class="st">&quot;&quot;</span>,  
  <span class="dt">axisLabels =</span> <span class="st">&quot;show&quot;</span>, <span class="dt">columnLabels =</span> <span class="kw">colnames</span>(iris))</code></pre></div>
<p><img src="11-lda-1_files/figure-html/unnamed-chunk-24-1.png" width="100%" style="display: block; margin: auto;" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">require</span>(MASS)
iris.lda&lt;-<span class="kw">lda</span>(Species <span class="op">~</span><span class="st"> </span>Sepal.Length <span class="op">+</span><span class="st"> </span>Sepal.Width <span class="op">+</span><span class="st"> </span>Petal.Length <span class="op">+</span><span class="st"> </span>Petal.Width, <span class="dt">data =</span>    iris)
datPred&lt;-<span class="kw">data.frame</span>(<span class="dt">Species=</span><span class="kw">predict</span>(iris.lda)<span class="op">$</span>class,<span class="kw">predict</span>(iris.lda)<span class="op">$</span>x) <span class="co">#create data.frame</span></code></pre></div>
<p>Creamos las superficies de decisión y las probabilidades de clase:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">iris.lda2 &lt;-<span class="st"> </span><span class="kw">lda</span>(datPred[,<span class="dv">2</span><span class="op">:</span><span class="dv">3</span>], datPred[,<span class="dv">1</span>])
x &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="kw">min</span>(datPred[,<span class="dv">2</span>]), <span class="kw">max</span>(datPred[,<span class="dv">2</span>]), <span class="dt">length.out=</span><span class="dv">30</span>)
y &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="kw">min</span>(datPred[,<span class="dv">3</span>]), <span class="kw">max</span>(datPred[,<span class="dv">3</span>]), <span class="dt">length.out=</span><span class="dv">30</span>)
Xcon &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">c</span>(<span class="kw">rep</span>(x,<span class="kw">length</span>(y)),<span class="kw">rep</span>(y, <span class="kw">rep</span>(<span class="kw">length</span>(x), <span class="kw">length</span>(y)))), <span class="dt">ncol =</span> <span class="dv">2</span>)
iris.pr1 &lt;-<span class="st"> </span><span class="kw">predict</span>(iris.lda2, Xcon)<span class="op">$</span>post[, <span class="kw">c</span>(<span class="st">&quot;setosa&quot;</span>,<span class="st">&quot;versicolor&quot;</span>)] <span class="op">%*%</span><span class="st"> </span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">1</span>)
iris.pr2 &lt;-<span class="st"> </span><span class="kw">predict</span>(iris.lda2, Xcon)<span class="op">$</span>post[, <span class="kw">c</span>(<span class="st">&quot;virginica&quot;</span>,<span class="st">&quot;setosa&quot;</span>)] <span class="op">%*%</span><span class="st"> </span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">1</span>)</code></pre></div>
<p>Graficamos las superficies (rectas) de decisión sobre los ajustados por el modelo por especie de flor:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">pr&lt;-<span class="kw">data.frame</span>(<span class="dt">x=</span><span class="kw">rep</span>(x, <span class="kw">length</span>(y)), <span class="dt">y=</span><span class="kw">rep</span>(y, <span class="dt">each=</span><span class="kw">length</span>(x)), 
    <span class="dt">z1=</span><span class="kw">as.vector</span>(iris.pr1), <span class="dt">z2=</span><span class="kw">as.vector</span>(iris.pr2))
<span class="kw">ggplot</span>(datPred, <span class="kw">aes</span>(<span class="dt">x=</span>LD1, <span class="dt">y=</span>LD2) ) <span class="op">+</span><span class="st"> </span>
<span class="st">    </span><span class="kw">geom_point</span>(<span class="dt">size =</span> <span class="dv">3</span>, <span class="kw">aes</span>(<span class="dt">pch =</span> Species,  <span class="dt">col=</span>Species)) <span class="op">+</span><span class="st"> </span>
<span class="st">    </span><span class="kw">geom_contour</span>(<span class="dt">data=</span>pr, <span class="kw">aes</span>(<span class="dt">x=</span>x, <span class="dt">y=</span>y, <span class="dt">z=</span>z1), <span class="dt">breaks=</span><span class="kw">c</span>(<span class="dv">0</span>,.<span class="dv">5</span>)) <span class="op">+</span><span class="st"> </span>
<span class="st">    </span><span class="kw">geom_contour</span>(<span class="dt">data=</span>pr, <span class="kw">aes</span>(<span class="dt">x=</span>x, <span class="dt">y=</span>y, <span class="dt">z=</span>z2), <span class="dt">breaks=</span><span class="kw">c</span>(<span class="dv">0</span>,.<span class="dv">5</span>))</code></pre></div>
<p><img src="11-lda-1_files/figure-html/unnamed-chunk-27-1.png" width="70%" style="display: block; margin: auto;" /></p>
</div>
</div>
<div id="tarea-9" class="section level2">
<h2><span class="header-section-number">11.5</span> Tarea</h2>
<ol style="list-style-type: decimal">
<li>Para comparar regresión lineal, análisis de discriminante lineal y regresión logística con dos clases utiliza el siguiente código para responder los incisos siguientes. Utiliza tu clave única como semilla.</li>
</ol>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">clave_unica &lt;-<span class="st"> </span><span class="dv">123456</span>
<span class="kw">set.seed</span>(clave_unica)
n &lt;-<span class="st"> </span><span class="dv">300</span>
x1 &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="kw">rnorm</span>(n<span class="op">/</span><span class="dv">3</span>,<span class="op">-</span><span class="dv">5</span>), <span class="kw">rnorm</span>(n<span class="op">/</span><span class="dv">3</span>, <span class="dv">0</span>, <span class="fl">1.5</span>), <span class="kw">rnorm</span>(n<span class="op">/</span><span class="dv">3</span>, <span class="dv">5</span>)) 
x2 &lt;-<span class="st"> </span><span class="op">-</span><span class="dv">12</span><span class="op">*</span><span class="kw">c</span>(<span class="kw">rep</span>(<span class="dv">0</span>,n<span class="op">/</span><span class="dv">2</span>),<span class="kw">rep</span>(<span class="dv">1</span>,n<span class="op">/</span><span class="dv">2</span>)) <span class="op">+</span><span class="st"> </span>x1 <span class="op">+</span><span class="st"> </span><span class="kw">rnorm</span>(n, <span class="dt">sd =</span> <span class="dv">2</span>) <span class="op">+</span><span class="st"> </span><span class="kw">c</span>(<span class="kw">rep</span>(<span class="op">-</span><span class="dv">5</span>, n<span class="op">/</span><span class="dv">2</span>), <span class="kw">rep</span>(<span class="dv">0</span>, n<span class="op">/</span><span class="dv">2</span>)) 
out &lt;-<span class="st"> </span><span class="kw">sample</span>((n<span class="op">/</span><span class="dv">2</span>)<span class="op">:</span>n, <span class="dt">size =</span> n<span class="op">/</span><span class="dv">10</span>)
x1[out] &lt;-<span class="st"> </span><span class="kw">rnorm</span>(n<span class="op">/</span><span class="dv">10</span>, <span class="dv">5</span>, <span class="dt">sd =</span> <span class="fl">0.5</span>) <span class="op">+</span><span class="st"> </span><span class="dv">10</span>
x2[out] &lt;-<span class="st"> </span><span class="op">-</span><span class="dv">12</span> <span class="op">+</span><span class="st"> </span>x1[out] <span class="op">+</span><span class="st"> </span><span class="kw">rnorm</span>(n<span class="op">/</span><span class="dv">10</span>, <span class="dt">sd =</span> <span class="fl">0.5</span>) <span class="op">-</span><span class="st"> </span><span class="dv">15</span>

y &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="kw">rep</span>(<span class="st">&#39;a&#39;</span>, n<span class="op">/</span><span class="dv">2</span>), <span class="kw">rep</span>(<span class="st">&#39;b&#39;</span>, n<span class="op">/</span><span class="dv">2</span>))
df &lt;-<span class="st"> </span><span class="kw">data.frame</span>(x1, x2, y)
<span class="kw">ggplot</span>(df, <span class="kw">aes</span>(<span class="dt">x =</span> x1, <span class="dt">y =</span> x2, <span class="dt">color =</span> y)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>()</code></pre></div>
<p><img src="11-lda-1_files/figure-html/unnamed-chunk-28-1.png" width="70%" style="display: block; margin: auto;" /></p>
<ol style="list-style-type: lower-alpha">
<li><p>Haz una gráfica de las superficies de decisión (rectas que separan las dos clases) utilizando el modelo simple de regresión lineal con predictores lineales. Calcula el error de predicción.</p></li>
<li><p>¿Habrá alguna diferencia entre el error utilizando regresión lineal con términos de polinomios cuadráticos y el error calculado en el inciso anterior?</p></li>
<li><p>Repite el inciso <em>a.</em> utilizando regresión logística. ¿Por qué la regresión logística es más consistente en la presencia de datos atípicos?</p></li>
<li><p>Repite el inciso <em>a.</em> utilizando análisis de discriminante lineal y compara con el error obtenido en los incisos anteriores.</p></li>
</ol>
<ol start="2" style="list-style-type: decimal">
<li>Demuestra que, en regresión lineal, si cada vector objetivo <span class="math inline">\(y_i\)</span> satisface una restricción lineal <span class="math display">\[
a^T y_i + b = 0
\]</span> para algunas constantes <span class="math inline">\(a\)</span> y <span class="math inline">\(b\)</span>, entonces la predicción del modelo para cualquier valor de <span class="math inline">\(x\)</span> satisface la misma restricción, de modo que <span class="math display">\[
a^T y(x) + b = 0.
\]</span> Por lo tanto, utilizando la codificación 1-a-K indicadoras para las <span class="math inline">\(K\)</span> clases, entonces las predicciones que produce el modelo tendrán la propiedad de que los elementos de <span class="math inline">\(y(x)\)</span> sumarán a 1 para cualquier valor de <span class="math inline">\(x\)</span>. Aunque no necesariamente están en el intervalo <span class="math inline">\((0,1)\)</span>.</li>
</ol>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="modelos-lineales-generalizados.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="discriminante-lineal-lda-2.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
