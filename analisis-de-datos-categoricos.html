<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Estadística Aplicada III</title>
  <meta name="description" content="Notas y material para el curso de Estadística Aplicada III, 2018 (ITAM)">
  <meta name="generator" content="bookdown 0.6.2 and GitBook 2.6.7">

  <meta property="og:title" content="Estadística Aplicada III" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Notas y material para el curso de Estadística Aplicada III, 2018 (ITAM)" />
  <meta name="github-repo" content="andreuboada/est-aplicada-3-2018" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Estadística Aplicada III" />
  
  <meta name="twitter:description" content="Notas y material para el curso de Estadística Aplicada III, 2018 (ITAM)" />
  

<meta name="author" content="Andreu Boada de Atela">


<meta name="date" content="2018-02-18">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="teorema-del-limite-central.html">
<link rel="next" href="referencias.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
<link rel="stylesheet" href="toc.css" type="text/css" />
<link rel="stylesheet" href="font-awesome.min.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Estadística Aplicada III</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Temario y referencias</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#evaluacion"><i class="fa fa-check"></i>Evaluación</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#software-r-y-rstudio"><i class="fa fa-check"></i>Software: R y Rstudio</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#referencias-principales"><i class="fa fa-check"></i>Referencias principales</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#otras-referencias"><i class="fa fa-check"></i>Otras referencias</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#tareas"><i class="fa fa-check"></i>Tareas</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introducción</a><ul>
<li class="chapter" data-level="1.1" data-path="intro.html"><a href="intro.html#por-que-un-analisis-multivariado"><i class="fa fa-check"></i><b>1.1</b> ¿Por qué un análisis multivariado?</a></li>
<li class="chapter" data-level="1.2" data-path="intro.html"><a href="intro.html#la-paradoja-de-simpson"><i class="fa fa-check"></i><b>1.2</b> La paradoja de Simpson</a></li>
<li class="chapter" data-level="1.3" data-path="intro.html"><a href="intro.html#modelos-log-lineales"><i class="fa fa-check"></i><b>1.3</b> Modelos log-lineales</a></li>
<li class="chapter" data-level="1.4" data-path="intro.html"><a href="intro.html#interpretacion-de-parametros"><i class="fa fa-check"></i><b>1.4</b> Interpretación de parámetros</a><ul>
<li class="chapter" data-level="1.4.1" data-path="intro.html"><a href="intro.html#ejemplo-dos-monedas"><i class="fa fa-check"></i><b>1.4.1</b> Ejemplo: dos monedas</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="intro.html"><a href="intro.html#otros-ejemplos"><i class="fa fa-check"></i><b>1.5</b> Otros ejemplos</a><ul>
<li class="chapter" data-level="1.5.1" data-path="intro.html"><a href="intro.html#discriminacion-de-residentes-hispanos-con-discapacidades"><i class="fa fa-check"></i><b>1.5.1</b> Discriminación de residentes hispanos con discapacidades</a></li>
<li class="chapter" data-level="1.5.2" data-path="intro.html"><a href="intro.html#consumo-de-chocolate-y-premios-nobel"><i class="fa fa-check"></i><b>1.5.2</b> Consumo de chocolate y premios Nobel</a></li>
</ul></li>
<li class="chapter" data-level="1.6" data-path="intro.html"><a href="intro.html#tarea"><i class="fa fa-check"></i><b>1.6</b> Tarea</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="Rintro.html"><a href="Rintro.html"><i class="fa fa-check"></i><b>2</b> Temas selectos de R</a><ul>
<li class="chapter" data-level="2.1" data-path="Rintro.html"><a href="Rintro.html#que-ventajas-tiene-r"><i class="fa fa-check"></i><b>2.1</b> ¿Qué ventajas tiene R?</a><ul>
<li class="chapter" data-level="2.1.1" data-path="Rintro.html"><a href="Rintro.html#r-es-gratuito-y-de-codigo-abierto"><i class="fa fa-check"></i><b>2.1.1</b> R es gratuito y de código abierto</a></li>
<li class="chapter" data-level="2.1.2" data-path="Rintro.html"><a href="Rintro.html#r-tiene-una-comunidad-comprometida"><i class="fa fa-check"></i><b>2.1.2</b> R tiene una comunidad comprometida</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="Rintro.html"><a href="Rintro.html#flujo-basico-de-trabajo-para-el-analisis-de-datos-en-r."><i class="fa fa-check"></i><b>2.2</b> Flujo básico de trabajo para el análisis de datos en R.</a></li>
<li class="chapter" data-level="2.3" data-path="Rintro.html"><a href="Rintro.html#introduccion-a-r-como-lenguaje-de-programacion-y-la-plataforma-interactiva-de-rstudio."><i class="fa fa-check"></i><b>2.3</b> Introducción a R como lenguaje de programación, y la plataforma interactiva de RStudio.</a><ul>
<li class="chapter" data-level="2.3.1" data-path="Rintro.html"><a href="Rintro.html#como-entender-r"><i class="fa fa-check"></i><b>2.3.1</b> ¿Cómo entender R?</a></li>
<li class="chapter" data-level="2.3.2" data-path="Rintro.html"><a href="Rintro.html#por-que-r"><i class="fa fa-check"></i><b>2.3.2</b> ¿Por qué R?</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="Rintro.html"><a href="Rintro.html#estructuras-de-datos"><i class="fa fa-check"></i><b>2.4</b> Estructuras de datos</a><ul>
<li class="chapter" data-level="2.4.1" data-path="Rintro.html"><a href="Rintro.html#vectores"><i class="fa fa-check"></i><b>2.4.1</b> Vectores</a></li>
<li class="chapter" data-level="2.4.2" data-path="Rintro.html"><a href="Rintro.html#data-frames"><i class="fa fa-check"></i><b>2.4.2</b> Data Frames</a></li>
<li class="chapter" data-level="2.4.3" data-path="Rintro.html"><a href="Rintro.html#listas"><i class="fa fa-check"></i><b>2.4.3</b> Listas</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="Rintro.html"><a href="Rintro.html#r-markdown"><i class="fa fa-check"></i><b>2.5</b> R Markdown</a><ul>
<li class="chapter" data-level="2.5.1" data-path="Rintro.html"><a href="Rintro.html#que-es-r-markdown"><i class="fa fa-check"></i><b>2.5.1</b> ¿Qué es R Markdown?</a></li>
<li class="chapter" data-level="2.5.2" data-path="Rintro.html"><a href="Rintro.html#estructura-basica-de-r-markdown"><i class="fa fa-check"></i><b>2.5.2</b> Estructura básica de R Markdown</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="Rintro.html"><a href="Rintro.html#proyectos-de-rstudio"><i class="fa fa-check"></i><b>2.6</b> Proyectos de RStudio</a></li>
<li class="chapter" data-level="2.7" data-path="Rintro.html"><a href="Rintro.html#otros-aspectos-importantes-de-r"><i class="fa fa-check"></i><b>2.7</b> Otros aspectos importantes de R</a><ul>
<li class="chapter" data-level="2.7.1" data-path="Rintro.html"><a href="Rintro.html#valores-faltantes"><i class="fa fa-check"></i><b>2.7.1</b> Valores faltantes</a></li>
<li class="chapter" data-level="2.7.2" data-path="Rintro.html"><a href="Rintro.html#funciones"><i class="fa fa-check"></i><b>2.7.2</b> Funciones</a></li>
<li class="chapter" data-level="2.7.3" data-path="Rintro.html"><a href="Rintro.html#funcionales"><i class="fa fa-check"></i><b>2.7.3</b> Funcionales</a></li>
<li class="chapter" data-level="2.7.4" data-path="Rintro.html"><a href="Rintro.html#rendimiento-en-r"><i class="fa fa-check"></i><b>2.7.4</b> Rendimiento en R</a></li>
</ul></li>
<li class="chapter" data-level="2.8" data-path="Rintro.html"><a href="Rintro.html#tarea-1"><i class="fa fa-check"></i><b>2.8</b> Tarea</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="manipulacion-y-visualizacion-de-datos.html"><a href="manipulacion-y-visualizacion-de-datos.html"><i class="fa fa-check"></i><b>3</b> Manipulación y visualización de datos</a><ul>
<li class="chapter" data-level="3.1" data-path="manipulacion-y-visualizacion-de-datos.html"><a href="manipulacion-y-visualizacion-de-datos.html#el-principio-de-datos-limpios"><i class="fa fa-check"></i><b>3.1</b> El principio de datos limpios</a><ul>
<li class="chapter" data-level="" data-path="manipulacion-y-visualizacion-de-datos.html"><a href="manipulacion-y-visualizacion-de-datos.html#ejemplo"><i class="fa fa-check"></i>Ejemplo:</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="manipulacion-y-visualizacion-de-datos.html"><a href="manipulacion-y-visualizacion-de-datos.html#limpieza-de-datos"><i class="fa fa-check"></i><b>3.2</b> Limpieza de datos</a></li>
<li class="chapter" data-level="3.3" data-path="manipulacion-y-visualizacion-de-datos.html"><a href="manipulacion-y-visualizacion-de-datos.html#separa-aplica-combina"><i class="fa fa-check"></i><b>3.3</b> <em>Separa-aplica-combina</em></a></li>
<li class="chapter" data-level="3.4" data-path="manipulacion-y-visualizacion-de-datos.html"><a href="manipulacion-y-visualizacion-de-datos.html#muertes-por-armas-de-fuego-en-eua"><i class="fa fa-check"></i><b>3.4</b> Muertes por armas de fuego en EUA</a></li>
<li class="chapter" data-level="3.5" data-path="manipulacion-y-visualizacion-de-datos.html"><a href="manipulacion-y-visualizacion-de-datos.html#el-cuarteto-de-anscombe"><i class="fa fa-check"></i><b>3.5</b> El Cuarteto de Anscombe</a></li>
<li class="chapter" data-level="3.6" data-path="manipulacion-y-visualizacion-de-datos.html"><a href="manipulacion-y-visualizacion-de-datos.html#the-grammar-of-graphics-de-leland-wilkinson"><i class="fa fa-check"></i><b>3.6</b> The <em>Grammar of Graphics</em> de Leland Wilkinson</a></li>
<li class="chapter" data-level="3.7" data-path="manipulacion-y-visualizacion-de-datos.html"><a href="manipulacion-y-visualizacion-de-datos.html#ggplot"><i class="fa fa-check"></i><b>3.7</b> ggplot</a></li>
<li class="chapter" data-level="3.8" data-path="manipulacion-y-visualizacion-de-datos.html"><a href="manipulacion-y-visualizacion-de-datos.html#un-histograma-de-las-muertes-en-iraq"><i class="fa fa-check"></i><b>3.8</b> Un histograma de las muertes en Iraq</a></li>
<li class="chapter" data-level="3.9" data-path="manipulacion-y-visualizacion-de-datos.html"><a href="manipulacion-y-visualizacion-de-datos.html#inglehartwelzel-un-mapa-cultural-del-mundo"><i class="fa fa-check"></i><b>3.9</b> Inglehart–Welzel: un mapa cultural del mundo</a><ul>
<li class="chapter" data-level="3.9.1" data-path="manipulacion-y-visualizacion-de-datos.html"><a href="manipulacion-y-visualizacion-de-datos.html#creando-un-ggplot"><i class="fa fa-check"></i><b>3.9.1</b> Creando un ggplot</a></li>
<li class="chapter" data-level="3.9.2" data-path="manipulacion-y-visualizacion-de-datos.html"><a href="manipulacion-y-visualizacion-de-datos.html#mapeos-aesthetics"><i class="fa fa-check"></i><b>3.9.2</b> Mapeos: Aesthetics</a></li>
</ul></li>
<li class="chapter" data-level="3.10" data-path="manipulacion-y-visualizacion-de-datos.html"><a href="manipulacion-y-visualizacion-de-datos.html#poniendo-todo-junto"><i class="fa fa-check"></i><b>3.10</b> Poniendo todo junto</a></li>
<li class="chapter" data-level="3.11" data-path="manipulacion-y-visualizacion-de-datos.html"><a href="manipulacion-y-visualizacion-de-datos.html#tarea-2"><i class="fa fa-check"></i><b>3.11</b> Tarea</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="teorema-del-limite-central.html"><a href="teorema-del-limite-central.html"><i class="fa fa-check"></i><b>4</b> Teorema del Límite Central</a><ul>
<li class="chapter" data-level="4.1" data-path="teorema-del-limite-central.html"><a href="teorema-del-limite-central.html#la-distribucion-de-bary"><i class="fa fa-check"></i><b>4.1</b> La distribución de <span class="math inline">\(\bar{Y}\)</span></a></li>
<li class="chapter" data-level="4.2" data-path="teorema-del-limite-central.html"><a href="teorema-del-limite-central.html#de-donde-proviene-la-distribucion-normal"><i class="fa fa-check"></i><b>4.2</b> ¿De dónde proviene la distribución normal?</a><ul>
<li class="chapter" data-level="4.2.1" data-path="teorema-del-limite-central.html"><a href="teorema-del-limite-central.html#que-signo-tiene-c"><i class="fa fa-check"></i><b>4.2.1</b> ¿Qué signo tiene c?</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="teorema-del-limite-central.html"><a href="teorema-del-limite-central.html#otras-observaciones"><i class="fa fa-check"></i><b>4.3</b> Otras observaciones</a></li>
<li class="chapter" data-level="4.4" data-path="teorema-del-limite-central.html"><a href="teorema-del-limite-central.html#diagramas-de-caja-y-brazos"><i class="fa fa-check"></i><b>4.4</b> Diagramas de caja y brazos</a><ul>
<li class="chapter" data-level="" data-path="teorema-del-limite-central.html"><a href="teorema-del-limite-central.html#ejemplo-1"><i class="fa fa-check"></i>Ejemplo</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="teorema-del-limite-central.html"><a href="teorema-del-limite-central.html#graficas-de-cuantiles-teoricos"><i class="fa fa-check"></i><b>4.5</b> Gráficas de cuantiles teóricos</a><ul>
<li class="chapter" data-level="" data-path="teorema-del-limite-central.html"><a href="teorema-del-limite-central.html#ejemplo-normal"><i class="fa fa-check"></i>Ejemplo: normal</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="teorema-del-limite-central.html"><a href="teorema-del-limite-central.html#graficas-de-cuantiles-para-un-conjunto-de-datos"><i class="fa fa-check"></i><b>4.6</b> Gráficas de cuantiles para un conjunto de datos</a><ul>
<li class="chapter" data-level="4.6.1" data-path="teorema-del-limite-central.html"><a href="teorema-del-limite-central.html#que-buscar-en-una-grafica-de-cuantiles"><i class="fa fa-check"></i><b>4.6.1</b> ¿Qué buscar en una gráfica de cuantiles?</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="teorema-del-limite-central.html"><a href="teorema-del-limite-central.html#graficas-qq-normales"><i class="fa fa-check"></i><b>4.7</b> Gráficas qq-normales</a><ul>
<li class="chapter" data-level="" data-path="teorema-del-limite-central.html"><a href="teorema-del-limite-central.html#ejemplo-cantantes"><i class="fa fa-check"></i>Ejemplo: cantantes</a></li>
</ul></li>
<li class="chapter" data-level="4.8" data-path="teorema-del-limite-central.html"><a href="teorema-del-limite-central.html#el-tlc-y-errores-estandar"><i class="fa fa-check"></i><b>4.8</b> El TLC y errores estándar</a></li>
<li class="chapter" data-level="4.9" data-path="teorema-del-limite-central.html"><a href="teorema-del-limite-central.html#ejemplo-2"><i class="fa fa-check"></i><b>4.9</b> Ejemplo</a></li>
<li class="chapter" data-level="4.10" data-path="teorema-del-limite-central.html"><a href="teorema-del-limite-central.html#tarea-3"><i class="fa fa-check"></i><b>4.10</b> Tarea</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="analisis-de-datos-categoricos.html"><a href="analisis-de-datos-categoricos.html"><i class="fa fa-check"></i><b>5</b> Análisis de datos categóricos</a><ul>
<li class="chapter" data-level="5.1" data-path="analisis-de-datos-categoricos.html"><a href="analisis-de-datos-categoricos.html#repaso-y-algunos-conceptos"><i class="fa fa-check"></i><b>5.1</b> Repaso y algunos conceptos</a><ul>
<li class="chapter" data-level="5.1.1" data-path="analisis-de-datos-categoricos.html"><a href="analisis-de-datos-categoricos.html#caso-binomial"><i class="fa fa-check"></i><b>5.1.1</b> Caso binomial</a></li>
<li class="chapter" data-level="" data-path="analisis-de-datos-categoricos.html"><a href="analisis-de-datos-categoricos.html#estimacion-de-parametros-multinomiales"><i class="fa fa-check"></i>Estimación de parámetros multinomiales</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="analisis-de-datos-categoricos.html"><a href="analisis-de-datos-categoricos.html#la-chi2-de-pearson-de-una-multinomial"><i class="fa fa-check"></i><b>5.2</b> La <span class="math inline">\(\chi^2\)</span> de Pearson de una multinomial</a><ul>
<li class="chapter" data-level="5.2.1" data-path="analisis-de-datos-categoricos.html"><a href="analisis-de-datos-categoricos.html#cociente-de-verosimilitud-de-una-multinomial"><i class="fa fa-check"></i><b>5.2.1</b> Cociente de verosimilitud de una multinomial</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="analisis-de-datos-categoricos.html"><a href="analisis-de-datos-categoricos.html#definiciones"><i class="fa fa-check"></i><b>5.3</b> Definiciones</a><ul>
<li class="chapter" data-level="5.3.1" data-path="analisis-de-datos-categoricos.html"><a href="analisis-de-datos-categoricos.html#notacion"><i class="fa fa-check"></i><b>5.3.1</b> Notación</a></li>
<li class="chapter" data-level="5.3.2" data-path="analisis-de-datos-categoricos.html"><a href="analisis-de-datos-categoricos.html#razon-de-momios"><i class="fa fa-check"></i><b>5.3.2</b> Razón de momios</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="analisis-de-datos-categoricos.html"><a href="analisis-de-datos-categoricos.html#asociacion-en-tablas-de-tamano-itimes-j"><i class="fa fa-check"></i><b>5.4</b> Asociación en tablas de tamaño <span class="math inline">\(I\times J\)</span></a><ul>
<li class="chapter" data-level="5.4.1" data-path="analisis-de-datos-categoricos.html"><a href="analisis-de-datos-categoricos.html#razones-de-momios-en-tablas-itimes-j"><i class="fa fa-check"></i><b>5.4.1</b> Razones de momios en tablas <span class="math inline">\(I\times J\)</span></a></li>
<li class="chapter" data-level="5.4.2" data-path="analisis-de-datos-categoricos.html"><a href="analisis-de-datos-categoricos.html#ejemplo-mushrooms"><i class="fa fa-check"></i><b>5.4.2</b> Ejemplo: mushrooms</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="analisis-de-datos-categoricos.html"><a href="analisis-de-datos-categoricos.html#intervalos-de-confianza-para-los-parametros-de-asociacion"><i class="fa fa-check"></i><b>5.5</b> Intervalos de confianza para los parámetros de asociación</a><ul>
<li class="chapter" data-level="5.5.1" data-path="analisis-de-datos-categoricos.html"><a href="analisis-de-datos-categoricos.html#error-estandar-de-la-razon-de-momios"><i class="fa fa-check"></i><b>5.5.1</b> Error estándar de la razón de momios</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="analisis-de-datos-categoricos.html"><a href="analisis-de-datos-categoricos.html#prueba-de-independencia"><i class="fa fa-check"></i><b>5.6</b> Prueba de independencia</a><ul>
<li class="chapter" data-level="5.6.1" data-path="analisis-de-datos-categoricos.html"><a href="analisis-de-datos-categoricos.html#la-prueba-chi2-de-pearson"><i class="fa fa-check"></i><b>5.6.1</b> La prueba <span class="math inline">\(\chi^2\)</span> de Pearson</a></li>
<li class="chapter" data-level="5.6.2" data-path="analisis-de-datos-categoricos.html"><a href="analisis-de-datos-categoricos.html#ejemplo-brecha-de-genero"><i class="fa fa-check"></i><b>5.6.2</b> Ejemplo: brecha de género</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="referencias.html"><a href="referencias.html"><i class="fa fa-check"></i>Referencias</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Publicado con bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Estadística Aplicada III</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="analisis-de-datos-categoricos" class="section level1">
<h1><span class="header-section-number">Clase 5</span> Análisis de datos categóricos</h1>
<style>
  .espacio {
     margin-bottom: 1cm;
  }
</style>
<style>
  .espacio3 {
     margin-bottom: 3cm;
  }
</style>
<p>Sólo necesitas instalar un paquete una vez, pero debes volver a cargarlo cada vez que inicies una nueva sesión.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(tidyverse)</code></pre></div>
<p>Las variables categóricas están por doquier. Desde ayudar a decidir cuándo un tratamiento médico es mejor hasta evaluar los factores que afectan nuestras opiniones y conductas, hoy en día los analistas encuentran innumerables usos para los métodos de datos categóricos. Primero vamos a repasar algunos conceptos de probabilidad.</p>
<div id="repaso-y-algunos-conceptos" class="section level2">
<h2><span class="header-section-number">5.1</span> Repaso y algunos conceptos</h2>
<p>Recordemos la <strong>distribución multinomial</strong>. Supongamos que cada uno de <span class="math inline">\(n\)</span> ensayos independientes e idénticos tiene realizaciones en <span class="math inline">\(c\)</span> categorías. Definimos <span class="math inline">\(y_{ij}\)</span> como <span class="math display">\[
y_{ij} = \left\{ \begin{array}{cl}
1 &amp; \text{si el }\; i\text{-ésimo ensayo cae en la categoría }j,\\
0 &amp; \text{en otro caso.}
\end{array}\right.
\]</span></p>
<p>Entonces <span class="math inline">\(y_i=(y_{i1},y_{i2},\ldots,y_{ic})\)</span> representa <em>un</em> ensayo multinomial, done <span class="math display">\[
\displaystyle{\sum_j{y_{ij}}}=1.
\]</span></p>
<p>Notemos que <span class="math inline">\(y_{ic}=1-(y_{i1}+\cdots+y_{i,c-1})\)</span> es redundante. Sea <span class="math inline">\(n_j=\displaystyle{\sum_i{y_{ij}}}\)</span> el número de ensayos que caen en la categoría <span class="math inline">\(j\)</span>. Los conteos <span class="math inline">\((n_1,n_2,\ldots,n_c)\)</span> tienen una distribución multinomial.</p>
<p>Sea <span class="math inline">\(\pi_{j}=P(Y_{ij}=1)\)</span>, la probabilidad de éxito en la categoría <span class="math inline">\(j\)</span>. La función de masa de probabilidad de <span class="math inline">\((n_1,n_2,\ldots,n_c)\)</span> es <span class="math display">\[
p(n_1,n_2,\ldots,n_c) = \dfrac{n!}{n_1!n_2!\cdots n_c!}\pi_1^{n_1}\pi_2^{n_2}\cdots \pi_c^{n_c}.
\]</span></p>
<p>Sea <span class="math inline">\(n=\displaystyle{\sum_j{n_j}}\)</span>. Recordemos que esta ecuación es de dimensión <span class="math inline">\(c-1\)</span> porque <span class="math display">\[
n_c = n - (n_1 + n_2 + \cdots + n_{c-1}).
\]</span></p>
<p>Se puede ver que <span class="math display">\[
\begin{eqnarray*}
E(n_j) =n\pi_j, \quad &amp;&amp; V(n_j)=n\pi_j(1-\pi_j),\\
C(n_i,n_j)=-n\pi_i \pi_j&amp;\quad&amp;\mbox{si } i\neq j
\end{eqnarray*}
\]</span></p>
<p><strong>Modelo Poisson</strong></p>
<p>Sean <span class="math inline">\((Y_1,Y_2,\ldots,Y_c)\)</span> variables aleatorias Poisson independientes con parámetros <span class="math inline">\((\mu_1,\mu_2,\ldots,\mu_c)\)</span>. La función de masa de probabilidad conjunta es <span class="math display">\[
P(Y_1=n_1, Y_2=n_2, \ldots, Y_c=n_c) = \prod_i{\mbox{exp}(-\mu_i)\dfrac{\mu_i^{n_i}}{n_i!}}.
\]</span></p>
<p>El total <span class="math inline">\(n=\displaystyle{\sum_i{Y_i}}\)</span> también tiene una distribución Poisson con media <span class="math inline">\(\displaystyle{\sum_i{\mu_i}}\)</span>. Como <span class="math inline">\(n\)</span> también es una variable aleatoria, al condicionar en <span class="math inline">\(n\)</span>, <span class="math inline">\(\{Y_i\}\)</span> ya no tienen una distribución Poisson, pues cada <span class="math inline">\(Y_i\)</span> no puede exceder <span class="math inline">\(n\)</span>.</p>
<p>La distribución condicional es <span class="math display">\[
\begin{eqnarray*}
P\left(Y_1=n_1,\ldots,Y_c=n_c \,\middle|\,  \sum_j{Y_j}=n\right) &amp;=&amp; \dfrac{P(Y_1=n_1,\ldots,Y_c=n_c)}{P\left(\sum_j{Y_j}\right)} \\
&amp;=&amp; \dfrac{\prod_i \mbox{exp}(-\mu_i)\mu_i^{n_i}/n_i!}{\mbox{exp}\left(-\sum_j{\mu_j}\right)\left(\sum_j {\mu_j}\right)^n/n!} \\
&amp;=&amp; \dfrac{n!}{\prod_i n_i!} \prod_i{\pi_i^{n_i}}
\end{eqnarray*}
\]</span> con <span class="math inline">\(\pi_i = \dfrac{\mu_i}{\sum_i \mu_i}\)</span>, es decir, se trata de una distribución multinomial con parámetros <span class="math inline">\((n, \{\pi_i\})\)</span>.</p>
<p>Muchos análisis de datos categóricos suponen una distribución multinomial. Tales análisis usualmente tineen resultados similres a aquellos análisis que suponen una distribución Poisson, por las similitudes en sus funciones de verosimilitud.</p>
<hr />
<p><br></p>
<p>En la estimación de parámetros a menudo se utilizan dos métodos para obtener intervalos de confianza:</p>
<ol style="list-style-type: decimal">
<li>Método de Wald</li>
</ol>
<p>En el caso univariado se utiliza como estimador de la varianza <span class="math inline">\(-E\left(\dfrac{d^2 L(\theta)}{d\theta^2}\right)\)</span> y el estadístico es <span class="math display">\[z=(\hat{\theta} - \theta_0)/\mbox{SE} \sim N(0,1)\]</span> o en el caso multivariado, <span class="math display">\[
W = \left(\hat{\theta}- \theta_0\right)^T\left[\mbox{Cov}\left(\hat{\theta}\right)\right]^{-1}\left(\hat{\theta}- \theta_0\right),
\]</span> y como <span class="math inline">\(\hat{\theta}\)</span> se distribuye normal asintóticamente, entonces la distribución de <span class="math inline">\(W\)</span> es <span class="math inline">\(\chi^2\)</span> con grados de libertad igual al rango de <span class="math inline">\(\mbox{Cov}\left(\hat{\theta}\right)\)</span>, el número de parámetros no redundantes.</p>
<ol start="2" style="list-style-type: decimal">
<li>Método de cociente de verosimilitud</li>
</ol>
<p>Si <span class="math inline">\(l_0\)</span> es el máximo valor de la función de verosimilitud bajo <span class="math inline">\(H_0\)</span> y <span class="math inline">\(l_1\)</span> es el valor máximo sobre el espacio de parámetros (que contiene también el valor bajo <span class="math inline">\(H_0\)</span>), entonces <span class="math inline">\(l_0 \leq l_1\)</span> y el estadístico es</p>
<p><span class="math display">\[-2\,  \mbox{log}(\Lambda) = -2\,  \mbox{log}(l_0/l_1)=-2(L_0-L_1) \sim \chi^2_n\]</span> donde los grados de libertad equivalen a la diferencia de dimensiones de los espacios de parámetros.</p>
<div id="caso-binomial" class="section level3">
<h3><span class="header-section-number">5.1.1</span> Caso binomial</h3>
<p>Definimos la función de verosimilitud de una variable aleatoria binomial con <span class="math inline">\(n\)</span> realizaciones y <span class="math inline">\(x\)</span> éxitos:</p>
<p><span class="math display">\[
L(\theta) = \mbox{log}(\theta^x(1-\theta)^{n-x}) = x\mbox{log}(\theta) + (n-x)\mbox{log}(1-\theta)
\]</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">likelihood &lt;-<span class="st"> </span><span class="cf">function</span>(x, n){
  <span class="cf">function</span>(theta){x<span class="op">*</span><span class="kw">log</span>(theta) <span class="op">+</span><span class="st"> </span>(n<span class="op">-</span>x)<span class="op">*</span><span class="kw">log</span>(<span class="dv">1</span><span class="op">-</span>theta)}
}</code></pre></div>
<p>Creamos nuestra función de verosimilitud para <span class="math inline">\(x=3\)</span> y <span class="math inline">\(n=10\)</span>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mi_likelihood &lt;-<span class="st"> </span><span class="kw">likelihood</span>(<span class="dv">3</span>, <span class="dv">10</span>)</code></pre></div>
<p>Graficamos la función:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(<span class="dt">data =</span> <span class="kw">data.frame</span>(<span class="dt">x =</span> <span class="dv">0</span>), <span class="dt">mapping =</span> <span class="kw">aes</span>(<span class="dt">x =</span> x)) <span class="op">+</span>
<span class="st">  </span><span class="kw">stat_function</span>(<span class="dt">fun =</span> mi_likelihood) <span class="op">+</span><span class="st"> </span><span class="kw">xlim</span>(<span class="fl">0.001</span>,<span class="fl">0.999</span>)</code></pre></div>
<p><img src="05-datos_categoricos_files/figure-html/unnamed-chunk-5-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>El estadístico de Wald da como resultado el invervalo</p>
<p><span class="math display">\[
\hat{\theta} \pm z_{\alpha/2}\sqrt{\dfrac{\hat{\theta}(1-\hat{\theta})}{n}}
\]</span></p>
<p>El estadístico del cociente de verosimilitud es:</p>
<p><span class="math display">\[
2x\left[x\mbox{log}\left(\dfrac{\hat{\theta}}{\theta_0}\right)+(n-x)\mbox{log}\left(\dfrac{1-\hat{\theta}}{1-\theta_0}\right)\right] = \chi^2_{1,\alpha}
\]</span></p>
<p>Se puede expresar como</p>
<p><span class="math display">\[
2\sum{\mbox{observado} \,\left[\,\mbox{log}\left(\dfrac{\mbox{observado}}{\mbox{ajustado}}\right)\right]}
\]</span></p>
<p>Existen varios métodos para obtener intervalos de confianza. Utilizando la función <code>ciAllx</code> del paquete <code>proportion</code> podemos obtener intervalos de confianza para <span class="math inline">\(\hat{\theta}\)</span> a partir de 6 métodos:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(proportion)
intervalos &lt;-<span class="st"> </span><span class="kw">ciAllx</span>(<span class="dt">x =</span> <span class="dv">3</span>, <span class="dt">n =</span> <span class="dv">10</span>, <span class="dt">alp =</span> <span class="fl">0.05</span>) 
intervalos <span class="op">%&gt;%</span><span class="st"> </span>knitr<span class="op">::</span><span class="kw">kable</span>()</code></pre></div>
<table>
<thead>
<tr class="header">
<th align="left">method</th>
<th align="right">x</th>
<th align="right">LowerLimit</th>
<th align="right">UpperLimit</th>
<th align="left">LowerAbb</th>
<th align="left">UpperAbb</th>
<th align="left">ZWI</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Wald</td>
<td align="right">3</td>
<td align="right">0.016</td>
<td align="right">0.584</td>
<td align="left">NO</td>
<td align="left">NO</td>
<td align="left">NO</td>
</tr>
<tr class="even">
<td align="left">ArcSine</td>
<td align="right">3</td>
<td align="right">0.071</td>
<td align="right">0.603</td>
<td align="left">NO</td>
<td align="left">NO</td>
<td align="left">NO</td>
</tr>
<tr class="odd">
<td align="left">Likelihood</td>
<td align="right">3</td>
<td align="right">0.085</td>
<td align="right">0.607</td>
<td align="left">NO</td>
<td align="left">NO</td>
<td align="left">NO</td>
</tr>
<tr class="even">
<td align="left">Score</td>
<td align="right">3</td>
<td align="right">0.108</td>
<td align="right">0.603</td>
<td align="left">NO</td>
<td align="left">NO</td>
<td align="left">NO</td>
</tr>
<tr class="odd">
<td align="left">Logit-Wald</td>
<td align="right">3</td>
<td align="right">0.100</td>
<td align="right">0.624</td>
<td align="left">NO</td>
<td align="left">NO</td>
<td align="left">NO</td>
</tr>
<tr class="even">
<td align="left">Wald-T</td>
<td align="right">3</td>
<td align="right">0.002</td>
<td align="right">0.598</td>
<td align="left">NO</td>
<td align="left">NO</td>
<td align="left">NO</td>
</tr>
</tbody>
</table>
<p>Los intervalos de confianza para todos los métodos son realmente muy similares. Si el tamaño de muestra <span class="math inline">\(n\)</span> es grande, los 6 métodos dan como resultado intervalos de confianza prácticamente idénticos.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(intervalos, <span class="kw">aes</span>(<span class="dt">y =</span> method)) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_segment</span>(<span class="kw">aes</span>(<span class="dt">x =</span> LowerLimit, <span class="dt">xend =</span> UpperLimit, <span class="dt">y =</span> method, <span class="dt">yend =</span> method)) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_vline</span>(<span class="dt">xintercept =</span> <span class="fl">0.3</span>, <span class="dt">color =</span> <span class="st">&#39;red&#39;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">xlab</span>(<span class="st">&#39;Intervalo de confianza para cada método&#39;</span>)</code></pre></div>
<p><img src="05-datos_categoricos_files/figure-html/unnamed-chunk-7-1.png" width="60%" style="display: block; margin: auto;" /></p>
<hr />
<p><br></p>
</div>
<div id="estimacion-de-parametros-multinomiales" class="section level3 unnumbered">
<h3>Estimación de parámetros multinomiales</h3>
<p>Definimos la función de verosimilitud <span class="math display">\[
l(n_1,n_2,\ldots,n_c | \pi_1, \pi_2, \ldots, \pi_c) = c \prod_j \pi_j^{n_j}
\]</span> donde <span class="math inline">\(\pi_j \geq 0\)</span> y <span class="math inline">\(\sum_j{\pi_j}=1\)</span>.</p>
<p>Para estimar <span class="math inline">\(\{\pi_j\}\)</span> maximizamos la log-verosimilitud <span class="math display">\[
L(\pi) = \sum_j{n_j \mbox{log}(\pi_j)}.
\]</span></p>
<p>Para no tener redundancias vemos <span class="math inline">\(L\)</span> como función de <span class="math inline">\(\pi_1,\pi_2,\ldots,\pi_{c-1}\)</span> pues <span class="math inline">\(\pi_c=1-(\pi_1+ \pi_2+\cdots+\pi_{c-1})\)</span>. Por lo tanto, <span class="math display">\[
\dfrac{d \pi_c}{d \pi_j} = -1 \qquad \mbox{para }\; j=1,2,\ldots,c-1.
\]</span> Por la regla de la cadena, <span class="math display">\[
\dfrac{d\,\mbox{log}(\pi_c)}{d\,\pi_j}=\dfrac{1}{\pi_c} \cdot \dfrac{d\, \pi_c}{d\, \pi_j}=-\dfrac{1}{\pi_c}.
\]</span> Ahora diferenciamos <span class="math inline">\(L\)</span> con respecto a <span class="math inline">\(\pi_j\)</span> <span class="math display">\[
\dfrac{d\, L(\pi)}{d\, \pi_j}=\dfrac{n_j}{\pi_j} - \dfrac{n_c}{\pi_c} = 0.
\]</span> Por lo que los estimadores de máxima verosimilitud satisfacen que <span class="math display">\[
\dfrac{\hat{\pi}_j}{\hat{\pi}_c} = \dfrac{n_j}{n_c}.
\]</span> Ahora bien, <span class="math display">\[
1 = \sum_j{\pi_j}= \dfrac{\hat{\pi}_c\left(\sum_j n_j\right)}{n_c}=\dfrac{\hat{\pi}_c n}{n_c},
\]</span> y se tiene que <span class="math inline">\(\hat{\pi_c}=n_c/n\)</span> y <span class="math inline">\(\hat{\pi_j}=n_j/n\)</span> para <span class="math inline">\(j=1,2,\ldots,c-1\)</span>.</p>
<p>Se puede verificar que estos estimadores efectivamente maximizan la verosimilitud. Notemos que <span class="math inline">\(\hat{\pi_j}=n_j/n\)</span> son las proporciones muestrales.</p>
</div>
</div>
<div id="la-chi2-de-pearson-de-una-multinomial" class="section level2">
<h2><span class="header-section-number">5.2</span> La <span class="math inline">\(\chi^2\)</span> de Pearson de una multinomial</h2>
<p>En 1900 el estadístico Karl Pearson definió una prueba de hipótesis para la multinomial. Su motivación inicial fue analizar las probabilidades de ocurrencias de varias realizaciones en el juego de la ruleta. Consideramos para <span class="math inline">\(j=1,2,\ldots,c\)</span> <span class="math display">\[
H_0:\pi_j =\pi_{j0} \qquad H_1:\pi_j \neq \pi_{j0}.
\]</span></p>
<p>Bajo <span class="math inline">\(H_0\)</span>, los valores esperados de <span class="math inline">\(\{n_j\}\)</span>, llamadas <em>frecuencias esperadas</em> son <span class="math inline">\(\mu_j=n\pi_{j0}\)</span>, <span class="math inline">\(j=1,\ldots,c\)</span>. El estadístico propueto es <span class="math display">\[
X^2 = \sum_j{\dfrac{(n_j - \mu_j)^2}{\mu_j}} \sim \chi^2_{(c-1)}.
\]</span></p>
<p>Si las diferencias <span class="math inline">\(\{n_j - \mu_j\}\)</span> son más grandes, esto produce valores <span class="math inline">\(X^2\)</span> más grandes para una <span class="math inline">\(n\)</span> fija. Si <span class="math inline">\(X_o^2\)</span> es el valor observado de <span class="math inline">\(X^2\)</span> entonces el valor p es <span class="math inline">\(P(X^2 \geq X_o^2)\)</span>. Si <span class="math inline">\(n\)</span> es grande, <span class="math inline">\(X^2\)</span> tiene una distribución <span class="math inline">\(\chi^2_{c-1}\)</span>.</p>
<div id="cociente-de-verosimilitud-de-una-multinomial" class="section level3">
<h3><span class="header-section-number">5.2.1</span> Cociente de verosimilitud de una multinomial</h3>
<p>Bajo <span class="math inline">\(H_0\)</span> la verosimilitud se maximiza cuando <span class="math inline">\(\hat{\pi}_j=\pi_{j0}\)</span> y en el caso general cuando <span class="math inline">\(\hat{pi}_j=\frac{n_j}{n}\)</span>. El cociente de verosimilitud es</p>
<p><span class="math display">\[
\Lambda = \dfrac{\prod_j{\pi_{j0}^{n_j}}}{\prod_j{(n_j/n)^{n_j}}}.
\]</span> Por lo tanto, el estadístico del cociente de verosimilitud es</p>
<p><span class="math display">\[
G^2 = -2\,\mbox{log}(\Lambda) = 2\, \sum_j{n_j \mbox{log}\left(\dfrac{n_j}{n}\pi_{j0}\right)}.
\]</span></p>
<p>A este estadístico se le llama <em>estadístico <span class="math inline">\(\chi^2\)</span> de verosimilitud</em>. Entre más grande sea el valor de <span class="math inline">\(G^2\)</span> hay mayor evidencia en contra de <span class="math inline">\(H_0\)</span>. En el caso general, el espacio de parámetros consiste de <span class="math inline">\(\{\pi_j\}\)</span> sujeto a que <span class="math inline">\(\sum_j{\pi_j}=1\)</span>, por lo que la dimensión es <span class="math inline">\(c-1\)</span>. Bajo <span class="math inline">\(H_0\)</span>, se especifica por completo <span class="math inline">\(\{\pi_j\}\)</span>, por lo que la dimensión es <span class="math inline">\(0\)</span>. La diferencia entre estas dimensiones es <span class="math inline">\((c-1)\)</span>. Si <span class="math inline">\(n\)</span> es grande, entonces <span class="math inline">\(G^2\)</span> tiene una distribución <span class="math inline">\(\chi^2\)</span> con <span class="math inline">\((c-1)\)</span> grados de libertad.</p>
</div>
</div>
<div id="definiciones" class="section level2">
<h2><span class="header-section-number">5.3</span> Definiciones</h2>
<p>Supongamos que se tiene una tabla de contingencias. A continuación introduciremos una notación y algunas definiciones.</p>
<div id="notacion" class="section level3">
<h3><span class="header-section-number">5.3.1</span> Notación</h3>
<p>Sea <span class="math inline">\(\pi_{ij}\)</span> la probabilidad de que una observación <span class="math inline">\((X,Y)\)</span> esté en la celdilla (<span class="math inline">\(i\)</span>,<span class="math inline">\(j\)</span>). Las densidades marginales las denotamos por: <span class="math display">\[
\pi_{i+}=\sum_j{\pi_{ij}},\qquad \pi_{+j}  = \sum_i{\pi_{ij}}
\]</span> Cuando ambas variables son aleatorias, se pueden definir las densidades marginales: <span class="math display">\[
\pi_{j|i} = \pi_{ij}/\pi_{i+}, \qquad \mbox{para toda }i\mbox{ y }j
\]</span></p>
<p>Se dice que las variables son <strong>independientes</strong> si <span class="math display">\[
\pi_{ij} = \pi_{i+}\pi_{+j} \quad \mbox{para }\; i=1,\ldots,I\; \mbox{ y para }\; j=1,\ldots,J.
\]</span> Cuando son independientes se cumple que <span class="math display">\[
\pi_{j|i}=\pi_{ij}/\pi_{i+}=(\pi_{i+}\pi_{+j})/\pi_{i+}=\pi_{+j} \quad \mbox{para }i=1,\ldots,I.
\]</span></p>
</div>
<div id="razon-de-momios" class="section level3">
<h3><span class="header-section-number">5.3.2</span> Razón de momios</h3>

<div class="nota">
Para una probabilidad de éxito <span class="math inline">\(\pi\)</span> se definen los <em>momios</em> (o <em>chances</em>) como <span class="math display">\[
\Omega = \dfrac{\pi}{1-\pi}
\]</span> Los momios siempre son no negativos.
</div>

<p><strong>Ejemplo</strong></p>
<p>Un <strong>sitio de apuestas</strong> escribe:</p>
<blockquote>
<p>Momio 7/1: Ganas $7 por cada $1 apostado. Si apuestas $10, cobras $70 más tu apuesta, es decir, $80. Momio 5/2: Ganas $5 por cada $2 apostados. Si apuestas $10, cobras $25 más tu apuesta, es decir, $35. Momio 3/5: Ganas $3 por cada $5 apostados. Si apuestas $10, cobras $6 más tu apuesta, es decir, $16.</p>
</blockquote>
<p class="espacio">
</p>
<p><img src="figuras/apuesta.png" width="70%" style="display: block; margin: auto;" /></p>
<p class="espacio">
</p>
<img src="figuras/manicule2.jpg" />
<div class="centered">
<p class="espacio">
</p>
<p>Si el momio es menor que 1 entonces…</p>
<ol style="list-style-type: lower-alpha">
<li><p>La probabilidad de éxito es cero.</p></li>
<li><p>La probabilidad de éxito es menor que <span class="math inline">\(1/2\)</span>.</p></li>
<li><p>El éxito es más probable que el fracaso.</p></li>
<li><p>Todas la anteriores.</p></li>
</ol>
<p class="espacio3">
</p>
</div>
<p><br></p>

<div class="information">
Si <span class="math inline">\(\Omega &gt; 1\)</span>, entonces es más probable el éxito que el fracaso. Por ejemplo, cuando <span class="math inline">\(\pi=0.75\)</span> entonces <span class="math inline">\(\Omega = 0.75/0.25 =3\)</span>, un éxito es 3 veces más probable que un fracaso, y esperaríamos 3 éxitos por cada fracaso. Cuando <span class="math inline">\(\Omega = \frac{1}{3}\)</span> un fracaso es tres veces más verosímil que un éxito.
</div>

<p><br></p>
<p>Inversamente,</p>
<p><span class="math display">\[
\pi = \dfrac{\Omega}{\Omega + 1}.
\]</span></p>
<p>Pensemos nuevamente en una tabla de contingencias de <span class="math inline">\(2\times 2\)</span>, en la <span class="math inline">\(i\)</span>-ésima fila los momios de éxito en vez de fracaso son <span class="math inline">\(\Omega_i=\pi_i/(1-\pi_i)\)</span>. La <strong>razón de momios</strong> de <span class="math inline">\(\Omega_1\)</span> y <span class="math inline">\(\Omega_2\)</span> en ambas filas es:</p>
<p><span class="math display">\[
\theta = \dfrac{\Omega_1}{\Omega_2}=\dfrac{\pi_1/(1-\pi_1)}{\pi_2/(1-\pi_2)}
\]</span></p>
<p>Si se tiene una tabla con probabilidades conjuntas <span class="math inline">\(\{\pi_{ij}\}\)</span> la definición equivalente de momio para cada fila es <span class="math inline">\(\Omega_i=\pi_{i1}/\pi_{i2}\)</span>, <span class="math inline">\(i=1,2\)</span>. Entonces la razón de momios es:</p>
<p><span class="math display">\[
\theta = \dfrac{\pi_{11}/\pi_{12}}{\pi_{21}/\pi_{22}}=\dfrac{\pi_{11}\pi_{22}}{\pi_{12}\pi_{21}}
\]</span></p>
<p>A <span class="math inline">\(\theta\)</span> se le conoce también como la <em>razón del producto cruzado</em>.</p>

<div class="nota">
<p>¿Cómo interpretamos este número?</p>
<ul>
<li><p>Si <span class="math inline">\(\theta=1\)</span> (o <span class="math inline">\(\Omega_1=\Omega_2\)</span>), entonces las variables son independientes.</p></li>
<li><p>Si <span class="math inline">\(\theta &gt; 1\)</span>, entonces las observaciones en el renglón 1 tienen más probabilidad de éxito que observaciones en en renglón 2, es decir, <span class="math inline">\(\pi_1 &gt; \pi_2\)</span>.</p></li>
<li>Si <span class="math inline">\(\theta &lt; 1\)</span>, entonces <span class="math inline">\(\pi_1 &lt; \pi_2\)</span>.
</div>
</li>
</ul>
<p>Para conteos en una tabla de contingencia, la <em>razón de momios muestral</em> es:</p>
<p><span class="math display">\[
\hat{\theta} = \dfrac{n_{11}n_{22}}{n_{12}n_{21}}
\]</span></p>
<p>Regresemos a los datos de billboard:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">billboard &lt;-<span class="st"> </span><span class="kw">read_csv</span>(<span class="st">&quot;datos/billboard_alltime.csv&quot;</span>)</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">OR &lt;-<span class="st"> </span><span class="cf">function</span>(var1, var2){
  n &lt;-<span class="st"> </span><span class="kw">table</span>(var1, var2)
  
  (n[<span class="dv">1</span>,<span class="dv">1</span>] <span class="op">/</span><span class="st"> </span>n[<span class="dv">1</span>,<span class="dv">2</span>])<span class="op">*</span>(n[<span class="dv">2</span>,<span class="dv">2</span>] <span class="op">/</span><span class="st"> </span>n[<span class="dv">2</span>,<span class="dv">1</span>])
}
<span class="kw">OR</span>(billboard<span class="op">$</span>gains_performance, billboard<span class="op">$</span>rising)
<span class="co">#&gt; [1] 2.75</span></code></pre></div>
<p>Los chances de éxito (subir una o más posiciones en el chart) cuando no hubo una presentación en vivo (rengón 1) son equivalentes a 4 veces los chances de éxito (incremento en el chart) que cuando no hubo presentación en vivo (renglón 2).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">ORWald &lt;-<span class="st"> </span><span class="cf">function</span>(var1, var2, <span class="dt">alpha =</span> <span class="fl">0.05</span>){
  tab &lt;-<span class="st"> </span><span class="kw">table</span>(var1, var2)
  siglog &lt;-<span class="st"> </span><span class="kw">sqrt</span>((<span class="dv">1</span><span class="op">/</span>tab[<span class="dv">1</span>,<span class="dv">1</span>]) <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span><span class="op">/</span>tab[<span class="dv">1</span>,<span class="dv">2</span>]) <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span><span class="op">/</span>tab[<span class="dv">2</span>,<span class="dv">1</span>]) <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span><span class="op">/</span>tab[<span class="dv">2</span>,<span class="dv">2</span>]))
  zalph &lt;-<span class="st"> </span><span class="kw">qnorm</span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>alpha<span class="op">/</span><span class="dv">2</span>)
  logOR &lt;-<span class="st"> </span><span class="kw">log</span>(<span class="kw">OR</span>(var1, var2))
  loglo &lt;-<span class="st"> </span>logOR <span class="op">-</span><span class="st"> </span>zalph <span class="op">*</span><span class="st"> </span>siglog
  loghi &lt;-<span class="st"> </span>logOR <span class="op">+</span><span class="st"> </span>zalph <span class="op">*</span><span class="st"> </span>siglog
  
  ORlo &lt;-<span class="st"> </span><span class="kw">exp</span>(loglo)
  ORhi &lt;-<span class="st"> </span><span class="kw">exp</span>(loghi)
  
  <span class="kw">tibble</span>(<span class="dt">LowerCI =</span> ORlo, <span class="dt">OR =</span> <span class="kw">OR</span>(var1, var2), <span class="dt">UpperCI =</span> ORhi, <span class="dt">alpha =</span> alpha)
}

<span class="kw">ORWald</span>(billboard<span class="op">$</span>gains_performance, billboard<span class="op">$</span>rising)</code></pre></div>
<p>Con la función <code>odds.ratio</code> del paquete <code>questionr</code> se puede calcular la razón de momios y el paquete hace una prueba de hipótesis conocida como <strong>prueba exacta de Fisher</strong>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(questionr)
<span class="kw">odds.ratio</span>(<span class="kw">table</span>(billboard<span class="op">$</span>gains_performance, billboard<span class="op">$</span>rising))
<span class="co">#&gt;                 OR 2.5 % 97.5 %      p    </span>
<span class="co">#&gt; Fisher&#39;s test 2.75  2.70    2.8 &lt;2e-16 ***</span>
<span class="co">#&gt; ---</span>
<span class="co">#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span></code></pre></div>

<div class="comentario">
<ul>
<li><p>Valores de <span class="math inline">\(\theta\)</span> más alejados de <span class="math inline">\(1\)</span> reflejan un mayor grado de asociación entre las variables.</p></li>
<li><p>Dos valores representan la misma asociación pero en direcciones opuestas, cuando uno es el recíproco del otro.</p></li>
<li>Por ejemplo, cuando <span class="math inline">\(\theta=0.25\)</span> los chances de éxito en el renglón 1 son 0.25 veces los chances en el renglón 2, o equivalentemente, los chances de éxito en el renglón 2 son 1/0.25 = 4 veces los chances en el renglón 1.
</div>
</li>
</ul>
<p class="espacio">
</p>
<img src="figuras/manicule2.jpg" />
<div class="centered">
<p class="espacio">
</p>
<p>Si se invierte el orden de los renglones o de las columnas, entonces <span class="math inline">\(\theta\)</span></p>
<ol style="list-style-type: lower-alpha">
<li><p>no cambia.</p></li>
<li><p>debe ser necesariamente <span class="math inline">\(1\)</span>.</p></li>
<li><p>es el recíproco de su valor original.</p></li>
<li><p>puede tomar cualquier valor.</p></li>
</ol>
<p class="espacio3">
</p>
</div>
<p><br></p>
<p>Para hacer inferencia es conveniente usar <span class="math inline">\(\mbox{log}(\theta)\)</span>. Este tiene las siguientes propiedades:</p>
<ol style="list-style-type: decimal">
<li><p>El caso de independencia corresponde a <span class="math inline">\(\mbox{log}(\theta) = 0\)</span>.</p></li>
<li><p>El logaritmo de la razón de momios es simétrico alrededor de <span class="math inline">\(0\)</span>.</p></li>
<li><p>Si se invierten los renglones o las columnas, entonces <span class="math inline">\(\mbox{log}(\theta)\)</span> cambia de signo pero tiene la misma magnitud. Por ejemplo, dos valores de <span class="math inline">\(\mbox{log}(\theta)\)</span> que tienen misma magnitud pero signos contrarios, como <span class="math inline">\(\mbox{log}(4)=1.39\)</span> y <span class="math inline">\(\mbox{log}(0.25)=-1.39\)</span>, representan el mismo grado de asociación.</p></li>
</ol>
</div>
</div>
<div id="asociacion-en-tablas-de-tamano-itimes-j" class="section level2">
<h2><span class="header-section-number">5.4</span> Asociación en tablas de tamaño <span class="math inline">\(I\times J\)</span></h2>
<p>En tablas de <span class="math inline">\(2\times 2\)</span> un sólo número como la razón de momios puede ser suficiente para resumir la asociación. En tablas <span class="math inline">\(I\times J\)</span> usualmente no es posible resumir la asociación entre las dos variables con un sólo número sin alguna pérdida de información. Sin embargo, un conjunto de razones de momios, o bien, algun otro estadístico de resumen pueden ser útil para describir la asociación entre las variables.</p>
<div id="razones-de-momios-en-tablas-itimes-j" class="section level3">
<h3><span class="header-section-number">5.4.1</span> Razones de momios en tablas <span class="math inline">\(I\times J\)</span></h3>
<p>Se puede utiliar los <span class="math inline">\(\dbinom{I}{2}\)</span> pares de renglones en combinación con los <span class="math inline">\(\dbinom{J}{2}\)</span> pares de columnas. Para renglones <span class="math inline">\(a\)</span> y <span class="math inline">\(b\)</span> y columnas <span class="math inline">\(c\)</span> y <span class="math inline">\(d\)</span> la razón de momios utiliza 4 valores en casillas en un patrón rectangular:</p>
<p><span class="math display">\[
\dfrac{\pi_{ab}\pi_{bd}}{\pi_{bc}\pi_{ad}}
\]</span></p>
<p>Consideremos el subconjunto de <span class="math inline">\((I-1)(J-1)\)</span> <em>razones de momios locales</em>:</p>
<p><span class="math display">\[
\theta_{ij} = \dfrac{\pi_{ij}\pi_{i+1,j+1}}{\pi_{i,j+1}\pi_{i+1,j}},  \qquad i=1,\ldots, I-1,\;\;\; j=1,\ldots,J-1.
\]</span></p>
<p>Estos <span class="math inline">\((I-1)(J-1)\)</span> razones de momios determinan las razones de momios entre pares de renglones y pares de columnas.</p>
</div>
<div id="ejemplo-mushrooms" class="section level3">
<h3><span class="header-section-number">5.4.2</span> Ejemplo: mushrooms</h3>
<p>Este conjunto de datos incluye descripciones de muestras correspondientes a 23 especies de setas de las familias Agaricus y Lepiota.</p>
<p>Cada especie está identificada como definitivamente comestible, definitivamente venenosa, o de comestibilidad desconocida y no recomendada su ingesta.</p>
<p>Las otras variables se presentan en la siguiente tabla:</p>
<table>
<colgroup>
<col width="21%" />
<col width="78%" />
</colgroup>
<thead>
<tr class="header">
<th>Variable</th>
<th>Categorías</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>cap-shape</td>
<td>bell=b,conical=c,convex=x,flat=f,knobbed=k,sunken=s</td>
</tr>
<tr class="even">
<td>cap-surface</td>
<td>fibrous=f,grooves=g,scaly=y,smooth=s</td>
</tr>
<tr class="odd">
<td>cap-color</td>
<td>brown=n,buff=b,cinnamon=c,gray=g,green=r,pink=p,purple=u,red=e,white=w,yellow=y</td>
</tr>
<tr class="even">
<td>bruises</td>
<td>bruises=t,no=f</td>
</tr>
<tr class="odd">
<td>odor</td>
<td>almond=a,anise=l,creosote=c,fishy=y,foul=f,musty=m,none=n,pungent=p,spicy=s</td>
</tr>
<tr class="even">
<td>gill-attachment</td>
<td>attached=a,descending=d,free=f,notched=n</td>
</tr>
<tr class="odd">
<td>gill-spacing</td>
<td>close=c,crowded=w,distant=d</td>
</tr>
<tr class="even">
<td>gill-size</td>
<td>broad=b,narrow=n</td>
</tr>
<tr class="odd">
<td>gill-color</td>
<td>black=k,brown=n,buff=b,chocolate=h,gray=g,green=r,orange=o,pink=p,purple=u,red=e,white=w,yellow=y</td>
</tr>
<tr class="even">
<td>stalk-shape</td>
<td>enlarging=e,tapering=t</td>
</tr>
<tr class="odd">
<td>stalk-root</td>
<td>bulbous=b,club=c,cup=u,equal=e,rhizomorphs=z,rooted=r,missing=?</td>
</tr>
<tr class="even">
<td>stalk-surface-above-ring</td>
<td>fibrous=f,scaly=y,silky=k,smooth=s</td>
</tr>
<tr class="odd">
<td>stalk-surface-below-ring</td>
<td>fibrous=f,scaly=y,silky=k,smooth=s</td>
</tr>
<tr class="even">
<td>stalk-color-above-ring</td>
<td>brown=n,buff=b,cinnamon=c,gray=g,orange=o,pink=p,red=e,white=w,yellow=y</td>
</tr>
<tr class="odd">
<td>stalk-color-below-ring</td>
<td>brown=n,buff=b,cinnamon=c,gray=g,orange=o,pink=p,red=e,white=w,yellow=y</td>
</tr>
<tr class="even">
<td>veil-type</td>
<td>partial=p,universal=u</td>
</tr>
<tr class="odd">
<td>veil-color</td>
<td>brown=n,orange=o,white=w,yellow=y</td>
</tr>
<tr class="even">
<td>ring-number</td>
<td>none=n,one=o,two=t</td>
</tr>
<tr class="odd">
<td>ring-type</td>
<td>cobwebby=c,evanescent=e,flaring=f,large=l,none=n,pendant=p,sheathing=s,zone=z</td>
</tr>
<tr class="even">
<td>spore-print-color</td>
<td>black=k,brown=n,buff=b,chocolate=h,green=r,orange=o,purple=u,white=w,yellow=y</td>
</tr>
<tr class="odd">
<td>population</td>
<td>abundant=a,clustered=c,numerous=n,scattered=s,several=v,solitary=y</td>
</tr>
<tr class="even">
<td>habitat</td>
<td>grasses=g,leaves=l,meadows=m,paths=p,urban=u,waste=w,woods=d</td>
</tr>
</tbody>
</table>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mushrooms &lt;-<span class="st"> </span><span class="kw">read_csv</span>(<span class="st">&quot;datos/mushrooms.csv&quot;</span>)
<span class="kw">glimpse</span>(mushrooms)
<span class="co">#&gt; Observations: 8,124</span>
<span class="co">#&gt; Variables: 23</span>
<span class="co">#&gt; $ edibility                  &lt;chr&gt; &quot;p&quot;, &quot;e&quot;, &quot;e&quot;, &quot;p&quot;, &quot;e&quot;, &quot;e&quot;, &quot;e&quot;, ...</span>
<span class="co">#&gt; $ `cap-shape`                &lt;chr&gt; &quot;x&quot;, &quot;x&quot;, &quot;b&quot;, &quot;x&quot;, &quot;x&quot;, &quot;x&quot;, &quot;b&quot;, ...</span>
<span class="co">#&gt; $ `cap-surface`              &lt;chr&gt; &quot;s&quot;, &quot;s&quot;, &quot;s&quot;, &quot;y&quot;, &quot;s&quot;, &quot;y&quot;, &quot;s&quot;, ...</span>
<span class="co">#&gt; $ `cap-color`                &lt;chr&gt; &quot;n&quot;, &quot;y&quot;, &quot;w&quot;, &quot;w&quot;, &quot;g&quot;, &quot;y&quot;, &quot;w&quot;, ...</span>
<span class="co">#&gt; $ bruises                    &lt;chr&gt; &quot;t&quot;, &quot;t&quot;, &quot;t&quot;, &quot;t&quot;, &quot;f&quot;, &quot;t&quot;, &quot;t&quot;, ...</span>
<span class="co">#&gt; $ odor                       &lt;chr&gt; &quot;p&quot;, &quot;a&quot;, &quot;l&quot;, &quot;p&quot;, &quot;n&quot;, &quot;a&quot;, &quot;a&quot;, ...</span>
<span class="co">#&gt; $ `gill-attachment`          &lt;chr&gt; &quot;f&quot;, &quot;f&quot;, &quot;f&quot;, &quot;f&quot;, &quot;f&quot;, &quot;f&quot;, &quot;f&quot;, ...</span>
<span class="co">#&gt; $ `gill-spacing`             &lt;chr&gt; &quot;c&quot;, &quot;c&quot;, &quot;c&quot;, &quot;c&quot;, &quot;w&quot;, &quot;c&quot;, &quot;c&quot;, ...</span>
<span class="co">#&gt; $ `gill-size`                &lt;chr&gt; &quot;n&quot;, &quot;b&quot;, &quot;b&quot;, &quot;n&quot;, &quot;b&quot;, &quot;b&quot;, &quot;b&quot;, ...</span>
<span class="co">#&gt; $ `gill-color`               &lt;chr&gt; &quot;k&quot;, &quot;k&quot;, &quot;n&quot;, &quot;n&quot;, &quot;k&quot;, &quot;n&quot;, &quot;g&quot;, ...</span>
<span class="co">#&gt; $ `stalk-shape`              &lt;chr&gt; &quot;e&quot;, &quot;e&quot;, &quot;e&quot;, &quot;e&quot;, &quot;t&quot;, &quot;e&quot;, &quot;e&quot;, ...</span>
<span class="co">#&gt; $ `stalk-root`               &lt;chr&gt; &quot;e&quot;, &quot;c&quot;, &quot;c&quot;, &quot;e&quot;, &quot;e&quot;, &quot;c&quot;, &quot;c&quot;, ...</span>
<span class="co">#&gt; $ `stalk-surface-above-ring` &lt;chr&gt; &quot;s&quot;, &quot;s&quot;, &quot;s&quot;, &quot;s&quot;, &quot;s&quot;, &quot;s&quot;, &quot;s&quot;, ...</span>
<span class="co">#&gt; $ `stalk-surface-below-ring` &lt;chr&gt; &quot;s&quot;, &quot;s&quot;, &quot;s&quot;, &quot;s&quot;, &quot;s&quot;, &quot;s&quot;, &quot;s&quot;, ...</span>
<span class="co">#&gt; $ `stalk-color-above-ring`   &lt;chr&gt; &quot;w&quot;, &quot;w&quot;, &quot;w&quot;, &quot;w&quot;, &quot;w&quot;, &quot;w&quot;, &quot;w&quot;, ...</span>
<span class="co">#&gt; $ `stalk-color-below-ring`   &lt;chr&gt; &quot;w&quot;, &quot;w&quot;, &quot;w&quot;, &quot;w&quot;, &quot;w&quot;, &quot;w&quot;, &quot;w&quot;, ...</span>
<span class="co">#&gt; $ `veil-type`                &lt;chr&gt; &quot;p&quot;, &quot;p&quot;, &quot;p&quot;, &quot;p&quot;, &quot;p&quot;, &quot;p&quot;, &quot;p&quot;, ...</span>
<span class="co">#&gt; $ `veil-color`               &lt;chr&gt; &quot;w&quot;, &quot;w&quot;, &quot;w&quot;, &quot;w&quot;, &quot;w&quot;, &quot;w&quot;, &quot;w&quot;, ...</span>
<span class="co">#&gt; $ `ring-number`              &lt;chr&gt; &quot;o&quot;, &quot;o&quot;, &quot;o&quot;, &quot;o&quot;, &quot;o&quot;, &quot;o&quot;, &quot;o&quot;, ...</span>
<span class="co">#&gt; $ `ring-type`                &lt;chr&gt; &quot;p&quot;, &quot;p&quot;, &quot;p&quot;, &quot;p&quot;, &quot;e&quot;, &quot;p&quot;, &quot;p&quot;, ...</span>
<span class="co">#&gt; $ `spore-print-color`        &lt;chr&gt; &quot;k&quot;, &quot;n&quot;, &quot;n&quot;, &quot;k&quot;, &quot;n&quot;, &quot;k&quot;, &quot;k&quot;, ...</span>
<span class="co">#&gt; $ population                 &lt;chr&gt; &quot;s&quot;, &quot;n&quot;, &quot;n&quot;, &quot;s&quot;, &quot;a&quot;, &quot;n&quot;, &quot;n&quot;, ...</span>
<span class="co">#&gt; $ habitat                    &lt;chr&gt; &quot;u&quot;, &quot;g&quot;, &quot;m&quot;, &quot;u&quot;, &quot;g&quot;, &quot;g&quot;, &quot;m&quot;, ...</span></code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(oddsratio)
mushrooms_<span class="dv">1</span> &lt;-<span class="st"> </span>mushrooms <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">edibility =</span> <span class="dv">1</span><span class="op">*</span>(edibility <span class="op">==</span><span class="st"> &#39;e&#39;</span>))
fit_glm &lt;-<span class="st"> </span><span class="kw">glm</span>(edibility <span class="op">~</span><span class="st"> `</span><span class="dt">cap-color</span><span class="st">`</span>, <span class="dt">data=</span>mushrooms_<span class="dv">1</span>, <span class="dt">family=</span><span class="st">&#39;binomial&#39;</span>)
<span class="kw">or_glm</span>(<span class="dt">data =</span> mushrooms_<span class="dv">1</span>, <span class="dt">model =</span> fit_glm)</code></pre></div>
<p>En esta tabla se tienen dos columnas donde “e” siginifica que la seta es comestible y “p” que la seta es venenosa. En los renglones están los colores de las setas codificados de acuerdo con la tabla anterior. En las columnas están las razones de momio para cada color para aquellas setas que son comestibles.</p>
<p>Veamos la tabla de color y comestibilidad:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">table</span>(mushrooms<span class="op">$</span>edibility, mushrooms<span class="op">$</span><span class="st">`</span><span class="dt">cap-color</span><span class="st">`</span>)
<span class="co">#&gt;    </span>
<span class="co">#&gt;        b    c    e    g    n    p    r    u    w    y</span>
<span class="co">#&gt;   e   48   32  624 1032 1264   56   16   16  720  400</span>
<span class="co">#&gt;   p  120   12  876  808 1020   88    0    0  320  672</span></code></pre></div>
<p>Podemos ver que la razón de momios para p=pink y u=purple es “infinita” porque hay muy pocas observaciones para setas de esos colores. De cualquier forma, con los momios podemos concluir que aquellas setas de colores c=cinnamon y w=white aumentan los chances de que sean comestibles en 6.7 y 5.6, respectivamente.</p>
</div>
</div>
<div id="intervalos-de-confianza-para-los-parametros-de-asociacion" class="section level2">
<h2><span class="header-section-number">5.5</span> Intervalos de confianza para los parámetros de asociación</h2>
<p>La precisión de los esitmadores de asociación está caracterizada por las distribuciones muestrales de los errores estándar. Para tablas de <span class="math inline">\(2\times 2\)</span> recordemos que <span class="math display">\[
\hat{\theta} = \dfrac{n_{11}n_{22}}{n_{12}n_{21}}
\]</span></p>
<p>Se puede demostrar que <span class="math inline">\(\hat{\theta}\)</span> tiene una distribución normal asinotóticamente alrededor de <span class="math inline">\(\theta\)</span>. A menos que <span class="math inline">\(n\)</span> sea grande, la distribución muestral generalmente es sesgada.</p>
<div id="error-estandar-de-la-razon-de-momios" class="section level3">
<h3><span class="header-section-number">5.5.1</span> Error estándar de la razón de momios</h3>
<p>Utilizando la transformación de logaritmo, la estructura multiplicativa converge muy rápidamente a la normalidad. Una aproximación del error estándar para <span class="math inline">\(\mbox{log}(\hat{\theta})\)</span> es</p>
<p><span class="math display">\[
\hat{\sigma}(\mbox{log}\hat{\theta}) = \sqrt{\dfrac{1}{n_{11}}+\dfrac{1}{n_{12}}+\dfrac{1}{n_{21}}+\dfrac{1}{n_{22}}}.
\]</span></p>
<p>Como consecuencia de la normalidad de la distribución de <span class="math inline">\(\mbox{log}(\hat{\theta})\)</span>,</p>
<p><span class="math display">\[
\mbox{log}(\hat{\theta}) \pm z_{\alpha/2}\hat{\sigma}(\mbox{log}\hat{\theta})
\]</span></p>
</div>
</div>
<div id="prueba-de-independencia" class="section level2">
<h2><span class="header-section-number">5.6</span> Prueba de independencia</h2>
<p>Suponemos que se tiene resultados obtenidos de una distribución multinomial y probabilidades conjuntas <span class="math inline">\(\{\pi_{ij}\}\)</span> en una tabla de contingencia de dimensiones <span class="math inline">\(I\times J\)</span>.</p>

<div class="nota">
La hipótesis nula de independencia estadística es: <span class="math display">\[
H_0:\pi_{ij}=\pi_{i+}\pi_{+j},\qquad \text{ para toda }\;\; i \;\;\text{ y }\;\; j.
\]</span>
</div>

<div id="la-prueba-chi2-de-pearson" class="section level3">
<h3><span class="header-section-number">5.6.1</span> La prueba <span class="math inline">\(\chi^2\)</span> de Pearson</h3>
<p>Ya estudiamos la prueba para valores específicos de probabilidades multinomiales. Una prueba de <span class="math inline">\(H_0:\mbox{independencia}\)</span> utiliza la <span class="math inline">\(\chi^2\)</span> con <span class="math inline">\(n_{ij}\)</span> en lugar de <span class="math inline">\(n_i\)</span> y con <span class="math inline">\(\mu_{ij}=n\pi_{i+}\pi_{+j}\)</span> en lugar de <span class="math inline">\(\mu_i\)</span>.</p>

<div class="information">
<p>Bajo <span class="math inline">\(H_0\)</span>:</p>
<p><span class="math display">\[E(n_{ij}) = \mu_{ij}\]</span></p>
<p>Usualmente <span class="math inline">\(\{\pi_{i+}\}\)</span> y <span class="math inline">\(\{\pi_{+j}\}\)</span> son <em>conocidas</em>. Sus estimadores de máxima verosimilitud son <span class="math inline">\(\hat{\pi}_{i+}=n_{i+}/n\)</span> y <span class="math inline">\(\hat{\pi}_{+j}=n_{+j}/n\)</span>.</p>
<p>Las frecuencias esperadas estimadas son <span class="math display">\[
\{\hat{\mu}_{ij} = n\hat{\pi}_{i+}\hat{\pi}_{+j}=n_{i+}n_{+j}/n^2\}
\]</span></p>
Por lo tanto, el estadístico de Pearson es: <span class="math display">\[
\chi^2 = \displaystyle{\sum_{i}\sum_{j}{\dfrac{(n_{ij}-\hat{\mu}_{ij})^2}{\hat{\mu}_{ij}}}}.
\]</span>
</div>

<p>En 1900, el mismo Karl Pearson argumento que reemplazar las <span class="math inline">\(\{\mu_{ij}\}\)</span> por sus estimadores <span class="math inline">\(\{\hat{\mu}_{ij}\}\)</span> no afectaría la distribución muestral cuando se tiene una muestra grande. Como la tabla de contingencia tiene <span class="math inline">\(IJ\)</span> categorías, Pearson argumentó que la <span class="math inline">\(\chi^2\)</span> se distribuye como <em>chi cuadrada</em> asintóticamente con grados de libertad <span class="math inline">\(IJ-1\)</span>.</p>

<div class="nota">
<p>Sin embargo, años después (en 1922) Fisher publicó un artículo corrigiendo el error de Pearson. Lo que sucede es lo siguiente: estimar <span class="math inline">\(\{\hat{\mu}_{ij}\}\)</span> requiere de estimar <span class="math inline">\(\{\pi_{i+}\}\)</span> y <span class="math inline">\(\{\pi_{+j}\}\)</span>, por lo que los grados de libertad son:</p>
<span class="math display">\[
(IJ - 1) - (I-1) - (J-1) = (I-1)(J-1).
\]</span>
</div>

<p><strong>El estadístico de cociente de verosimilitud</strong></p>
<p>Para una muestra multinomial, el kernel de la verosimilitud es</p>
<p><span class="math display">\[
\prod_i \prod_j{\pi_{ij}^{n_{ij}}},\qquad \;\text{donde todas }\;\; \pi_{ij}\geq0\;\; \mbox{y}\;\;\sum_i \sum_j{\pi_{ij}}=1.
\]</span></p>
<p>Bajo <span class="math inline">\(H_0:\text{independencia}\)</span>, <span class="math inline">\(\hat{\pi}_{ij}=\hat{\pi}_{i+}\hat{\pi}_{+j}=n_{i+}n_{+j}/n^2\)</span>. En el caso general, <span class="math inline">\(\hat{\pi}_{ij}=n_{ij}/n\)</span>. El cociente de verosimilitud es igual a</p>
<p><span class="math display">\[
\Lambda = \dfrac{\prod_i \prod_j (n_{i+}n_{+j})^{n_{ij}}}{n^n\prod_i\prod_j{n_{ij}^{n_{ij}}}}.
\]</span></p>
<p>El estadístico del cociente de verosimilitud es <span class="math inline">\(-2\mbox{log}(\Lambda)\)</span>. Denotado por <span class="math inline">\(G^2\)</span>, es igual a:</p>
<p><span class="math display">\[
G^2 = -2\mbox{log}(\Lambda) = 2\sum_i\sum_j{n_{ij}\mbox{log}(n_{ij}/\hat{\mu}_{ij})}
\]</span></p>
<p>Entre más grandes sean los valores de <span class="math inline">\(G^2\)</span> y <span class="math inline">\(X^2\)</span>, mayor evidencia de independencia. En el caso general el espacio consiste de <span class="math inline">\(\{\pi_{ij}\}\)</span> sujeto a la restricción lineal de que deben sumar <span class="math inline">\(1\)</span>. El espacio de parámetros tiene dimensión <span class="math inline">\(IJ-1\)</span>. Bajo <span class="math inline">\(H_0\)</span> el espacio está determinado por <span class="math inline">\(\{\pi_{i+}\}\)</span> y <span class="math inline">\(\{\pi_{+j}\}\)</span>, por lo que su dimensión es de <span class="math inline">\((I-1) + (J-1)\)</span>. La diferencia entre estas dimensiones es <span class="math inline">\((I-1)(J-1)\)</span>. Para muestras grandes, <span class="math inline">\(G^2\)</span> tiene una distribución nula <span class="math inline">\(\chi^2\)</span> con grados de libertad <span class="math inline">\((I-1)(J-1)\)</span>. Por lo que <span class="math inline">\(G^2\)</span> y <span class="math inline">\(X^2\)</span> tienen la misma distribución límite. De hecho, son asintóticamente equivalentes: <span class="math inline">\(X^2 - G^2\)</span> converge en probabilidad a <span class="math inline">\(0\)</span>.</p>
</div>
<div id="ejemplo-brecha-de-genero" class="section level3">
<h3><span class="header-section-number">5.6.2</span> Ejemplo: brecha de género</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">gendergap &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">c</span>(<span class="dv">279</span>,<span class="dv">73</span>,<span class="dv">225</span>,<span class="dv">165</span>,<span class="dv">47</span>,<span class="dv">191</span>), <span class="dt">byrow =</span> T, <span class="dt">ncol =</span> <span class="dv">3</span>)
<span class="kw">dimnames</span>(gendergap) &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">Gender=</span><span class="kw">c</span>(<span class="st">&quot;Female&quot;</span>,<span class="st">&quot;Male&quot;</span>), <span class="dt">PartyID=</span><span class="kw">c</span>(<span class="st">&quot;Democrat&quot;</span>,<span class="st">&quot;Independent&quot;</span>,<span class="st">&quot;Republican&quot;</span>))
gendergap <span class="op">%&gt;%</span><span class="st"> </span>knitr<span class="op">::</span><span class="kw">kable</span>()</code></pre></div>
<table>
<thead>
<tr class="header">
<th></th>
<th align="right">Democrat</th>
<th align="right">Independent</th>
<th align="right">Republican</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Female</td>
<td align="right">279</td>
<td align="right">73</td>
<td align="right">225</td>
</tr>
<tr class="even">
<td>Male</td>
<td align="right">165</td>
<td align="right">47</td>
<td align="right">191</td>
</tr>
</tbody>
</table>
<p>La prueba de <span class="math inline">\(\chi^2\)</span> de Pearson se puede obtener con la función <code>chisq.test</code> que ya está en R base:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">chisq.test</span>(gendergap)
<span class="co">#&gt; </span>
<span class="co">#&gt;  Pearson&#39;s Chi-squared test</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; data:  gendergap</span>
<span class="co">#&gt; X-squared = 7, df = 2, p-value = 0.03</span></code></pre></div>
<!--
## General Social Survey 1972 - 2016











-->

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="teorema-del-limite-central.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="referencias.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
