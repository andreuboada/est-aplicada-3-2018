<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Estadística Aplicada III</title>
  <meta name="description" content="Notas y material para el curso de Estadística Aplicada III, 2018 (ITAM)">
  <meta name="generator" content="bookdown 0.7.10 and GitBook 2.6.7">

  <meta property="og:title" content="Estadística Aplicada III" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Notas y material para el curso de Estadística Aplicada III, 2018 (ITAM)" />
  <meta name="github-repo" content="andreuboada/est-aplicada-3-2018" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Estadística Aplicada III" />
  
  <meta name="twitter:description" content="Notas y material para el curso de Estadística Aplicada III, 2018 (ITAM)" />
  

<meta name="author" content="Andreu Boada de Atela">


<meta name="date" content="2018-05-10">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="teorema-del-limite-central.html">
<link rel="next" href="regresion-logistica-1.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
<link rel="stylesheet" href="toc.css" type="text/css" />
<link rel="stylesheet" href="font-awesome.min.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Estadística Aplicada III</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Temario y referencias</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#evaluacion"><i class="fa fa-check"></i>Evaluación</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#software-r-y-rstudio"><i class="fa fa-check"></i>Software: R y Rstudio</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#referencias-principales"><i class="fa fa-check"></i>Referencias principales</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#otras-referencias"><i class="fa fa-check"></i>Otras referencias</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#tareas"><i class="fa fa-check"></i>Tareas</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introducción</a><ul>
<li class="chapter" data-level="1.1" data-path="intro.html"><a href="intro.html#por-que-un-analisis-multivariado"><i class="fa fa-check"></i><b>1.1</b> ¿Por qué un análisis multivariado?</a></li>
<li class="chapter" data-level="1.2" data-path="intro.html"><a href="intro.html#la-paradoja-de-simpson"><i class="fa fa-check"></i><b>1.2</b> La paradoja de Simpson</a></li>
<li class="chapter" data-level="1.3" data-path="intro.html"><a href="intro.html#modelos-log-lineales"><i class="fa fa-check"></i><b>1.3</b> Modelos log-lineales</a></li>
<li class="chapter" data-level="1.4" data-path="intro.html"><a href="intro.html#interpretacion-de-parametros"><i class="fa fa-check"></i><b>1.4</b> Interpretación de parámetros</a><ul>
<li class="chapter" data-level="1.4.1" data-path="intro.html"><a href="intro.html#ejemplo-dos-monedas"><i class="fa fa-check"></i><b>1.4.1</b> Ejemplo: dos monedas</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="intro.html"><a href="intro.html#otros-ejemplos"><i class="fa fa-check"></i><b>1.5</b> Otros ejemplos</a><ul>
<li class="chapter" data-level="1.5.1" data-path="intro.html"><a href="intro.html#discriminacion-de-residentes-hispanos-con-discapacidades"><i class="fa fa-check"></i><b>1.5.1</b> Discriminación de residentes hispanos con discapacidades</a></li>
<li class="chapter" data-level="1.5.2" data-path="intro.html"><a href="intro.html#consumo-de-chocolate-y-premios-nobel"><i class="fa fa-check"></i><b>1.5.2</b> Consumo de chocolate y premios Nobel</a></li>
</ul></li>
<li class="chapter" data-level="1.6" data-path="intro.html"><a href="intro.html#tarea"><i class="fa fa-check"></i><b>1.6</b> Tarea</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="Rintro.html"><a href="Rintro.html"><i class="fa fa-check"></i><b>2</b> Temas selectos de R</a><ul>
<li class="chapter" data-level="2.1" data-path="Rintro.html"><a href="Rintro.html#que-ventajas-tiene-r"><i class="fa fa-check"></i><b>2.1</b> ¿Qué ventajas tiene R?</a><ul>
<li class="chapter" data-level="2.1.1" data-path="Rintro.html"><a href="Rintro.html#r-es-gratuito-y-de-codigo-abierto"><i class="fa fa-check"></i><b>2.1.1</b> R es gratuito y de código abierto</a></li>
<li class="chapter" data-level="2.1.2" data-path="Rintro.html"><a href="Rintro.html#r-tiene-una-comunidad-comprometida"><i class="fa fa-check"></i><b>2.1.2</b> R tiene una comunidad comprometida</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="Rintro.html"><a href="Rintro.html#flujo-basico-de-trabajo-para-el-analisis-de-datos-en-r."><i class="fa fa-check"></i><b>2.2</b> Flujo básico de trabajo para el análisis de datos en R.</a></li>
<li class="chapter" data-level="2.3" data-path="Rintro.html"><a href="Rintro.html#introduccion-a-r-como-lenguaje-de-programacion-y-la-plataforma-interactiva-de-rstudio."><i class="fa fa-check"></i><b>2.3</b> Introducción a R como lenguaje de programación, y la plataforma interactiva de RStudio.</a><ul>
<li class="chapter" data-level="2.3.1" data-path="Rintro.html"><a href="Rintro.html#como-entender-r"><i class="fa fa-check"></i><b>2.3.1</b> ¿Cómo entender R?</a></li>
<li class="chapter" data-level="2.3.2" data-path="Rintro.html"><a href="Rintro.html#por-que-r"><i class="fa fa-check"></i><b>2.3.2</b> ¿Por qué R?</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="Rintro.html"><a href="Rintro.html#estructuras-de-datos"><i class="fa fa-check"></i><b>2.4</b> Estructuras de datos</a><ul>
<li class="chapter" data-level="2.4.1" data-path="Rintro.html"><a href="Rintro.html#vectores"><i class="fa fa-check"></i><b>2.4.1</b> Vectores</a></li>
<li class="chapter" data-level="2.4.2" data-path="Rintro.html"><a href="Rintro.html#data-frames"><i class="fa fa-check"></i><b>2.4.2</b> Data Frames</a></li>
<li class="chapter" data-level="2.4.3" data-path="Rintro.html"><a href="Rintro.html#listas"><i class="fa fa-check"></i><b>2.4.3</b> Listas</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="Rintro.html"><a href="Rintro.html#r-markdown"><i class="fa fa-check"></i><b>2.5</b> R Markdown</a><ul>
<li class="chapter" data-level="2.5.1" data-path="Rintro.html"><a href="Rintro.html#que-es-r-markdown"><i class="fa fa-check"></i><b>2.5.1</b> ¿Qué es R Markdown?</a></li>
<li class="chapter" data-level="2.5.2" data-path="Rintro.html"><a href="Rintro.html#estructura-basica-de-r-markdown"><i class="fa fa-check"></i><b>2.5.2</b> Estructura básica de R Markdown</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="Rintro.html"><a href="Rintro.html#proyectos-de-rstudio"><i class="fa fa-check"></i><b>2.6</b> Proyectos de RStudio</a></li>
<li class="chapter" data-level="2.7" data-path="Rintro.html"><a href="Rintro.html#otros-aspectos-importantes-de-r"><i class="fa fa-check"></i><b>2.7</b> Otros aspectos importantes de R</a><ul>
<li class="chapter" data-level="2.7.1" data-path="Rintro.html"><a href="Rintro.html#valores-faltantes"><i class="fa fa-check"></i><b>2.7.1</b> Valores faltantes</a></li>
<li class="chapter" data-level="2.7.2" data-path="Rintro.html"><a href="Rintro.html#funciones"><i class="fa fa-check"></i><b>2.7.2</b> Funciones</a></li>
<li class="chapter" data-level="2.7.3" data-path="Rintro.html"><a href="Rintro.html#funcionales"><i class="fa fa-check"></i><b>2.7.3</b> Funcionales</a></li>
<li class="chapter" data-level="2.7.4" data-path="Rintro.html"><a href="Rintro.html#rendimiento-en-r"><i class="fa fa-check"></i><b>2.7.4</b> Rendimiento en R</a></li>
</ul></li>
<li class="chapter" data-level="2.8" data-path="Rintro.html"><a href="Rintro.html#tarea-1"><i class="fa fa-check"></i><b>2.8</b> Tarea</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="manipulacion-y-visualizacion-de-datos.html"><a href="manipulacion-y-visualizacion-de-datos.html"><i class="fa fa-check"></i><b>3</b> Manipulación y visualización de datos</a><ul>
<li class="chapter" data-level="3.1" data-path="manipulacion-y-visualizacion-de-datos.html"><a href="manipulacion-y-visualizacion-de-datos.html#el-principio-de-datos-limpios"><i class="fa fa-check"></i><b>3.1</b> El principio de datos limpios</a></li>
<li class="chapter" data-level="3.2" data-path="manipulacion-y-visualizacion-de-datos.html"><a href="manipulacion-y-visualizacion-de-datos.html#limpieza-de-datos"><i class="fa fa-check"></i><b>3.2</b> Limpieza de datos</a></li>
<li class="chapter" data-level="3.3" data-path="manipulacion-y-visualizacion-de-datos.html"><a href="manipulacion-y-visualizacion-de-datos.html#separa-aplica-combina"><i class="fa fa-check"></i><b>3.3</b> <em>Separa-aplica-combina</em></a></li>
<li class="chapter" data-level="3.4" data-path="manipulacion-y-visualizacion-de-datos.html"><a href="manipulacion-y-visualizacion-de-datos.html#muertes-por-armas-de-fuego-en-eua"><i class="fa fa-check"></i><b>3.4</b> Muertes por armas de fuego en EUA</a></li>
<li class="chapter" data-level="3.5" data-path="manipulacion-y-visualizacion-de-datos.html"><a href="manipulacion-y-visualizacion-de-datos.html#el-cuarteto-de-anscombe"><i class="fa fa-check"></i><b>3.5</b> El Cuarteto de Anscombe</a></li>
<li class="chapter" data-level="3.6" data-path="manipulacion-y-visualizacion-de-datos.html"><a href="manipulacion-y-visualizacion-de-datos.html#the-grammar-of-graphics-de-leland-wilkinson"><i class="fa fa-check"></i><b>3.6</b> The <em>Grammar of Graphics</em> de Leland Wilkinson</a></li>
<li class="chapter" data-level="3.7" data-path="manipulacion-y-visualizacion-de-datos.html"><a href="manipulacion-y-visualizacion-de-datos.html#ggplot"><i class="fa fa-check"></i><b>3.7</b> ggplot</a></li>
<li class="chapter" data-level="3.8" data-path="manipulacion-y-visualizacion-de-datos.html"><a href="manipulacion-y-visualizacion-de-datos.html#un-histograma-de-las-muertes-en-iraq"><i class="fa fa-check"></i><b>3.8</b> Un histograma de las muertes en Iraq</a></li>
<li class="chapter" data-level="3.9" data-path="manipulacion-y-visualizacion-de-datos.html"><a href="manipulacion-y-visualizacion-de-datos.html#inglehartwelzel-un-mapa-cultural-del-mundo"><i class="fa fa-check"></i><b>3.9</b> Inglehart–Welzel: un mapa cultural del mundo</a><ul>
<li class="chapter" data-level="3.9.1" data-path="manipulacion-y-visualizacion-de-datos.html"><a href="manipulacion-y-visualizacion-de-datos.html#creando-un-ggplot"><i class="fa fa-check"></i><b>3.9.1</b> Creando un ggplot</a></li>
<li class="chapter" data-level="3.9.2" data-path="manipulacion-y-visualizacion-de-datos.html"><a href="manipulacion-y-visualizacion-de-datos.html#mapeos-aesthetics"><i class="fa fa-check"></i><b>3.9.2</b> Mapeos: Aesthetics</a></li>
</ul></li>
<li class="chapter" data-level="3.10" data-path="manipulacion-y-visualizacion-de-datos.html"><a href="manipulacion-y-visualizacion-de-datos.html#poniendo-todo-junto"><i class="fa fa-check"></i><b>3.10</b> Poniendo todo junto</a></li>
<li class="chapter" data-level="3.11" data-path="manipulacion-y-visualizacion-de-datos.html"><a href="manipulacion-y-visualizacion-de-datos.html#tarea-2"><i class="fa fa-check"></i><b>3.11</b> Tarea</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="teorema-del-limite-central.html"><a href="teorema-del-limite-central.html"><i class="fa fa-check"></i><b>4</b> Teorema del Límite Central</a><ul>
<li class="chapter" data-level="4.1" data-path="teorema-del-limite-central.html"><a href="teorema-del-limite-central.html#la-distribucion-de-la-media"><i class="fa fa-check"></i><b>4.1</b> La distribución de la media</a></li>
<li class="chapter" data-level="4.2" data-path="teorema-del-limite-central.html"><a href="teorema-del-limite-central.html#de-donde-proviene-la-distribucion-normal"><i class="fa fa-check"></i><b>4.2</b> ¿De dónde proviene la distribución normal?</a><ul>
<li class="chapter" data-level="4.2.1" data-path="teorema-del-limite-central.html"><a href="teorema-del-limite-central.html#que-signo-tiene-c"><i class="fa fa-check"></i><b>4.2.1</b> ¿Qué signo tiene c?</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="teorema-del-limite-central.html"><a href="teorema-del-limite-central.html#otras-observaciones"><i class="fa fa-check"></i><b>4.3</b> Otras observaciones</a></li>
<li class="chapter" data-level="4.4" data-path="teorema-del-limite-central.html"><a href="teorema-del-limite-central.html#diagramas-de-caja-y-brazos"><i class="fa fa-check"></i><b>4.4</b> Diagramas de caja y brazos</a><ul>
<li class="chapter" data-level="" data-path="teorema-del-limite-central.html"><a href="teorema-del-limite-central.html#ejemplo"><i class="fa fa-check"></i>Ejemplo</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="teorema-del-limite-central.html"><a href="teorema-del-limite-central.html#graficas-de-cuantiles-teoricos"><i class="fa fa-check"></i><b>4.5</b> Gráficas de cuantiles teóricos</a><ul>
<li class="chapter" data-level="" data-path="teorema-del-limite-central.html"><a href="teorema-del-limite-central.html#ejemplo-normal"><i class="fa fa-check"></i>Ejemplo: normal</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="teorema-del-limite-central.html"><a href="teorema-del-limite-central.html#graficas-de-cuantiles-para-un-conjunto-de-datos"><i class="fa fa-check"></i><b>4.6</b> Gráficas de cuantiles para un conjunto de datos</a><ul>
<li class="chapter" data-level="4.6.1" data-path="teorema-del-limite-central.html"><a href="teorema-del-limite-central.html#que-buscar-en-una-grafica-de-cuantiles"><i class="fa fa-check"></i><b>4.6.1</b> ¿Qué buscar en una gráfica de cuantiles?</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="teorema-del-limite-central.html"><a href="teorema-del-limite-central.html#graficas-qq-normales"><i class="fa fa-check"></i><b>4.7</b> Gráficas qq-normales</a><ul>
<li class="chapter" data-level="" data-path="teorema-del-limite-central.html"><a href="teorema-del-limite-central.html#ejemplo-cantantes"><i class="fa fa-check"></i>Ejemplo: cantantes</a></li>
</ul></li>
<li class="chapter" data-level="4.8" data-path="teorema-del-limite-central.html"><a href="teorema-del-limite-central.html#el-tlc-y-errores-estandar"><i class="fa fa-check"></i><b>4.8</b> El TLC y errores estándar</a></li>
<li class="chapter" data-level="4.9" data-path="teorema-del-limite-central.html"><a href="teorema-del-limite-central.html#ejemplo-1"><i class="fa fa-check"></i><b>4.9</b> Ejemplo</a></li>
<li class="chapter" data-level="4.10" data-path="teorema-del-limite-central.html"><a href="teorema-del-limite-central.html#tarea-3"><i class="fa fa-check"></i><b>4.10</b> Tarea</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="analisis-de-datos-categoricos.html"><a href="analisis-de-datos-categoricos.html"><i class="fa fa-check"></i><b>5</b> Análisis de datos categóricos</a><ul>
<li class="chapter" data-level="5.1" data-path="analisis-de-datos-categoricos.html"><a href="analisis-de-datos-categoricos.html#repaso-y-algunos-conceptos"><i class="fa fa-check"></i><b>5.1</b> Repaso y algunos conceptos</a><ul>
<li class="chapter" data-level="5.1.1" data-path="analisis-de-datos-categoricos.html"><a href="analisis-de-datos-categoricos.html#caso-binomial"><i class="fa fa-check"></i><b>5.1.1</b> Caso binomial</a></li>
<li class="chapter" data-level="" data-path="analisis-de-datos-categoricos.html"><a href="analisis-de-datos-categoricos.html#estimacion-de-parametros-multinomiales"><i class="fa fa-check"></i>Estimación de parámetros multinomiales</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="analisis-de-datos-categoricos.html"><a href="analisis-de-datos-categoricos.html#la-chi2-de-pearson-de-una-multinomial"><i class="fa fa-check"></i><b>5.2</b> La <span class="math inline">\(\chi^2\)</span> de Pearson de una multinomial</a><ul>
<li class="chapter" data-level="5.2.1" data-path="analisis-de-datos-categoricos.html"><a href="analisis-de-datos-categoricos.html#cociente-de-verosimilitud-de-una-multinomial"><i class="fa fa-check"></i><b>5.2.1</b> Cociente de verosimilitud de una multinomial</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="analisis-de-datos-categoricos.html"><a href="analisis-de-datos-categoricos.html#definiciones"><i class="fa fa-check"></i><b>5.3</b> Definiciones</a><ul>
<li class="chapter" data-level="5.3.1" data-path="analisis-de-datos-categoricos.html"><a href="analisis-de-datos-categoricos.html#notacion"><i class="fa fa-check"></i><b>5.3.1</b> Notación</a></li>
<li class="chapter" data-level="5.3.2" data-path="analisis-de-datos-categoricos.html"><a href="analisis-de-datos-categoricos.html#razon-de-momios"><i class="fa fa-check"></i><b>5.3.2</b> Razón de momios</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="analisis-de-datos-categoricos.html"><a href="analisis-de-datos-categoricos.html#asociacion-en-tablas-de-tamano-itimes-j"><i class="fa fa-check"></i><b>5.4</b> Asociación en tablas de tamaño <span class="math inline">\(I\times J\)</span></a><ul>
<li class="chapter" data-level="5.4.1" data-path="analisis-de-datos-categoricos.html"><a href="analisis-de-datos-categoricos.html#razones-de-momios-en-tablas-itimes-j"><i class="fa fa-check"></i><b>5.4.1</b> Razones de momios en tablas <span class="math inline">\(I\times J\)</span></a></li>
<li class="chapter" data-level="5.4.2" data-path="analisis-de-datos-categoricos.html"><a href="analisis-de-datos-categoricos.html#ejemplo-mushrooms"><i class="fa fa-check"></i><b>5.4.2</b> Ejemplo: mushrooms</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="analisis-de-datos-categoricos.html"><a href="analisis-de-datos-categoricos.html#intervalos-de-confianza-para-los-parametros-de-asociacion"><i class="fa fa-check"></i><b>5.5</b> Intervalos de confianza para los parámetros de asociación</a><ul>
<li class="chapter" data-level="5.5.1" data-path="analisis-de-datos-categoricos.html"><a href="analisis-de-datos-categoricos.html#error-estandar-de-la-razon-de-momios"><i class="fa fa-check"></i><b>5.5.1</b> Error estándar de la razón de momios</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="analisis-de-datos-categoricos.html"><a href="analisis-de-datos-categoricos.html#prueba-de-independencia"><i class="fa fa-check"></i><b>5.6</b> Prueba de independencia</a><ul>
<li class="chapter" data-level="5.6.1" data-path="analisis-de-datos-categoricos.html"><a href="analisis-de-datos-categoricos.html#la-prueba-chi2-de-pearson"><i class="fa fa-check"></i><b>5.6.1</b> La prueba <span class="math inline">\(\chi^2\)</span> de Pearson</a></li>
<li class="chapter" data-level="5.6.2" data-path="analisis-de-datos-categoricos.html"><a href="analisis-de-datos-categoricos.html#ejemplo-brecha-de-genero"><i class="fa fa-check"></i><b>5.6.2</b> Ejemplo: brecha de género</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="analisis-de-datos-categoricos.html"><a href="analisis-de-datos-categoricos.html#general-social-survey-1972---2016"><i class="fa fa-check"></i><b>5.7</b> General Social Survey 1972 - 2016</a></li>
<li class="chapter" data-level="5.8" data-path="analisis-de-datos-categoricos.html"><a href="analisis-de-datos-categoricos.html#la-catadora-de-te"><i class="fa fa-check"></i><b>5.8</b> La catadora de té</a></li>
<li class="chapter" data-level="5.9" data-path="analisis-de-datos-categoricos.html"><a href="analisis-de-datos-categoricos.html#modelos-multinomiales-para-conteos"><i class="fa fa-check"></i><b>5.9</b> Modelos multinomiales para conteos</a></li>
<li class="chapter" data-level="5.10" data-path="analisis-de-datos-categoricos.html"><a href="analisis-de-datos-categoricos.html#modelos-log-lineales-con-tres-variables-categoricas"><i class="fa fa-check"></i><b>5.10</b> Modelos log lineales con tres variables categóricas</a><ul>
<li class="chapter" data-level="5.10.1" data-path="analisis-de-datos-categoricos.html"><a href="analisis-de-datos-categoricos.html#tipos-de-independencia"><i class="fa fa-check"></i><b>5.10.1</b> Tipos de independencia</a></li>
<li class="chapter" data-level="5.10.2" data-path="analisis-de-datos-categoricos.html"><a href="analisis-de-datos-categoricos.html#asociacion-homogenea-e-interacciones-de-3-factores"><i class="fa fa-check"></i><b>5.10.2</b> Asociación homogénea e interacciones de 3 factores</a></li>
</ul></li>
<li class="chapter" data-level="5.11" data-path="analisis-de-datos-categoricos.html"><a href="analisis-de-datos-categoricos.html#ejemplo-sensitividad-y-especificidad"><i class="fa fa-check"></i><b>5.11</b> Ejemplo: sensitividad y especificidad</a></li>
<li class="chapter" data-level="5.12" data-path="analisis-de-datos-categoricos.html"><a href="analisis-de-datos-categoricos.html#ejemplo-horoscopos"><i class="fa fa-check"></i><b>5.12</b> Ejemplo: horóscopos</a></li>
<li class="chapter" data-level="5.13" data-path="analisis-de-datos-categoricos.html"><a href="analisis-de-datos-categoricos.html#tarea-opcional"><i class="fa fa-check"></i><b>5.13</b> Tarea (opcional)</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="regresion-logistica-1.html"><a href="regresion-logistica-1.html"><i class="fa fa-check"></i><b>6</b> Regresión logística 1</a><ul>
<li class="chapter" data-level="6.1" data-path="regresion-logistica-1.html"><a href="regresion-logistica-1.html#regresion-logistica-con-un-solo-predictor"><i class="fa fa-check"></i><b>6.1</b> Regresión logística con un solo predictor</a></li>
<li class="chapter" data-level="6.2" data-path="regresion-logistica-1.html"><a href="regresion-logistica-1.html#el-modelo-de-regresion-logistica"><i class="fa fa-check"></i><b>6.2</b> El modelo de regresión logística</a><ul>
<li class="chapter" data-level="6.2.1" data-path="regresion-logistica-1.html"><a href="regresion-logistica-1.html#funcion-logistica"><i class="fa fa-check"></i><b>6.2.1</b> Función logística</a></li>
<li class="chapter" data-level="" data-path="regresion-logistica-1.html"><a href="regresion-logistica-1.html#ejemplo-2"><i class="fa fa-check"></i>Ejemplo</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="regresion-logistica-1.html"><a href="regresion-logistica-1.html#tarea-4"><i class="fa fa-check"></i><b>6.3</b> Tarea</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="regresion-logistica-2.html"><a href="regresion-logistica-2.html"><i class="fa fa-check"></i><b>7</b> Regresión logística 2</a><ul>
<li class="chapter" data-level="7.1" data-path="regresion-logistica-2.html"><a href="regresion-logistica-2.html#incertidumbre-en-la-estimacion"><i class="fa fa-check"></i><b>7.1</b> Incertidumbre en la estimación</a></li>
<li class="chapter" data-level="7.2" data-path="regresion-logistica-2.html"><a href="regresion-logistica-2.html#funcion-logistica-1"><i class="fa fa-check"></i><b>7.2</b> Función logística</a></li>
<li class="chapter" data-level="7.3" data-path="regresion-logistica-2.html"><a href="regresion-logistica-2.html#interpretacion-de-los-coeficientes"><i class="fa fa-check"></i><b>7.3</b> Interpretación de los coeficientes</a><ul>
<li class="chapter" data-level="7.3.1" data-path="regresion-logistica-2.html"><a href="regresion-logistica-2.html#evaluar-en-o-alrededor-de-la-media"><i class="fa fa-check"></i><b>7.3.1</b> Evaluar en (o alrededor de) la media</a></li>
<li class="chapter" data-level="7.3.2" data-path="regresion-logistica-2.html"><a href="regresion-logistica-2.html#la-regla-de-dividir-entre-4"><i class="fa fa-check"></i><b>7.3.2</b> La regla de “dividir entre 4”</a></li>
<li class="chapter" data-level="7.3.3" data-path="regresion-logistica-2.html"><a href="regresion-logistica-2.html#interpretacion-de-los-coeficientes-como-cocientes-de-momios"><i class="fa fa-check"></i><b>7.3.3</b> Interpretación de los coeficientes como cocientes de momios</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="regresion-logistica-2.html"><a href="regresion-logistica-2.html#ejemplo-pozos-en-bangladesh"><i class="fa fa-check"></i><b>7.4</b> Ejemplo: pozos en Bangladesh</a><ul>
<li class="chapter" data-level="7.4.1" data-path="regresion-logistica-2.html"><a href="regresion-logistica-2.html#descripcion-del-problema"><i class="fa fa-check"></i><b>7.4.1</b> Descripción del problema</a></li>
<li class="chapter" data-level="7.4.2" data-path="regresion-logistica-2.html"><a href="regresion-logistica-2.html#antecedentes-del-problema"><i class="fa fa-check"></i><b>7.4.2</b> Antecedentes del problema</a></li>
<li class="chapter" data-level="7.4.3" data-path="regresion-logistica-2.html"><a href="regresion-logistica-2.html#metodologia-para-abordar-el-problema"><i class="fa fa-check"></i><b>7.4.3</b> Metodología para abordar el problema</a></li>
<li class="chapter" data-level="7.4.4" data-path="regresion-logistica-2.html"><a href="regresion-logistica-2.html#ajuste-y-resultados-del-modelo"><i class="fa fa-check"></i><b>7.4.4</b> Ajuste y resultados del modelo</a></li>
<li class="chapter" data-level="7.4.5" data-path="regresion-logistica-2.html"><a href="regresion-logistica-2.html#interpretacion-de-los-coeficientes-1"><i class="fa fa-check"></i><b>7.4.5</b> Interpretación de los coeficientes</a></li>
<li class="chapter" data-level="7.4.6" data-path="regresion-logistica-2.html"><a href="regresion-logistica-2.html#agregamos-una-segunda-variable-de-entrada"><i class="fa fa-check"></i><b>7.4.6</b> Agregamos una segunda variable de entrada</a></li>
<li class="chapter" data-level="7.4.7" data-path="regresion-logistica-2.html"><a href="regresion-logistica-2.html#comparacion-de-coeficientes-cuando-anades-un-predictor"><i class="fa fa-check"></i><b>7.4.7</b> Comparación de coeficientes cuando añades un predictor</a></li>
<li class="chapter" data-level="7.4.8" data-path="regresion-logistica-2.html"><a href="regresion-logistica-2.html#graficar-el-modelo-ajustado-con-dos-predictores"><i class="fa fa-check"></i><b>7.4.8</b> Graficar el modelo ajustado con dos predictores</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="regresion-logistica-2.html"><a href="regresion-logistica-2.html#ajuste-de-coeficientes-para-regresion-logistica-binomial."><i class="fa fa-check"></i><b>7.5</b> Ajuste de coeficientes para regresión logística (binomial).</a></li>
<li class="chapter" data-level="7.6" data-path="regresion-logistica-2.html"><a href="regresion-logistica-2.html#descenso-en-gradiente"><i class="fa fa-check"></i><b>7.6</b> Descenso en gradiente</a><ul>
<li class="chapter" data-level="7.6.1" data-path="regresion-logistica-2.html"><a href="regresion-logistica-2.html#seleccion-de-tamano-de-paso-eta"><i class="fa fa-check"></i><b>7.6.1</b> Selección de tamaño de paso <span class="math inline">\(\eta\)</span></a></li>
<li class="chapter" data-level="7.6.2" data-path="regresion-logistica-2.html"><a href="regresion-logistica-2.html#funciones-de-varias-variables"><i class="fa fa-check"></i><b>7.6.2</b> Funciones de varias variables</a></li>
</ul></li>
<li class="chapter" data-level="7.7" data-path="regresion-logistica-2.html"><a href="regresion-logistica-2.html#ejemplo-diabetes"><i class="fa fa-check"></i><b>7.7</b> Ejemplo: diabetes</a></li>
<li class="chapter" data-level="7.8" data-path="regresion-logistica-2.html"><a href="regresion-logistica-2.html#observaciones-adicionales"><i class="fa fa-check"></i><b>7.8</b> Observaciones adicionales</a></li>
<li class="chapter" data-level="7.9" data-path="regresion-logistica-2.html"><a href="regresion-logistica-2.html#regresion-logistica-para-problemas-de-mas-de-2-clases"><i class="fa fa-check"></i><b>7.9</b> Regresión logística para problemas de más de 2 clases</a></li>
<li class="chapter" data-level="7.10" data-path="regresion-logistica-2.html"><a href="regresion-logistica-2.html#regresion-logistica-multinomial"><i class="fa fa-check"></i><b>7.10</b> Regresión logística multinomial</a></li>
<li class="chapter" data-level="7.11" data-path="regresion-logistica-2.html"><a href="regresion-logistica-2.html#identificabilidad-y-separacion"><i class="fa fa-check"></i><b>7.11</b> Identificabilidad y separación</a></li>
<li class="chapter" data-level="7.12" data-path="regresion-logistica-2.html"><a href="regresion-logistica-2.html#tarea-5"><i class="fa fa-check"></i><b>7.12</b> Tarea</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="regresion-logistica-3.html"><a href="regresion-logistica-3.html"><i class="fa fa-check"></i><b>8</b> Regresión logística 3</a><ul>
<li class="chapter" data-level="8.1" data-path="regresion-logistica-3.html"><a href="regresion-logistica-3.html#ejemplo-oscares"><i class="fa fa-check"></i><b>8.1</b> Ejemplo óscares</a></li>
<li class="chapter" data-level="8.2" data-path="regresion-logistica-3.html"><a href="regresion-logistica-3.html#repaso-de-regresion-logistica"><i class="fa fa-check"></i><b>8.2</b> Repaso de regresión logística</a></li>
<li class="chapter" data-level="8.3" data-path="regresion-logistica-3.html"><a href="regresion-logistica-3.html#regresion-logistica-con-interacciones"><i class="fa fa-check"></i><b>8.3</b> Regresión logística con interacciones</a></li>
<li class="chapter" data-level="8.4" data-path="regresion-logistica-3.html"><a href="regresion-logistica-3.html#graficas-del-modelo-con-interacciones"><i class="fa fa-check"></i><b>8.4</b> Gráficas del modelo con interacciones</a></li>
<li class="chapter" data-level="8.5" data-path="regresion-logistica-3.html"><a href="regresion-logistica-3.html#agregar-mas-predictores"><i class="fa fa-check"></i><b>8.5</b> Agregar más predictores</a></li>
<li class="chapter" data-level="8.6" data-path="regresion-logistica-3.html"><a href="regresion-logistica-3.html#evaluacion-de-modelos-de-regresion-logistica"><i class="fa fa-check"></i><b>8.6</b> Evaluación de modelos de regresión logística</a><ul>
<li class="chapter" data-level="8.6.1" data-path="regresion-logistica-3.html"><a href="regresion-logistica-3.html#graficas-de-residuales-agrupados-vs-predictores"><i class="fa fa-check"></i><b>8.6.1</b> Gráficas de residuales agrupados vs predictores</a></li>
<li class="chapter" data-level="8.6.2" data-path="regresion-logistica-3.html"><a href="regresion-logistica-3.html#transformaciones"><i class="fa fa-check"></i><b>8.6.2</b> Transformaciones</a></li>
<li class="chapter" data-level="8.6.3" data-path="regresion-logistica-3.html"><a href="regresion-logistica-3.html#tasa-de-error-y-comparacion-contra-el-modelo-nulo"><i class="fa fa-check"></i><b>8.6.3</b> Tasa de error y comparación contra el modelo nulo</a></li>
</ul></li>
<li class="chapter" data-level="8.7" data-path="regresion-logistica-3.html"><a href="regresion-logistica-3.html#diferencias-predictivas-promedio-en-la-escala-de-probabilidad"><i class="fa fa-check"></i><b>8.7</b> Diferencias predictivas promedio en la escala de probabilidad</a><ul>
<li class="chapter" data-level="" data-path="regresion-logistica-3.html"><a href="regresion-logistica-3.html#diferencias-predictivas-promedio-en-presencia-de-interacciones"><i class="fa fa-check"></i>Diferencias predictivas promedio en presencia de interacciones</a></li>
<li class="chapter" data-level="" data-path="regresion-logistica-3.html"><a href="regresion-logistica-3.html#notacion-general-para-diferencias-predictivas"><i class="fa fa-check"></i>Notación general para diferencias predictivas</a></li>
</ul></li>
<li class="chapter" data-level="8.8" data-path="regresion-logistica-3.html"><a href="regresion-logistica-3.html#tarea-6"><i class="fa fa-check"></i><b>8.8</b> Tarea</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="regularizacion.html"><a href="regularizacion.html"><i class="fa fa-check"></i><b>9</b> Regularización</a><ul>
<li class="chapter" data-level="9.1" data-path="regularizacion.html"><a href="regularizacion.html#repaso"><i class="fa fa-check"></i><b>9.1</b> Repaso</a></li>
<li class="chapter" data-level="9.2" data-path="regularizacion.html"><a href="regularizacion.html#otras-medidas-de-clasificacion"><i class="fa fa-check"></i><b>9.2</b> Otras medidas de clasificación</a></li>
<li class="chapter" data-level="9.3" data-path="regularizacion.html"><a href="regularizacion.html#analisis-de-error-en-clasificacion-binaria"><i class="fa fa-check"></i><b>9.3</b> Análisis de error en clasificación binaria</a><ul>
<li class="chapter" data-level="9.3.1" data-path="regularizacion.html"><a href="regularizacion.html#punto-de-corte-para-un-clasificador-binario"><i class="fa fa-check"></i><b>9.3.1</b> Punto de corte para un clasificador binario</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="regularizacion.html"><a href="regularizacion.html#curvas-roc"><i class="fa fa-check"></i><b>9.4</b> Curvas ROC</a><ul>
<li class="chapter" data-level="9.4.1" data-path="regularizacion.html"><a href="regularizacion.html#espacio-roc"><i class="fa fa-check"></i><b>9.4.1</b> Espacio ROC</a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="regularizacion.html"><a href="regularizacion.html#regularizacion-1"><i class="fa fa-check"></i><b>9.5</b> Regularización</a><ul>
<li class="chapter" data-level="9.5.1" data-path="regularizacion.html"><a href="regularizacion.html#reduciendo-varianza-de-los-coeficientes"><i class="fa fa-check"></i><b>9.5.1</b> Reduciendo varianza de los coeficientes</a></li>
</ul></li>
<li class="chapter" data-level="9.6" data-path="regularizacion.html"><a href="regularizacion.html#regularizacion-ridge"><i class="fa fa-check"></i><b>9.6</b> Regularización Ridge</a><ul>
<li class="chapter" data-level="9.6.1" data-path="regularizacion.html"><a href="regularizacion.html#seleccion-de-coeficiente-de-regularizacion"><i class="fa fa-check"></i><b>9.6.1</b> Selección de coeficiente de regularización</a></li>
</ul></li>
<li class="chapter" data-level="9.7" data-path="regularizacion.html"><a href="regularizacion.html#regularizacion-lasso"><i class="fa fa-check"></i><b>9.7</b> Regularización Lasso</a></li>
<li class="chapter" data-level="9.8" data-path="regularizacion.html"><a href="regularizacion.html#tarea-7"><i class="fa fa-check"></i><b>9.8</b> Tarea</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="modelos-lineales-generalizados.html"><a href="modelos-lineales-generalizados.html"><i class="fa fa-check"></i><b>10</b> Modelos lineales generalizados</a><ul>
<li class="chapter" data-level="10.1" data-path="modelos-lineales-generalizados.html"><a href="modelos-lineales-generalizados.html#regresion-lineal-y-logistica"><i class="fa fa-check"></i><b>10.1</b> Regresión lineal y logística</a></li>
<li class="chapter" data-level="10.2" data-path="modelos-lineales-generalizados.html"><a href="modelos-lineales-generalizados.html#otros-modelos"><i class="fa fa-check"></i><b>10.2</b> Otros modelos</a></li>
<li class="chapter" data-level="10.3" data-path="modelos-lineales-generalizados.html"><a href="modelos-lineales-generalizados.html#ejemplo-accidentes-de-trafico"><i class="fa fa-check"></i><b>10.3</b> Ejemplo: accidentes de tráfico</a></li>
<li class="chapter" data-level="10.4" data-path="modelos-lineales-generalizados.html"><a href="modelos-lineales-generalizados.html#interpretacion-de-coeficientes-poisson"><i class="fa fa-check"></i><b>10.4</b> Interpretación de coeficientes Poisson</a></li>
<li class="chapter" data-level="10.5" data-path="modelos-lineales-generalizados.html"><a href="modelos-lineales-generalizados.html#diferencias-entre-el-modelo-binomial-y-poisson"><i class="fa fa-check"></i><b>10.5</b> Diferencias entre el modelo binomial y Poisson</a></li>
<li class="chapter" data-level="10.6" data-path="modelos-lineales-generalizados.html"><a href="modelos-lineales-generalizados.html#ejemplo-fertilidad-en-fiji"><i class="fa fa-check"></i><b>10.6</b> Ejemplo: fertilidad en Fiji</a></li>
<li class="chapter" data-level="10.7" data-path="modelos-lineales-generalizados.html"><a href="modelos-lineales-generalizados.html#variable-de-expuestos-offset"><i class="fa fa-check"></i><b>10.7</b> Variable de expuestos (offset)</a></li>
<li class="chapter" data-level="10.8" data-path="modelos-lineales-generalizados.html"><a href="modelos-lineales-generalizados.html#ejemplos-seguros"><i class="fa fa-check"></i><b>10.8</b> Ejemplos: seguros</a><ul>
<li class="chapter" data-level="" data-path="modelos-lineales-generalizados.html"><a href="modelos-lineales-generalizados.html#numero-de-expuestos-interpretacion"><i class="fa fa-check"></i>Número de expuestos (interpretación)</a></li>
</ul></li>
<li class="chapter" data-level="10.9" data-path="modelos-lineales-generalizados.html"><a href="modelos-lineales-generalizados.html#ejemplo-arboles"><i class="fa fa-check"></i><b>10.9</b> Ejemplo: árboles</a></li>
<li class="chapter" data-level="10.10" data-path="modelos-lineales-generalizados.html"><a href="modelos-lineales-generalizados.html#sobredispersion"><i class="fa fa-check"></i><b>10.10</b> Sobredispersión</a></li>
<li class="chapter" data-level="10.11" data-path="modelos-lineales-generalizados.html"><a href="modelos-lineales-generalizados.html#ejemplo-numero-de-publicaciones"><i class="fa fa-check"></i><b>10.11</b> Ejemplo: número de publicaciones</a></li>
<li class="chapter" data-level="10.12" data-path="modelos-lineales-generalizados.html"><a href="modelos-lineales-generalizados.html#tarea-8"><i class="fa fa-check"></i><b>10.12</b> Tarea</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="discriminante-lineal-lda-1.html"><a href="discriminante-lineal-lda-1.html"><i class="fa fa-check"></i><b>11</b> Discriminante Lineal (LDA) 1</a><ul>
<li class="chapter" data-level="11.1" data-path="discriminante-lineal-lda-1.html"><a href="discriminante-lineal-lda-1.html#problemas-de-clasificacion"><i class="fa fa-check"></i><b>11.1</b> Problemas de clasificación</a></li>
<li class="chapter" data-level="11.2" data-path="discriminante-lineal-lda-1.html"><a href="discriminante-lineal-lda-1.html#funciones-de-discriminante"><i class="fa fa-check"></i><b>11.2</b> Funciones de discriminante</a></li>
<li class="chapter" data-level="11.3" data-path="discriminante-lineal-lda-1.html"><a href="discriminante-lineal-lda-1.html#regresion-lineal-en-una-matriz-indicadora"><i class="fa fa-check"></i><b>11.3</b> Regresión lineal en una matriz indicadora</a></li>
<li class="chapter" data-level="11.4" data-path="discriminante-lineal-lda-1.html"><a href="discriminante-lineal-lda-1.html#discriminante-lineal-de-fisher"><i class="fa fa-check"></i><b>11.4</b> Discriminante lineal de Fisher</a><ul>
<li class="chapter" data-level="11.4.1" data-path="discriminante-lineal-lda-1.html"><a href="discriminante-lineal-lda-1.html#ejemplo-separacion-entre-clases"><i class="fa fa-check"></i><b>11.4.1</b> Ejemplo: separación entre clases</a></li>
<li class="chapter" data-level="11.4.2" data-path="discriminante-lineal-lda-1.html"><a href="discriminante-lineal-lda-1.html#ejemplo-iris-de-fisher"><i class="fa fa-check"></i><b>11.4.2</b> Ejemplo: iris de Fisher</a></li>
</ul></li>
<li class="chapter" data-level="11.5" data-path="discriminante-lineal-lda-1.html"><a href="discriminante-lineal-lda-1.html#tarea-9"><i class="fa fa-check"></i><b>11.5</b> Tarea</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="discriminante-lineal-lda-2.html"><a href="discriminante-lineal-lda-2.html"><i class="fa fa-check"></i><b>12</b> Discriminante Lineal (LDA) 2</a><ul>
<li class="chapter" data-level="12.1" data-path="discriminante-lineal-lda-2.html"><a href="discriminante-lineal-lda-2.html#aplicaciones"><i class="fa fa-check"></i><b>12.1</b> Aplicaciones</a></li>
<li class="chapter" data-level="12.2" data-path="discriminante-lineal-lda-2.html"><a href="discriminante-lineal-lda-2.html#ejemplo-vinos"><i class="fa fa-check"></i><b>12.2</b> Ejemplo: vinos</a></li>
<li class="chapter" data-level="12.3" data-path="discriminante-lineal-lda-2.html"><a href="discriminante-lineal-lda-2.html#ejemplo-admisiones-al-mba"><i class="fa fa-check"></i><b>12.3</b> Ejemplo: admisiones al MBA</a></li>
<li class="chapter" data-level="12.4" data-path="discriminante-lineal-lda-2.html"><a href="discriminante-lineal-lda-2.html#repaso-1"><i class="fa fa-check"></i><b>12.4</b> Repaso</a><ul>
<li><a href="discriminante-lineal-lda-2.html#caso-k2">Caso <span class="math inline">\(k=2\)</span></a></li>
</ul></li>
<li class="chapter" data-level="12.5" data-path="discriminante-lineal-lda-2.html"><a href="discriminante-lineal-lda-2.html#supuestos-probabilisticos"><i class="fa fa-check"></i><b>12.5</b> Supuestos probabilísticos</a></li>
<li class="chapter" data-level="12.6" data-path="discriminante-lineal-lda-2.html"><a href="discriminante-lineal-lda-2.html#relacion-con-minimos-cuadrados"><i class="fa fa-check"></i><b>12.6</b> Relación con mínimos cuadrados</a></li>
<li class="chapter" data-level="12.7" data-path="discriminante-lineal-lda-2.html"><a href="discriminante-lineal-lda-2.html#tarea-10"><i class="fa fa-check"></i><b>12.7</b> Tarea</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="componentes-principales-1.html"><a href="componentes-principales-1.html"><i class="fa fa-check"></i><b>13</b> Componentes Principales 1</a><ul>
<li class="chapter" data-level="13.1" data-path="componentes-principales-1.html"><a href="componentes-principales-1.html#motivacion"><i class="fa fa-check"></i><b>13.1</b> Motivación</a></li>
<li class="chapter" data-level="13.2" data-path="componentes-principales-1.html"><a href="componentes-principales-1.html#formulacion-de-maxima-varianza"><i class="fa fa-check"></i><b>13.2</b> Formulación de máxima varianza</a></li>
<li class="chapter" data-level="13.3" data-path="componentes-principales-1.html"><a href="componentes-principales-1.html#formulacion-de-error-minimo"><i class="fa fa-check"></i><b>13.3</b> Formulación de error mínimo</a></li>
<li class="chapter" data-level="13.4" data-path="componentes-principales-1.html"><a href="componentes-principales-1.html#aplicaciones-de-pca"><i class="fa fa-check"></i><b>13.4</b> Aplicaciones de PCA</a><ul>
<li class="chapter" data-level="13.4.1" data-path="componentes-principales-1.html"><a href="componentes-principales-1.html#compresion-de-datos"><i class="fa fa-check"></i><b>13.4.1</b> Compresión de datos</a></li>
<li class="chapter" data-level="13.4.2" data-path="componentes-principales-1.html"><a href="componentes-principales-1.html#ejemplo-compresion-de-una-imagen"><i class="fa fa-check"></i><b>13.4.2</b> Ejemplo: compresión de una imagen</a></li>
</ul></li>
<li class="chapter" data-level="13.5" data-path="componentes-principales-1.html"><a href="componentes-principales-1.html#tarea-11"><i class="fa fa-check"></i><b>13.5</b> Tarea</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="componentes-principales-2.html"><a href="componentes-principales-2.html"><i class="fa fa-check"></i><b>14</b> Componentes Principales 2</a><ul>
<li class="chapter" data-level="14.1" data-path="componentes-principales-2.html"><a href="componentes-principales-2.html#pca-probabilistico-y-analisis-de-factores"><i class="fa fa-check"></i><b>14.1</b> PCA probabilístico y Análisis de Factores</a><ul>
<li class="chapter" data-level="14.1.1" data-path="componentes-principales-2.html"><a href="componentes-principales-2.html#analisis-de-factores"><i class="fa fa-check"></i><b>14.1.1</b> Análisis de factores</a></li>
</ul></li>
<li class="chapter" data-level="14.2" data-path="componentes-principales-2.html"><a href="componentes-principales-2.html#analisis-de-factores-descripcion-tradicional"><i class="fa fa-check"></i><b>14.2</b> Análisis de factores (descripción tradicional)</a><ul>
<li class="chapter" data-level="14.2.1" data-path="componentes-principales-2.html"><a href="componentes-principales-2.html#el-modelo"><i class="fa fa-check"></i><b>14.2.1</b> El modelo</a></li>
<li class="chapter" data-level="14.2.2" data-path="componentes-principales-2.html"><a href="componentes-principales-2.html#estimacion-del-modelo"><i class="fa fa-check"></i><b>14.2.2</b> Estimación del modelo</a></li>
<li class="chapter" data-level="14.2.3" data-path="componentes-principales-2.html"><a href="componentes-principales-2.html#analisis-de-factores-de-maxima-verosimilitud"><i class="fa fa-check"></i><b>14.2.3</b> Análisis de factores de máxima verosimilitud</a></li>
<li class="chapter" data-level="14.2.4" data-path="componentes-principales-2.html"><a href="componentes-principales-2.html#evaluacion-del-modelo"><i class="fa fa-check"></i><b>14.2.4</b> Evaluación del modelo</a></li>
<li class="chapter" data-level="14.2.5" data-path="componentes-principales-2.html"><a href="componentes-principales-2.html#visualizacion"><i class="fa fa-check"></i><b>14.2.5</b> Visualización</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="componentes-principales-2.html"><a href="componentes-principales-2.html#tarea-12"><i class="fa fa-check"></i><b>14.3</b> Tarea</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="correlacion-canonica-cca.html"><a href="correlacion-canonica-cca.html"><i class="fa fa-check"></i><b>15</b> Correlación Canónica (CCA)</a><ul>
<li class="chapter" data-level="15.1" data-path="correlacion-canonica-cca.html"><a href="correlacion-canonica-cca.html#cca-vs-pca"><i class="fa fa-check"></i><b>15.1</b> CCA vs PCA</a></li>
<li class="chapter" data-level="15.2" data-path="correlacion-canonica-cca.html"><a href="correlacion-canonica-cca.html#variables-y-correlaciones-canonicas"><i class="fa fa-check"></i><b>15.2</b> Variables y correlaciones canónicas</a><ul>
<li class="chapter" data-level="15.2.1" data-path="correlacion-canonica-cca.html"><a href="correlacion-canonica-cca.html#combinaciones-lineaes-de-factores"><i class="fa fa-check"></i><b>15.2.1</b> Combinaciones lineaes de factores</a></li>
<li class="chapter" data-level="15.2.2" data-path="correlacion-canonica-cca.html"><a href="correlacion-canonica-cca.html#ejemplo-simple"><i class="fa fa-check"></i><b>15.2.2</b> Ejemplo simple</a></li>
</ul></li>
<li class="chapter" data-level="15.3" data-path="correlacion-canonica-cca.html"><a href="correlacion-canonica-cca.html#ejemplo-test-psicologico"><i class="fa fa-check"></i><b>15.3</b> Ejemplo: test psicológico</a></li>
<li class="chapter" data-level="15.4" data-path="correlacion-canonica-cca.html"><a href="correlacion-canonica-cca.html#tarea-13"><i class="fa fa-check"></i><b>15.4</b> Tarea</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="conglomerados-clustering-1.html"><a href="conglomerados-clustering-1.html"><i class="fa fa-check"></i><b>16</b> Conglomerados (clustering) 1</a><ul>
<li class="chapter" data-level="16.1" data-path="conglomerados-clustering-1.html"><a href="conglomerados-clustering-1.html#introduccion"><i class="fa fa-check"></i><b>16.1</b> Introducción</a><ul>
<li class="chapter" data-level="" data-path="conglomerados-clustering-1.html"><a href="conglomerados-clustering-1.html#ejemplo-7"><i class="fa fa-check"></i>Ejemplo</a></li>
</ul></li>
<li class="chapter" data-level="16.2" data-path="conglomerados-clustering-1.html"><a href="conglomerados-clustering-1.html#enfoques-combinatorio-y-basado-en-modelos."><i class="fa fa-check"></i><b>16.2</b> Enfoques: combinatorio y basado en modelos.</a></li>
<li class="chapter" data-level="16.3" data-path="conglomerados-clustering-1.html"><a href="conglomerados-clustering-1.html#k-medias"><i class="fa fa-check"></i><b>16.3</b> K-medias</a><ul>
<li class="chapter" data-level="" data-path="conglomerados-clustering-1.html"><a href="conglomerados-clustering-1.html#algoritmo-de-k-medias"><i class="fa fa-check"></i>Algoritmo de k-medias</a></li>
<li class="chapter" data-level="" data-path="conglomerados-clustering-1.html"><a href="conglomerados-clustering-1.html#ejemplo-8"><i class="fa fa-check"></i>Ejemplo</a></li>
<li><a href="conglomerados-clustering-1.html#usando-la-funcion-kmeans">Usando la funcion <code>kmeans</code></a></li>
</ul></li>
<li class="chapter" data-level="16.4" data-path="conglomerados-clustering-1.html"><a href="conglomerados-clustering-1.html#seleccion-de-numero-de-clusters."><i class="fa fa-check"></i><b>16.4</b> Selección de número de clusters.</a><ul>
<li class="chapter" data-level="" data-path="conglomerados-clustering-1.html"><a href="conglomerados-clustering-1.html#variacion-dentro-de-clusters-para-distintas-soluciones"><i class="fa fa-check"></i>Variación dentro de clusters para distintas soluciones</a></li>
<li class="chapter" data-level="16.4.1" data-path="conglomerados-clustering-1.html"><a href="conglomerados-clustering-1.html#criterios-especificos"><i class="fa fa-check"></i><b>16.4.1</b> Criterios específicos</a></li>
</ul></li>
<li class="chapter" data-level="16.5" data-path="conglomerados-clustering-1.html"><a href="conglomerados-clustering-1.html#dificultades-en-segmentacionclustering."><i class="fa fa-check"></i><b>16.5</b> Dificultades en segmentación/clustering.</a><ul>
<li class="chapter" data-level="16.5.1" data-path="conglomerados-clustering-1.html"><a href="conglomerados-clustering-1.html#estructuras-no-compactas"><i class="fa fa-check"></i><b>16.5.1</b> Estructuras no compactas</a></li>
<li class="chapter" data-level="16.5.2" data-path="conglomerados-clustering-1.html"><a href="conglomerados-clustering-1.html#existencia-o-no-de-grupos-naturales"><i class="fa fa-check"></i><b>16.5.2</b> Existencia o no de grupos “naturales”</a></li>
<li class="chapter" data-level="" data-path="conglomerados-clustering-1.html"><a href="conglomerados-clustering-1.html#grupos-en-dimension-alta"><i class="fa fa-check"></i>Grupos en dimensión alta</a></li>
<li class="chapter" data-level="" data-path="conglomerados-clustering-1.html"><a href="conglomerados-clustering-1.html#dificultades-en-la-seleccion-de-metrica"><i class="fa fa-check"></i>Dificultades en la selección de métrica</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="17" data-path="conglomerados-clustering-2.html"><a href="conglomerados-clustering-2.html"><i class="fa fa-check"></i><b>17</b> Conglomerados (clustering) 2</a><ul>
<li class="chapter" data-level="17.1" data-path="conglomerados-clustering-2.html"><a href="conglomerados-clustering-2.html#clustering-jerarquico"><i class="fa fa-check"></i><b>17.1</b> Clustering jerárquico</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="referencias.html"><a href="referencias.html"><i class="fa fa-check"></i>Referencias</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Publicado con bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Estadística Aplicada III</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="analisis-de-datos-categoricos" class="section level1">
<h1><span class="header-section-number">Clase 5</span> Análisis de datos categóricos</h1>
<style>
  .espacio {
     margin-bottom: 1cm;
  }
</style>
<style>
  .espacio3 {
     margin-bottom: 3cm;
  }
</style>
<p>Sólo necesitas instalar un paquete una vez, pero debes volver a cargarlo cada vez que inicies una nueva sesión.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(tidyverse)</code></pre></div>
<p>Las variables categóricas están por doquier. Desde ayudar a decidir cuándo un tratamiento médico es mejor hasta evaluar los factores que afectan nuestras opiniones y conductas, hoy en día los analistas encuentran innumerables usos para los métodos de datos categóricos. Primero vamos a repasar algunos conceptos de probabilidad.</p>
<div id="repaso-y-algunos-conceptos" class="section level2">
<h2><span class="header-section-number">5.1</span> Repaso y algunos conceptos</h2>
<p>Recordemos la <strong>distribución multinomial</strong>. Supongamos que cada uno de <span class="math inline">\(n\)</span> ensayos independientes e idénticos tiene realizaciones en <span class="math inline">\(c\)</span> categorías. Definimos <span class="math inline">\(y_{ij}\)</span> como <span class="math display">\[
y_{ij} = \left\{ \begin{array}{cl}
1 &amp; \text{si el }\; i\text{-esimo ensayo cae en la categoria }j,\\
0 &amp; \text{en otro caso.}
\end{array}\right.
\]</span></p>
<p>Entonces <span class="math inline">\(y_i=(y_{i1},y_{i2},\ldots,y_{ic})\)</span> representa <em>un</em> ensayo multinomial, done <span class="math display">\[
\displaystyle{\sum_j{y_{ij}}}=1.
\]</span></p>
<p>Notemos que <span class="math inline">\(y_{ic}=1-(y_{i1}+\cdots+y_{i,c-1})\)</span> es redundante. Sea <span class="math inline">\(n_j=\displaystyle{\sum_i{y_{ij}}}\)</span> el número de ensayos que caen en la categoría <span class="math inline">\(j\)</span>. Los conteos <span class="math inline">\((n_1,n_2,\ldots,n_c)\)</span> tienen una distribución multinomial.</p>
<p>Sea <span class="math inline">\(\pi_{j}=P(Y_{ij}=1)\)</span>, la probabilidad de éxito en la categoría <span class="math inline">\(j\)</span>. La función de masa de probabilidad de <span class="math inline">\((n_1,n_2,\ldots,n_c)\)</span> es <span class="math display">\[
p(n_1,n_2,\ldots,n_c) = \dfrac{n!}{n_1!n_2!\cdots n_c!}\pi_1^{n_1}\pi_2^{n_2}\cdots \pi_c^{n_c}.
\]</span></p>
<p>Sea <span class="math inline">\(n=\displaystyle{\sum_j{n_j}}\)</span>. Recordemos que esta ecuación es de dimensión <span class="math inline">\(c-1\)</span> porque <span class="math display">\[
n_c = n - (n_1 + n_2 + \cdots + n_{c-1}).
\]</span></p>
<p>Se puede ver que <span class="math display">\[
\begin{eqnarray*}
E(n_j) =n\pi_j, \quad &amp;&amp; V(n_j)=n\pi_j(1-\pi_j),\\
C(n_i,n_j)=-n\pi_i \pi_j&amp;\quad&amp;\mbox{si } i\neq j
\end{eqnarray*}
\]</span></p>
<p><strong>Modelo Poisson</strong></p>
<p>Sean <span class="math inline">\((Y_1,Y_2,\ldots,Y_c)\)</span> variables aleatorias Poisson independientes con parámetros <span class="math inline">\((\mu_1,\mu_2,\ldots,\mu_c)\)</span>. La función de masa de probabilidad conjunta es <span class="math display">\[
P(Y_1=n_1, Y_2=n_2, \ldots, Y_c=n_c) = \prod_i{\mbox{exp}(-\mu_i)\dfrac{\mu_i^{n_i}}{n_i!}}.
\]</span></p>
<p>El total <span class="math inline">\(n=\displaystyle{\sum_i{Y_i}}\)</span> también tiene una distribución Poisson con media <span class="math inline">\(\displaystyle{\sum_i{\mu_i}}\)</span>. Como <span class="math inline">\(n\)</span> también es una variable aleatoria, al condicionar en <span class="math inline">\(n\)</span>, <span class="math inline">\(\{Y_i\}\)</span> ya no tienen una distribución Poisson, pues cada <span class="math inline">\(Y_i\)</span> no puede exceder <span class="math inline">\(n\)</span>.</p>
<p>La distribución condicional es <span class="math display">\[
\begin{eqnarray*}
P\left(Y_1=n_1,\ldots,Y_c=n_c \,\middle|\,  \sum_j{Y_j}=n\right) &amp;=&amp; \dfrac{P(Y_1=n_1,\ldots,Y_c=n_c)}{P\left(\sum_j{Y_j}\right)} \\
&amp;=&amp; \dfrac{\prod_i \mbox{exp}(-\mu_i)\mu_i^{n_i}/n_i!}{\mbox{exp}\left(-\sum_j{\mu_j}\right)\left(\sum_j {\mu_j}\right)^n/n!} \\
&amp;=&amp; \dfrac{n!}{\prod_i n_i!} \prod_i{\pi_i^{n_i}}
\end{eqnarray*}
\]</span> con <span class="math inline">\(\pi_i = \dfrac{\mu_i}{\sum_i \mu_i}\)</span>, es decir, se trata de una distribución multinomial con parámetros <span class="math inline">\((n, \{\pi_i\})\)</span>.</p>
<p>Muchos análisis de datos categóricos suponen una distribución multinomial. Tales análisis usualmente tineen resultados similres a aquellos análisis que suponen una distribución Poisson, por las similitudes en sus funciones de verosimilitud.</p>
<hr />
<p><br></p>
<p>En la estimación de parámetros a menudo se utilizan dos métodos para obtener intervalos de confianza:</p>
<ol style="list-style-type: decimal">
<li>Método de Wald</li>
</ol>
<p>En el caso univariado se utiliza como estimador de la varianza <span class="math inline">\(-E\left(\dfrac{d^2 L(\theta)}{d\theta^2}\right)\)</span> y el estadístico es <span class="math display">\[z=(\hat{\theta} - \theta_0)/\mbox{SE} \sim N(0,1)\]</span> o en el caso multivariado, <span class="math display">\[
W = \left(\hat{\theta}- \theta_0\right)^T\left[\mbox{Cov}\left(\hat{\theta}\right)\right]^{-1}\left(\hat{\theta}- \theta_0\right),
\]</span> y como <span class="math inline">\(\hat{\theta}\)</span> se distribuye normal asintóticamente, entonces la distribución de <span class="math inline">\(W\)</span> es <span class="math inline">\(\chi^2\)</span> con grados de libertad igual al rango de <span class="math inline">\(\mbox{Cov}\left(\hat{\theta}\right)\)</span>, el número de parámetros no redundantes.</p>
<ol start="2" style="list-style-type: decimal">
<li>Método de cociente de verosimilitud</li>
</ol>
<p>Si <span class="math inline">\(l_0\)</span> es el máximo valor de la función de verosimilitud bajo <span class="math inline">\(H_0\)</span> y <span class="math inline">\(l_1\)</span> es el valor máximo sobre el espacio de parámetros (que contiene también el valor bajo <span class="math inline">\(H_0\)</span>), entonces <span class="math inline">\(l_0 \leq l_1\)</span> y el estadístico es</p>
<p><span class="math display">\[-2\,  \mbox{log}(\Lambda) = -2\,  \mbox{log}(l_0/l_1)=-2(L_0-L_1) \sim \chi^2_n\]</span> donde los grados de libertad equivalen a la diferencia de dimensiones de los espacios de parámetros.</p>
<div id="caso-binomial" class="section level3">
<h3><span class="header-section-number">5.1.1</span> Caso binomial</h3>
<p>Definimos la función de verosimilitud de una variable aleatoria binomial con <span class="math inline">\(n\)</span> realizaciones y <span class="math inline">\(x\)</span> éxitos:</p>
<p><span class="math display">\[
L(\theta) = \mbox{log}(\theta^x(1-\theta)^{n-x}) = x\mbox{log}(\theta) + (n-x)\mbox{log}(1-\theta)
\]</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">likelihood &lt;-<span class="st"> </span><span class="cf">function</span>(x, n){
  <span class="cf">function</span>(theta){x<span class="op">*</span><span class="kw">log</span>(theta) <span class="op">+</span><span class="st"> </span>(n<span class="op">-</span>x)<span class="op">*</span><span class="kw">log</span>(<span class="dv">1</span><span class="op">-</span>theta)}
}</code></pre></div>
<p>Creamos nuestra función de verosimilitud para <span class="math inline">\(x=3\)</span> y <span class="math inline">\(n=10\)</span>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mi_likelihood &lt;-<span class="st"> </span><span class="kw">likelihood</span>(<span class="dv">3</span>, <span class="dv">10</span>)</code></pre></div>
<p>Graficamos la función:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(<span class="dt">data =</span> <span class="kw">data.frame</span>(<span class="dt">x =</span> <span class="dv">0</span>), <span class="dt">mapping =</span> <span class="kw">aes</span>(<span class="dt">x =</span> x)) <span class="op">+</span>
<span class="st">  </span><span class="kw">stat_function</span>(<span class="dt">fun =</span> mi_likelihood) <span class="op">+</span><span class="st"> </span><span class="kw">xlim</span>(<span class="fl">0.001</span>,<span class="fl">0.999</span>)</code></pre></div>
<p><img src="05-datos_categoricos_files/figure-html/unnamed-chunk-5-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>El estadístico de Wald da como resultado el invervalo</p>
<p><span class="math display">\[
\hat{\theta} \pm z_{\alpha/2}\sqrt{\dfrac{\hat{\theta}(1-\hat{\theta})}{n}}
\]</span></p>
<p>El estadístico del cociente de verosimilitud es:</p>
<p><span class="math display">\[
2x\left[x\mbox{log}\left(\dfrac{\hat{\theta}}{\theta_0}\right)+(n-x)\mbox{log}\left(\dfrac{1-\hat{\theta}}{1-\theta_0}\right)\right] = \chi^2_{1,\alpha}
\]</span></p>
<p>Se puede expresar como</p>
<p><span class="math display">\[
2\sum{\mbox{observado} \,\left[\,\mbox{log}\left(\dfrac{\mbox{observado}}{\mbox{ajustado}}\right)\right]}
\]</span></p>
<p>Existen varios métodos para obtener intervalos de confianza. Utilizando la función <code>ciAllx</code> del paquete <code>proportion</code> podemos obtener intervalos de confianza para <span class="math inline">\(\hat{\theta}\)</span> a partir de 6 métodos:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(proportion)
intervalos &lt;-<span class="st"> </span><span class="kw">ciAllx</span>(<span class="dt">x =</span> <span class="dv">3</span>, <span class="dt">n =</span> <span class="dv">10</span>, <span class="dt">alp =</span> <span class="fl">0.05</span>) 
intervalos <span class="op">%&gt;%</span><span class="st"> </span>knitr<span class="op">::</span><span class="kw">kable</span>()</code></pre></div>
<table>
<thead>
<tr class="header">
<th align="left">method</th>
<th align="right">x</th>
<th align="right">LowerLimit</th>
<th align="right">UpperLimit</th>
<th align="left">LowerAbb</th>
<th align="left">UpperAbb</th>
<th align="left">ZWI</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Wald</td>
<td align="right">3</td>
<td align="right">0.016</td>
<td align="right">0.584</td>
<td align="left">NO</td>
<td align="left">NO</td>
<td align="left">NO</td>
</tr>
<tr class="even">
<td align="left">ArcSine</td>
<td align="right">3</td>
<td align="right">0.071</td>
<td align="right">0.603</td>
<td align="left">NO</td>
<td align="left">NO</td>
<td align="left">NO</td>
</tr>
<tr class="odd">
<td align="left">Likelihood</td>
<td align="right">3</td>
<td align="right">0.085</td>
<td align="right">0.607</td>
<td align="left">NO</td>
<td align="left">NO</td>
<td align="left">NO</td>
</tr>
<tr class="even">
<td align="left">Score</td>
<td align="right">3</td>
<td align="right">0.108</td>
<td align="right">0.603</td>
<td align="left">NO</td>
<td align="left">NO</td>
<td align="left">NO</td>
</tr>
<tr class="odd">
<td align="left">Logit-Wald</td>
<td align="right">3</td>
<td align="right">0.100</td>
<td align="right">0.624</td>
<td align="left">NO</td>
<td align="left">NO</td>
<td align="left">NO</td>
</tr>
<tr class="even">
<td align="left">Wald-T</td>
<td align="right">3</td>
<td align="right">0.002</td>
<td align="right">0.598</td>
<td align="left">NO</td>
<td align="left">NO</td>
<td align="left">NO</td>
</tr>
</tbody>
</table>
<p>Los intervalos de confianza para todos los métodos son realmente muy similares. Si el tamaño de muestra <span class="math inline">\(n\)</span> es grande, los 6 métodos dan como resultado intervalos de confianza prácticamente idénticos.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(intervalos, <span class="kw">aes</span>(<span class="dt">y =</span> method)) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_segment</span>(<span class="kw">aes</span>(<span class="dt">x =</span> LowerLimit, <span class="dt">xend =</span> UpperLimit, <span class="dt">y =</span> method, <span class="dt">yend =</span> method)) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_vline</span>(<span class="dt">xintercept =</span> <span class="fl">0.3</span>, <span class="dt">color =</span> <span class="st">&#39;red&#39;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">xlab</span>(<span class="st">&#39;Intervalo de confianza para cada método&#39;</span>)</code></pre></div>
<p><img src="05-datos_categoricos_files/figure-html/unnamed-chunk-7-1.png" width="60%" style="display: block; margin: auto;" /></p>
<hr />
<p><br></p>
</div>
<div id="estimacion-de-parametros-multinomiales" class="section level3 unnumbered">
<h3>Estimación de parámetros multinomiales</h3>
<p>Definimos la función de verosimilitud <span class="math display">\[
l(n_1,n_2,\ldots,n_c | \pi_1, \pi_2, \ldots, \pi_c) = c \prod_j \pi_j^{n_j}
\]</span> donde <span class="math inline">\(\pi_j \geq 0\)</span> y <span class="math inline">\(\sum_j{\pi_j}=1\)</span>.</p>
<p>Para estimar <span class="math inline">\(\{\pi_j\}\)</span> maximizamos la log-verosimilitud <span class="math display">\[
L(\pi) = \sum_j{n_j \mbox{log}(\pi_j)}.
\]</span></p>
<p>Para no tener redundancias vemos <span class="math inline">\(L\)</span> como función de <span class="math inline">\(\pi_1,\pi_2,\ldots,\pi_{c-1}\)</span> pues <span class="math inline">\(\pi_c=1-(\pi_1+ \pi_2+\cdots+\pi_{c-1})\)</span>. Por lo tanto, <span class="math display">\[
\dfrac{d \pi_c}{d \pi_j} = -1 \qquad \mbox{para }\; j=1,2,\ldots,c-1.
\]</span> Por la regla de la cadena, <span class="math display">\[
\dfrac{d\,\mbox{log}(\pi_c)}{d\,\pi_j}=\dfrac{1}{\pi_c} \cdot \dfrac{d\, \pi_c}{d\, \pi_j}=-\dfrac{1}{\pi_c}.
\]</span> Ahora diferenciamos <span class="math inline">\(L\)</span> con respecto a <span class="math inline">\(\pi_j\)</span> <span class="math display">\[
\dfrac{d\, L(\pi)}{d\, \pi_j}=\dfrac{n_j}{\pi_j} - \dfrac{n_c}{\pi_c} = 0.
\]</span> Por lo que los estimadores de máxima verosimilitud satisfacen que <span class="math display">\[
\dfrac{\hat{\pi}_j}{\hat{\pi}_c} = \dfrac{n_j}{n_c}.
\]</span> Ahora bien, <span class="math display">\[
1 = \sum_j{\pi_j}= \dfrac{\hat{\pi}_c\left(\sum_j n_j\right)}{n_c}=\dfrac{\hat{\pi}_c n}{n_c},
\]</span> y se tiene que <span class="math inline">\(\hat{\pi_c}=n_c/n\)</span> y <span class="math inline">\(\hat{\pi_j}=n_j/n\)</span> para <span class="math inline">\(j=1,2,\ldots,c-1\)</span>.</p>
<p>Se puede verificar que estos estimadores efectivamente maximizan la verosimilitud. Notemos que <span class="math inline">\(\hat{\pi_j}=n_j/n\)</span> son las proporciones muestrales.</p>
</div>
</div>
<div id="la-chi2-de-pearson-de-una-multinomial" class="section level2">
<h2><span class="header-section-number">5.2</span> La <span class="math inline">\(\chi^2\)</span> de Pearson de una multinomial</h2>
<p>En 1900 el estadístico Karl Pearson definió una prueba de hipótesis para la multinomial. Su motivación inicial fue analizar las probabilidades de ocurrencias de varias realizaciones en el juego de la ruleta. Consideramos para <span class="math inline">\(j=1,2,\ldots,c\)</span> <span class="math display">\[
H_0:\pi_j =\pi_{j0} \qquad H_1:\pi_j \neq \pi_{j0}.
\]</span></p>
<p>Bajo <span class="math inline">\(H_0\)</span>, los valores esperados de <span class="math inline">\(\{n_j\}\)</span>, llamadas <em>frecuencias esperadas</em> son <span class="math inline">\(\mu_j=n\pi_{j0}\)</span>, <span class="math inline">\(j=1,\ldots,c\)</span>. El estadístico propueto es <span class="math display">\[
X^2 = \sum_j{\dfrac{(n_j - \mu_j)^2}{\mu_j}} \sim \chi^2_{(c-1)}.
\]</span></p>
<p>Si las diferencias <span class="math inline">\(\{n_j - \mu_j\}\)</span> son más grandes, esto produce valores <span class="math inline">\(X^2\)</span> más grandes para una <span class="math inline">\(n\)</span> fija. Si <span class="math inline">\(X_o^2\)</span> es el valor observado de <span class="math inline">\(X^2\)</span> entonces el valor p es <span class="math inline">\(P(X^2 \geq X_o^2)\)</span>. Si <span class="math inline">\(n\)</span> es grande, <span class="math inline">\(X^2\)</span> tiene una distribución <span class="math inline">\(\chi^2_{c-1}\)</span>.</p>
<div id="cociente-de-verosimilitud-de-una-multinomial" class="section level3">
<h3><span class="header-section-number">5.2.1</span> Cociente de verosimilitud de una multinomial</h3>
<p>Bajo <span class="math inline">\(H_0\)</span> la verosimilitud se maximiza cuando <span class="math inline">\(\hat{\pi}_j=\pi_{j0}\)</span> y en el caso general cuando <span class="math inline">\(\hat{pi}_j=\frac{n_j}{n}\)</span>. El cociente de verosimilitud es</p>
<p><span class="math display">\[
\Lambda = \dfrac{\prod_j{\pi_{j0}^{n_j}}}{\prod_j{(n_j/n)^{n_j}}}.
\]</span> Por lo tanto, el estadístico del cociente de verosimilitud es</p>
<p><span class="math display">\[
G^2 = -2\,\mbox{log}(\Lambda) = 2\, \sum_j{n_j \mbox{log}\left(\dfrac{n_j}{n\pi_{j0}}\right)}.
\]</span></p>
<p>A este estadístico se le llama <em>estadístico <span class="math inline">\(\chi^2\)</span> de verosimilitud</em>. Entre más grande sea el valor de <span class="math inline">\(G^2\)</span> hay mayor evidencia en contra de <span class="math inline">\(H_0\)</span>. En el caso general, el espacio de parámetros consiste de <span class="math inline">\(\{\pi_j\}\)</span> sujeto a que <span class="math inline">\(\sum_j{\pi_j}=1\)</span>, por lo que la dimensión es <span class="math inline">\(c-1\)</span>. Bajo <span class="math inline">\(H_0\)</span>, se especifica por completo <span class="math inline">\(\{\pi_j\}\)</span>, por lo que la dimensión es <span class="math inline">\(0\)</span>. La diferencia entre estas dimensiones es <span class="math inline">\((c-1)\)</span>. Si <span class="math inline">\(n\)</span> es grande, entonces <span class="math inline">\(G^2\)</span> tiene una distribución <span class="math inline">\(\chi^2\)</span> con <span class="math inline">\((c-1)\)</span> grados de libertad.</p>
</div>
</div>
<div id="definiciones" class="section level2">
<h2><span class="header-section-number">5.3</span> Definiciones</h2>
<p>Supongamos que se tiene una tabla de contingencias. A continuación introduciremos una notación y algunas definiciones.</p>
<div id="notacion" class="section level3">
<h3><span class="header-section-number">5.3.1</span> Notación</h3>
<p>Sea <span class="math inline">\(\pi_{ij}\)</span> la probabilidad de que una observación <span class="math inline">\((X,Y)\)</span> esté en la celdilla (<span class="math inline">\(i\)</span>,<span class="math inline">\(j\)</span>). Las densidades marginales las denotamos por: <span class="math display">\[
\pi_{i+}=\sum_j{\pi_{ij}},\qquad \pi_{+j}  = \sum_i{\pi_{ij}}
\]</span> Cuando ambas variables son aleatorias, se pueden definir las densidades marginales: <span class="math display">\[
\pi_{j|i} = \pi_{ij}/\pi_{i+}, \qquad \mbox{para toda }i\mbox{ y }j
\]</span></p>
<p>Se dice que las variables son <strong>independientes</strong> si <span class="math display">\[
\pi_{ij} = \pi_{i+}\pi_{+j} \quad \mbox{para }\; i=1,\ldots,I\; \mbox{ y para }\; j=1,\ldots,J.
\]</span> Cuando son independientes se cumple que <span class="math display">\[
\pi_{j|i}=\pi_{ij}/\pi_{i+}=(\pi_{i+}\pi_{+j})/\pi_{i+}=\pi_{+j} \quad \mbox{para }i=1,\ldots,I.
\]</span></p>
</div>
<div id="razon-de-momios" class="section level3">
<h3><span class="header-section-number">5.3.2</span> Razón de momios</h3>

<div class="nota">
Para una probabilidad de éxito <span class="math inline">\(\pi\)</span> se definen los <em>momios</em> (o <em>chances</em>) como <span class="math display">\[
\Omega = \dfrac{\pi}{1-\pi}
\]</span> Los momios siempre son no negativos.
</div>

<p><strong>Ejemplo</strong></p>
<p>Un <strong>sitio de apuestas</strong> escribe:</p>
<blockquote>
<p>Momio 7/1: Ganas $7 por cada $1 apostado. Si apuestas $10, cobras $70 más tu apuesta, es decir, $80.</p>
</blockquote>
<blockquote>
<p>Momio 5/2: Ganas $5 por cada $2 apostados. Si apuestas $10, cobras $25 más tu apuesta, es decir, $35.</p>
</blockquote>
<blockquote>
<p>Momio 3/5: Ganas $3 por cada $5 apostados. Si apuestas $10, cobras $6 más tu apuesta, es decir, $16.</p>
</blockquote>
<p class="espacio">
</p>
<p><img src="figuras/apuesta.png" width="45%" style="display: block; margin: auto;" /></p>
<p class="espacio">
</p>
<p><br></p>
<img src="figuras/manicule2.jpg" />
<div class="centered">
<p class="espacio">
</p>
<p>Si el momio es menor que 1 entonces…</p>
<ol style="list-style-type: lower-alpha">
<li><p>La probabilidad de éxito es cero.</p></li>
<li><p>La probabilidad de éxito es menor que <span class="math inline">\(1/2\)</span>.</p></li>
<li><p>El éxito es más probable que el fracaso.</p></li>
<li><p>Todas la anteriores.</p></li>
</ol>
<p class="espacio3">
</p>
</div>
<p><br></p>

<div class="information">
Si <span class="math inline">\(\Omega &gt; 1\)</span>, entonces es más probable el éxito que el fracaso. Por ejemplo, cuando <span class="math inline">\(\pi=0.75\)</span> entonces <span class="math inline">\(\Omega = 0.75/0.25 =3\)</span>, un éxito es 3 veces más probable que un fracaso, y esperaríamos 3 éxitos por cada fracaso. Cuando <span class="math inline">\(\Omega = \frac{1}{3}\)</span> un fracaso es tres veces más verosímil que un éxito.
</div>

<p><br></p>
<p>Inversamente,</p>
<p><span class="math display">\[
\pi = \dfrac{\Omega}{\Omega + 1}.
\]</span></p>
<p>Pensemos nuevamente en una tabla de contingencias de <span class="math inline">\(2\times 2\)</span>, en la <span class="math inline">\(i\)</span>-ésima fila los momios de éxito en vez de fracaso son <span class="math inline">\(\Omega_i=\pi_i/(1-\pi_i)\)</span>. La <strong>razón de momios</strong> de <span class="math inline">\(\Omega_1\)</span> y <span class="math inline">\(\Omega_2\)</span> en ambas filas es:</p>
<p><span class="math display">\[
\theta = \dfrac{\Omega_1}{\Omega_2}=\dfrac{\pi_1/(1-\pi_1)}{\pi_2/(1-\pi_2)}
\]</span></p>
<p>Si se tiene una tabla con probabilidades conjuntas <span class="math inline">\(\{\pi_{ij}\}\)</span> la definición equivalente de momio para cada fila es <span class="math inline">\(\Omega_i=\pi_{i1}/\pi_{i2}\)</span>, <span class="math inline">\(i=1,2\)</span>. Entonces la razón de momios es:</p>
<p><span class="math display">\[
\theta = \dfrac{\pi_{11}/\pi_{12}}{\pi_{21}/\pi_{22}}=\dfrac{\pi_{11}\pi_{22}}{\pi_{12}\pi_{21}}
\]</span></p>
<p>A <span class="math inline">\(\theta\)</span> se le conoce también como la <em>razón del producto cruzado</em>.</p>

<div class="nota">
<p>¿Cómo interpretamos este número?</p>
<ul>
<li><p>Si <span class="math inline">\(\theta=1\)</span> (o <span class="math inline">\(\Omega_1=\Omega_2\)</span>), entonces las variables son independientes.</p></li>
<li><p>Si <span class="math inline">\(\theta &gt; 1\)</span>, entonces las observaciones en el renglón 1 tienen más probabilidad de éxito que observaciones en en renglón 2, es decir, <span class="math inline">\(\pi_1 &gt; \pi_2\)</span>.</p></li>
<li>Si <span class="math inline">\(\theta &lt; 1\)</span>, entonces <span class="math inline">\(\pi_1 &lt; \pi_2\)</span>.
</div>
</li>
</ul>
<p>Para conteos en una tabla de contingencia, la <em>razón de momios muestral</em> es:</p>
<p><span class="math display">\[
\hat{\theta} = \dfrac{n_{11}n_{22}}{n_{12}n_{21}}
\]</span></p>
<p>Regresemos a los datos de billboard:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">billboard &lt;-<span class="st"> </span><span class="kw">read_csv</span>(<span class="st">&quot;datos/billboard_alltime.csv&quot;</span>)</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">OR &lt;-<span class="st"> </span><span class="cf">function</span>(var1, var2){
  n &lt;-<span class="st"> </span><span class="kw">table</span>(var1, var2)
  
  (n[<span class="dv">1</span>,<span class="dv">1</span>] <span class="op">/</span><span class="st"> </span>n[<span class="dv">1</span>,<span class="dv">2</span>])<span class="op">*</span>(n[<span class="dv">2</span>,<span class="dv">2</span>] <span class="op">/</span><span class="st"> </span>n[<span class="dv">2</span>,<span class="dv">1</span>])
}
<span class="kw">OR</span>(billboard<span class="op">$</span>gains_performance, billboard<span class="op">$</span>rising)
<span class="co">#&gt; [1] 2.75</span></code></pre></div>
<p>Los chances de éxito (subir una o más posiciones en el chart) cuando no hubo una presentación en vivo (rengón 1) son equivalentes a 2.75 veces los chances de éxito (incremento en el chart) que cuando no hubo presentación en vivo (renglón 2).</p>
<p>Con la función <code>odds.ratio</code> del paquete <code>questionr</code> se puede calcular la razón de momios y el paquete hace una prueba de hipótesis conocida como <strong>prueba exacta de Fisher</strong>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(questionr)
<span class="kw">odds.ratio</span>(<span class="kw">table</span>(billboard<span class="op">$</span>gains_performance, billboard<span class="op">$</span>rising))
<span class="co">#&gt;                 OR 2.5 % 97.5 %      p    </span>
<span class="co">#&gt; Fisher&#39;s test 2.75  2.70    2.8 &lt;2e-16 ***</span>
<span class="co">#&gt; ---</span>
<span class="co">#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span></code></pre></div>

<div class="comentario">
<ul>
<li><p>Valores de <span class="math inline">\(\theta\)</span> más alejados de <span class="math inline">\(1\)</span> reflejan un mayor grado de asociación entre las variables.</p></li>
<li><p>Dos valores representan la misma asociación pero en direcciones opuestas, cuando uno es el recíproco del otro.</p></li>
<li>Por ejemplo, cuando <span class="math inline">\(\theta=0.25\)</span> los chances de éxito en el renglón 1 son 0.25 veces los chances en el renglón 2, o equivalentemente, los chances de éxito en el renglón 2 son 1/0.25 = 4 veces los chances en el renglón 1.
</div>
</li>
</ul>
<p class="espacio">
</p>
<img src="figuras/manicule2.jpg" />
<div class="centered">
<p class="espacio">
</p>
<p>Si se invierte el orden de los renglones o de las columnas, entonces <span class="math inline">\(\theta\)</span></p>
<ol style="list-style-type: lower-alpha">
<li><p>no cambia.</p></li>
<li><p>debe ser necesariamente <span class="math inline">\(1\)</span>.</p></li>
<li><p>es el recíproco de su valor original.</p></li>
<li><p>puede tomar cualquier valor.</p></li>
</ol>
<p class="espacio3">
</p>
</div>
<p><br></p>
<p>Para hacer inferencia es conveniente usar <span class="math inline">\(\mbox{log}(\theta)\)</span>. Este tiene las siguientes propiedades:</p>
<ol style="list-style-type: decimal">
<li><p>El caso de independencia corresponde a <span class="math inline">\(\mbox{log}(\theta) = 0\)</span>.</p></li>
<li><p>El logaritmo de la razón de momios es simétrico alrededor de <span class="math inline">\(0\)</span>.</p></li>
<li><p>Si se invierten los renglones o las columnas, entonces <span class="math inline">\(\mbox{log}(\theta)\)</span> cambia de signo pero tiene la misma magnitud. Por ejemplo, dos valores de <span class="math inline">\(\mbox{log}(\theta)\)</span> que tienen misma magnitud pero signos contrarios, como <span class="math inline">\(\mbox{log}(4)=1.39\)</span> y <span class="math inline">\(\mbox{log}(0.25)=-1.39\)</span>, representan el mismo grado de asociación.</p></li>
</ol>
</div>
</div>
<div id="asociacion-en-tablas-de-tamano-itimes-j" class="section level2">
<h2><span class="header-section-number">5.4</span> Asociación en tablas de tamaño <span class="math inline">\(I\times J\)</span></h2>
<p>En tablas de <span class="math inline">\(2\times 2\)</span> un sólo número como la razón de momios puede ser suficiente para resumir la asociación. En tablas <span class="math inline">\(I\times J\)</span> usualmente no es posible resumir la asociación entre las dos variables con un sólo número sin alguna pérdida de información. Sin embargo, un conjunto de razones de momios, o bien, algun otro estadístico de resumen pueden ser útil para describir la asociación entre las variables.</p>
<div id="razones-de-momios-en-tablas-itimes-j" class="section level3">
<h3><span class="header-section-number">5.4.1</span> Razones de momios en tablas <span class="math inline">\(I\times J\)</span></h3>
<p>Se puede utiliar los <span class="math inline">\(\dbinom{I}{2}\)</span> pares de renglones en combinación con los <span class="math inline">\(\dbinom{J}{2}\)</span> pares de columnas. Para renglones <span class="math inline">\(a\)</span> y <span class="math inline">\(b\)</span> y columnas <span class="math inline">\(c\)</span> y <span class="math inline">\(d\)</span> la razón de momios utiliza 4 valores en casillas en un patrón rectangular:</p>
<p><span class="math display">\[
\dfrac{\pi_{ab}\pi_{bd}}{\pi_{bc}\pi_{ad}}
\]</span></p>
<p>Consideremos el subconjunto de <span class="math inline">\((I-1)(J-1)\)</span> <em>razones de momios locales</em>:</p>
<p><span class="math display">\[
\theta_{ij} = \dfrac{\pi_{ij}\pi_{i+1,j+1}}{\pi_{i,j+1}\pi_{i+1,j}},  \qquad i=1,\ldots, I-1,\;\;\; j=1,\ldots,J-1.
\]</span></p>
<p>Estos <span class="math inline">\((I-1)(J-1)\)</span> razones de momios determinan las razones de momios entre pares de renglones y pares de columnas.</p>
</div>
<div id="ejemplo-mushrooms" class="section level3">
<h3><span class="header-section-number">5.4.2</span> Ejemplo: mushrooms</h3>
<p>Este conjunto de datos incluye descripciones de muestras correspondientes a 23 especies de setas de las familias Agaricus y Lepiota.</p>
<p>Cada especie está identificada como definitivamente comestible, definitivamente venenosa, o de comestibilidad desconocida y no recomendada su ingesta.</p>
<p>Las otras variables se presentan en la siguiente tabla:</p>
<table>
<colgroup>
<col width="21%" />
<col width="78%" />
</colgroup>
<thead>
<tr class="header">
<th>Variable</th>
<th>Categorías</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>cap-shape</td>
<td>bell=b,conical=c,convex=x,flat=f,knobbed=k,sunken=s</td>
</tr>
<tr class="even">
<td>cap-surface</td>
<td>fibrous=f,grooves=g,scaly=y,smooth=s</td>
</tr>
<tr class="odd">
<td>cap-color</td>
<td>brown=n,buff=b,cinnamon=c,gray=g,green=r,pink=p,purple=u,red=e,white=w,yellow=y</td>
</tr>
<tr class="even">
<td>bruises</td>
<td>bruises=t,no=f</td>
</tr>
<tr class="odd">
<td>odor</td>
<td>almond=a,anise=l,creosote=c,fishy=y,foul=f,musty=m,none=n,pungent=p,spicy=s</td>
</tr>
<tr class="even">
<td>gill-attachment</td>
<td>attached=a,descending=d,free=f,notched=n</td>
</tr>
<tr class="odd">
<td>gill-spacing</td>
<td>close=c,crowded=w,distant=d</td>
</tr>
<tr class="even">
<td>gill-size</td>
<td>broad=b,narrow=n</td>
</tr>
<tr class="odd">
<td>gill-color</td>
<td>black=k,brown=n,buff=b,chocolate=h,gray=g,green=r,orange=o,pink=p,purple=u,red=e,white=w,yellow=y</td>
</tr>
<tr class="even">
<td>stalk-shape</td>
<td>enlarging=e,tapering=t</td>
</tr>
<tr class="odd">
<td>stalk-root</td>
<td>bulbous=b,club=c,cup=u,equal=e,rhizomorphs=z,rooted=r,missing=?</td>
</tr>
<tr class="even">
<td>stalk-surface-above-ring</td>
<td>fibrous=f,scaly=y,silky=k,smooth=s</td>
</tr>
<tr class="odd">
<td>stalk-surface-below-ring</td>
<td>fibrous=f,scaly=y,silky=k,smooth=s</td>
</tr>
<tr class="even">
<td>stalk-color-above-ring</td>
<td>brown=n,buff=b,cinnamon=c,gray=g,orange=o,pink=p,red=e,white=w,yellow=y</td>
</tr>
<tr class="odd">
<td>stalk-color-below-ring</td>
<td>brown=n,buff=b,cinnamon=c,gray=g,orange=o,pink=p,red=e,white=w,yellow=y</td>
</tr>
<tr class="even">
<td>veil-type</td>
<td>partial=p,universal=u</td>
</tr>
<tr class="odd">
<td>veil-color</td>
<td>brown=n,orange=o,white=w,yellow=y</td>
</tr>
<tr class="even">
<td>ring-number</td>
<td>none=n,one=o,two=t</td>
</tr>
<tr class="odd">
<td>ring-type</td>
<td>cobwebby=c,evanescent=e,flaring=f,large=l,none=n,pendant=p,sheathing=s,zone=z</td>
</tr>
<tr class="even">
<td>spore-print-color</td>
<td>black=k,brown=n,buff=b,chocolate=h,green=r,orange=o,purple=u,white=w,yellow=y</td>
</tr>
<tr class="odd">
<td>population</td>
<td>abundant=a,clustered=c,numerous=n,scattered=s,several=v,solitary=y</td>
</tr>
<tr class="even">
<td>habitat</td>
<td>grasses=g,leaves=l,meadows=m,paths=p,urban=u,waste=w,woods=d</td>
</tr>
</tbody>
</table>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mushrooms &lt;-<span class="st"> </span><span class="kw">read_csv</span>(<span class="st">&quot;datos/mushrooms.csv&quot;</span>)
<span class="kw">glimpse</span>(mushrooms)
<span class="co">#&gt; Observations: 8,124</span>
<span class="co">#&gt; Variables: 23</span>
<span class="co">#&gt; $ edibility                  &lt;chr&gt; &quot;p&quot;, &quot;e&quot;, &quot;e&quot;, &quot;p&quot;, &quot;e&quot;, &quot;e&quot;, &quot;e&quot;, ...</span>
<span class="co">#&gt; $ `cap-shape`                &lt;chr&gt; &quot;x&quot;, &quot;x&quot;, &quot;b&quot;, &quot;x&quot;, &quot;x&quot;, &quot;x&quot;, &quot;b&quot;, ...</span>
<span class="co">#&gt; $ `cap-surface`              &lt;chr&gt; &quot;s&quot;, &quot;s&quot;, &quot;s&quot;, &quot;y&quot;, &quot;s&quot;, &quot;y&quot;, &quot;s&quot;, ...</span>
<span class="co">#&gt; $ `cap-color`                &lt;chr&gt; &quot;n&quot;, &quot;y&quot;, &quot;w&quot;, &quot;w&quot;, &quot;g&quot;, &quot;y&quot;, &quot;w&quot;, ...</span>
<span class="co">#&gt; $ bruises                    &lt;chr&gt; &quot;t&quot;, &quot;t&quot;, &quot;t&quot;, &quot;t&quot;, &quot;f&quot;, &quot;t&quot;, &quot;t&quot;, ...</span>
<span class="co">#&gt; $ odor                       &lt;chr&gt; &quot;p&quot;, &quot;a&quot;, &quot;l&quot;, &quot;p&quot;, &quot;n&quot;, &quot;a&quot;, &quot;a&quot;, ...</span>
<span class="co">#&gt; $ `gill-attachment`          &lt;chr&gt; &quot;f&quot;, &quot;f&quot;, &quot;f&quot;, &quot;f&quot;, &quot;f&quot;, &quot;f&quot;, &quot;f&quot;, ...</span>
<span class="co">#&gt; $ `gill-spacing`             &lt;chr&gt; &quot;c&quot;, &quot;c&quot;, &quot;c&quot;, &quot;c&quot;, &quot;w&quot;, &quot;c&quot;, &quot;c&quot;, ...</span>
<span class="co">#&gt; $ `gill-size`                &lt;chr&gt; &quot;n&quot;, &quot;b&quot;, &quot;b&quot;, &quot;n&quot;, &quot;b&quot;, &quot;b&quot;, &quot;b&quot;, ...</span>
<span class="co">#&gt; $ `gill-color`               &lt;chr&gt; &quot;k&quot;, &quot;k&quot;, &quot;n&quot;, &quot;n&quot;, &quot;k&quot;, &quot;n&quot;, &quot;g&quot;, ...</span>
<span class="co">#&gt; $ `stalk-shape`              &lt;chr&gt; &quot;e&quot;, &quot;e&quot;, &quot;e&quot;, &quot;e&quot;, &quot;t&quot;, &quot;e&quot;, &quot;e&quot;, ...</span>
<span class="co">#&gt; $ `stalk-root`               &lt;chr&gt; &quot;e&quot;, &quot;c&quot;, &quot;c&quot;, &quot;e&quot;, &quot;e&quot;, &quot;c&quot;, &quot;c&quot;, ...</span>
<span class="co">#&gt; $ `stalk-surface-above-ring` &lt;chr&gt; &quot;s&quot;, &quot;s&quot;, &quot;s&quot;, &quot;s&quot;, &quot;s&quot;, &quot;s&quot;, &quot;s&quot;, ...</span>
<span class="co">#&gt; $ `stalk-surface-below-ring` &lt;chr&gt; &quot;s&quot;, &quot;s&quot;, &quot;s&quot;, &quot;s&quot;, &quot;s&quot;, &quot;s&quot;, &quot;s&quot;, ...</span>
<span class="co">#&gt; $ `stalk-color-above-ring`   &lt;chr&gt; &quot;w&quot;, &quot;w&quot;, &quot;w&quot;, &quot;w&quot;, &quot;w&quot;, &quot;w&quot;, &quot;w&quot;, ...</span>
<span class="co">#&gt; $ `stalk-color-below-ring`   &lt;chr&gt; &quot;w&quot;, &quot;w&quot;, &quot;w&quot;, &quot;w&quot;, &quot;w&quot;, &quot;w&quot;, &quot;w&quot;, ...</span>
<span class="co">#&gt; $ `veil-type`                &lt;chr&gt; &quot;p&quot;, &quot;p&quot;, &quot;p&quot;, &quot;p&quot;, &quot;p&quot;, &quot;p&quot;, &quot;p&quot;, ...</span>
<span class="co">#&gt; $ `veil-color`               &lt;chr&gt; &quot;w&quot;, &quot;w&quot;, &quot;w&quot;, &quot;w&quot;, &quot;w&quot;, &quot;w&quot;, &quot;w&quot;, ...</span>
<span class="co">#&gt; $ `ring-number`              &lt;chr&gt; &quot;o&quot;, &quot;o&quot;, &quot;o&quot;, &quot;o&quot;, &quot;o&quot;, &quot;o&quot;, &quot;o&quot;, ...</span>
<span class="co">#&gt; $ `ring-type`                &lt;chr&gt; &quot;p&quot;, &quot;p&quot;, &quot;p&quot;, &quot;p&quot;, &quot;e&quot;, &quot;p&quot;, &quot;p&quot;, ...</span>
<span class="co">#&gt; $ `spore-print-color`        &lt;chr&gt; &quot;k&quot;, &quot;n&quot;, &quot;n&quot;, &quot;k&quot;, &quot;n&quot;, &quot;k&quot;, &quot;k&quot;, ...</span>
<span class="co">#&gt; $ population                 &lt;chr&gt; &quot;s&quot;, &quot;n&quot;, &quot;n&quot;, &quot;s&quot;, &quot;a&quot;, &quot;n&quot;, &quot;n&quot;, ...</span>
<span class="co">#&gt; $ habitat                    &lt;chr&gt; &quot;u&quot;, &quot;g&quot;, &quot;m&quot;, &quot;u&quot;, &quot;g&quot;, &quot;g&quot;, &quot;m&quot;, ...</span></code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(oddsratio)
mushrooms_<span class="dv">1</span> &lt;-<span class="st"> </span>mushrooms <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">edibility =</span> <span class="dv">1</span><span class="op">*</span>(edibility <span class="op">==</span><span class="st"> &#39;e&#39;</span>))
fit_glm &lt;-<span class="st"> </span><span class="kw">glm</span>(edibility <span class="op">~</span><span class="st"> `</span><span class="dt">cap-color</span><span class="st">`</span>, <span class="dt">data=</span>mushrooms_<span class="dv">1</span>, <span class="dt">family=</span><span class="st">&#39;binomial&#39;</span>)
or_mushrooms &lt;-<span class="st"> </span><span class="kw">or_glm</span>(<span class="dt">data =</span> mushrooms_<span class="dv">1</span>, <span class="dt">model =</span> fit_glm)</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">or_mushrooms <span class="op">%&gt;%</span><span class="st"> </span>knitr<span class="op">::</span><span class="kw">kable</span>()</code></pre></div>
<table>
<thead>
<tr class="header">
<th align="left">predictor</th>
<th align="right">oddsratio</th>
<th align="right">CI_low (2.5 %)</th>
<th align="right">CI_high (97.5 %)</th>
<th align="left">increment</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><code>cap-color</code>c</td>
<td align="right">6.67e+00</td>
<td align="right">3.247</td>
<td align="right">14.50</td>
<td align="left">Indicator variable</td>
</tr>
<tr class="even">
<td align="left"><code>cap-color</code>e</td>
<td align="right">1.78e+00</td>
<td align="right">1.263</td>
<td align="right">2.55</td>
<td align="left">Indicator variable</td>
</tr>
<tr class="odd">
<td align="left"><code>cap-color</code>g</td>
<td align="right">3.19e+00</td>
<td align="right">2.272</td>
<td align="right">4.56</td>
<td align="left">Indicator variable</td>
</tr>
<tr class="even">
<td align="left"><code>cap-color</code>n</td>
<td align="right">3.10e+00</td>
<td align="right">2.210</td>
<td align="right">4.41</td>
<td align="left">Indicator variable</td>
</tr>
<tr class="odd">
<td align="left"><code>cap-color</code>p</td>
<td align="right">1.59e+00</td>
<td align="right">0.992</td>
<td align="right">2.56</td>
<td align="left">Indicator variable</td>
</tr>
<tr class="even">
<td align="left"><code>cap-color</code>r</td>
<td align="right">5.30e+06</td>
<td align="right">4.411</td>
<td align="right">NA</td>
<td align="left">Indicator variable</td>
</tr>
<tr class="odd">
<td align="left"><code>cap-color</code>u</td>
<td align="right">5.30e+06</td>
<td align="right">4.411</td>
<td align="right">NA</td>
<td align="left">Indicator variable</td>
</tr>
<tr class="even">
<td align="left"><code>cap-color</code>w</td>
<td align="right">5.62e+00</td>
<td align="right">3.951</td>
<td align="right">8.12</td>
<td align="left">Indicator variable</td>
</tr>
<tr class="odd">
<td align="left"><code>cap-color</code>y</td>
<td align="right">1.49e+00</td>
<td align="right">1.048</td>
<td align="right">2.14</td>
<td align="left">Indicator variable</td>
</tr>
</tbody>
</table>
<p>En esta tabla se tienen dos columnas donde “e” siginifica que la seta es comestible y “p” que la seta es venenosa. En los renglones están los colores de las setas codificados de acuerdo con la tabla anterior. En las columnas están las razones de momio para cada color para aquellas setas que son comestibles.</p>
<p>Veamos la tabla de color y comestibilidad:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">table</span>(mushrooms<span class="op">$</span>edibility, mushrooms<span class="op">$</span><span class="st">`</span><span class="dt">cap-color</span><span class="st">`</span>)
<span class="co">#&gt;    </span>
<span class="co">#&gt;        b    c    e    g    n    p    r    u    w    y</span>
<span class="co">#&gt;   e   48   32  624 1032 1264   56   16   16  720  400</span>
<span class="co">#&gt;   p  120   12  876  808 1020   88    0    0  320  672</span></code></pre></div>
<p>Podemos ver que la razón de momios para p=pink y u=purple es “infinita” porque hay muy pocas observaciones para setas de esos colores. De cualquier forma, con los momios podemos concluir que aquellas setas de colores c=cinnamon y w=white aumentan los chances de que sean comestibles en 6.7 y 5.6, respectivamente.</p>
</div>
</div>
<div id="intervalos-de-confianza-para-los-parametros-de-asociacion" class="section level2">
<h2><span class="header-section-number">5.5</span> Intervalos de confianza para los parámetros de asociación</h2>
<p>La precisión de los esitmadores de asociación está caracterizada por las distribuciones muestrales de los errores estándar. Para tablas de <span class="math inline">\(2\times 2\)</span> recordemos que <span class="math display">\[
\hat{\theta} = \dfrac{n_{11}n_{22}}{n_{12}n_{21}}
\]</span></p>
<p>Se puede demostrar que <span class="math inline">\(\hat{\theta}\)</span> tiene una distribución normal asinotóticamente alrededor de <span class="math inline">\(\theta\)</span>. A menos que <span class="math inline">\(n\)</span> sea grande, la distribución muestral generalmente es sesgada.</p>
<div id="error-estandar-de-la-razon-de-momios" class="section level3">
<h3><span class="header-section-number">5.5.1</span> Error estándar de la razón de momios</h3>
<p>Utilizando la transformación de logaritmo, la estructura multiplicativa converge muy rápidamente a la normalidad. Una aproximación del error estándar para <span class="math inline">\(\mbox{log}(\hat{\theta})\)</span> es</p>
<p><span class="math display">\[
\hat{\sigma}(\mbox{log}\hat{\theta}) = \sqrt{\dfrac{1}{n_{11}}+\dfrac{1}{n_{12}}+\dfrac{1}{n_{21}}+\dfrac{1}{n_{22}}}.
\]</span></p>
<p>Como consecuencia de la normalidad de la distribución de <span class="math inline">\(\mbox{log}(\hat{\theta})\)</span>,</p>
<p><span class="math display">\[
\mbox{log}(\hat{\theta}) \pm z_{\alpha/2}\hat{\sigma}(\mbox{log}\hat{\theta})
\]</span></p>
</div>
</div>
<div id="prueba-de-independencia" class="section level2">
<h2><span class="header-section-number">5.6</span> Prueba de independencia</h2>
<p>Suponemos que se tiene resultados obtenidos de una distribución multinomial y probabilidades conjuntas <span class="math inline">\(\{\pi_{ij}\}\)</span> en una tabla de contingencia de dimensiones <span class="math inline">\(I\times J\)</span>.</p>

<div class="nota">
La hipótesis nula de independencia estadística es: <span class="math display">\[
H_0:\pi_{ij}=\pi_{i+}\pi_{+j},\qquad \text{ para toda }\;\; i \;\;\text{ y }\;\; j.
\]</span>
</div>

<div id="la-prueba-chi2-de-pearson" class="section level3">
<h3><span class="header-section-number">5.6.1</span> La prueba <span class="math inline">\(\chi^2\)</span> de Pearson</h3>
<p>Ya estudiamos la prueba para valores específicos de probabilidades multinomiales. Una prueba de <span class="math inline">\(H_0:\mbox{independencia}\)</span> utiliza la <span class="math inline">\(\chi^2\)</span> con <span class="math inline">\(n_{ij}\)</span> en lugar de <span class="math inline">\(n_i\)</span> y con <span class="math inline">\(\mu_{ij}=n\pi_{i+}\pi_{+j}\)</span> en lugar de <span class="math inline">\(\mu_i\)</span>.</p>

<div class="information">
<p>Bajo <span class="math inline">\(H_0\)</span>:</p>
<p><span class="math display">\[E(n_{ij}) = \mu_{ij}\]</span></p>
<p>Usualmente <span class="math inline">\(\{\pi_{i+}\}\)</span> y <span class="math inline">\(\{\pi_{+j}\}\)</span> son <em>conocidas</em>. Sus estimadores de máxima verosimilitud son <span class="math inline">\(\hat{\pi}_{i+}=n_{i+}/n\)</span> y <span class="math inline">\(\hat{\pi}_{+j}=n_{+j}/n\)</span>.</p>
<p>Las frecuencias esperadas estimadas son <span class="math display">\[
\{\hat{\mu}_{ij} = n\hat{\pi}_{i+}\hat{\pi}_{+j}=n_{i+}n_{+j}/n^2\}
\]</span></p>
Por lo tanto, el estadístico de Pearson es: <span class="math display">\[
X^2 = \displaystyle{\sum_{i}\sum_{j}{\dfrac{(n_{ij}-\hat{\mu}_{ij})^2}{\hat{\mu}_{ij}}}}.
\]</span>
</div>

<p>En 1900, el mismo Karl Pearson argumento que reemplazar las <span class="math inline">\(\{\mu_{ij}\}\)</span> por sus estimadores <span class="math inline">\(\{\hat{\mu}_{ij}\}\)</span> no afectaría la distribución muestral cuando se tiene una muestra grande. Como la tabla de contingencia tiene <span class="math inline">\(IJ\)</span> categorías, Pearson argumentó que la <span class="math inline">\(X^2\)</span> se distribuye como <em>chi cuadrada</em> asintóticamente con grados de libertad <span class="math inline">\(IJ-1\)</span>.</p>

<div class="nota">
<p>Sin embargo, años después (en 1922) Fisher publicó un artículo corrigiendo el error de Pearson. Lo que sucede es lo siguiente: estimar <span class="math inline">\(\{\hat{\mu}_{ij}\}\)</span> requiere de estimar <span class="math inline">\(\{\pi_{i+}\}\)</span> y <span class="math inline">\(\{\pi_{+j}\}\)</span>, por lo que los grados de libertad son:</p>
<span class="math display">\[
(IJ - 1) - (I-1) - (J-1) = (I-1)(J-1).
\]</span>
</div>

<p><strong>El estadístico de cociente de verosimilitud</strong></p>
<p>Para una muestra multinomial, el kernel de la verosimilitud es</p>
<p><span class="math display">\[
\prod_i \prod_j{\pi_{ij}^{n_{ij}}},\qquad \;\text{donde todas }\;\; \pi_{ij}\geq0\;\; \mbox{y}\;\;\sum_i \sum_j{\pi_{ij}}=1.
\]</span></p>
<p>Bajo <span class="math inline">\(H_0:\text{independencia}\)</span>, <span class="math inline">\(\hat{\pi}_{ij}=\hat{\pi}_{i+}\hat{\pi}_{+j}=n_{i+}n_{+j}/n^2\)</span>. En el caso general, <span class="math inline">\(\hat{\pi}_{ij}=n_{ij}/n\)</span>. El cociente de verosimilitud es igual a</p>
<p><span class="math display">\[
\Lambda = \dfrac{\prod_i \prod_j (n_{i+}n_{+j})^{n_{ij}}}{n^n\prod_i\prod_j{n_{ij}^{n_{ij}}}}.
\]</span></p>
<p>El estadístico del cociente de verosimilitud es <span class="math inline">\(-2\mbox{log}(\Lambda)\)</span>. Denotado por <span class="math inline">\(G^2\)</span>, es igual a:</p>
<p><span class="math display">\[
G^2 = -2\mbox{log}(\Lambda) = 2\sum_i\sum_j{n_{ij}\mbox{log}(n_{ij}/\hat{\mu}_{ij})}
\]</span></p>
<p>Entre más grandes sean los valores de <span class="math inline">\(G^2\)</span> y <span class="math inline">\(X^2\)</span>, mayor evidencia de independencia. En el caso general el espacio consiste de <span class="math inline">\(\{\pi_{ij}\}\)</span> sujeto a la restricción lineal de que deben sumar <span class="math inline">\(1\)</span>. El espacio de parámetros tiene dimensión <span class="math inline">\(IJ-1\)</span>. Bajo <span class="math inline">\(H_0\)</span> el espacio está determinado por <span class="math inline">\(\{\pi_{i+}\}\)</span> y <span class="math inline">\(\{\pi_{+j}\}\)</span>, por lo que su dimensión es de <span class="math inline">\((I-1) + (J-1)\)</span>. La diferencia entre estas dimensiones es <span class="math inline">\((I-1)(J-1)\)</span>. Para muestras grandes, <span class="math inline">\(G^2\)</span> tiene una distribución nula <span class="math inline">\(\chi^2\)</span> con grados de libertad <span class="math inline">\((I-1)(J-1)\)</span>. Por lo que <span class="math inline">\(G^2\)</span> y <span class="math inline">\(X^2\)</span> tienen la misma distribución límite. De hecho, son asintóticamente equivalentes: <span class="math inline">\(X^2 - G^2\)</span> converge en probabilidad a <span class="math inline">\(0\)</span>.</p>
</div>
<div id="ejemplo-brecha-de-genero" class="section level3">
<h3><span class="header-section-number">5.6.2</span> Ejemplo: brecha de género</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">gendergap &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">c</span>(<span class="dv">279</span>,<span class="dv">73</span>,<span class="dv">225</span>,<span class="dv">165</span>,<span class="dv">47</span>,<span class="dv">191</span>), <span class="dt">byrow =</span> T, <span class="dt">ncol =</span> <span class="dv">3</span>)
<span class="kw">dimnames</span>(gendergap) &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">Gender=</span><span class="kw">c</span>(<span class="st">&quot;Female&quot;</span>,<span class="st">&quot;Male&quot;</span>), <span class="dt">PartyID=</span><span class="kw">c</span>(<span class="st">&quot;Democrat&quot;</span>,<span class="st">&quot;Independent&quot;</span>,<span class="st">&quot;Republican&quot;</span>))
gendergap <span class="op">%&gt;%</span><span class="st"> </span>knitr<span class="op">::</span><span class="kw">kable</span>()</code></pre></div>
<table>
<thead>
<tr class="header">
<th></th>
<th align="right">Democrat</th>
<th align="right">Independent</th>
<th align="right">Republican</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Female</td>
<td align="right">279</td>
<td align="right">73</td>
<td align="right">225</td>
</tr>
<tr class="even">
<td>Male</td>
<td align="right">165</td>
<td align="right">47</td>
<td align="right">191</td>
</tr>
</tbody>
</table>
<p>La prueba de <span class="math inline">\(\chi^2\)</span> de Pearson se puede realizar con la función <code>chisq.test</code> que ya está en R base:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">chisq.test</span>(gendergap)
<span class="co">#&gt; </span>
<span class="co">#&gt;  Pearson&#39;s Chi-squared test</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; data:  gendergap</span>
<span class="co">#&gt; X-squared = 7, df = 2, p-value = 0.03</span></code></pre></div>
</div>
</div>
<div id="general-social-survey-1972---2016" class="section level2">
<h2><span class="header-section-number">5.7</span> General Social Survey 1972 - 2016</h2>
<p>La Encuesta Social General (GSS) es una encuesta sociológica creada y recopilada desde 1972 por el Centro Nacional de Investigación de Opinión de la Universidad de Chicago. La GSS recopila información y mantiene un registro histórico de las preocupaciones, experiencias, actitudes y prácticas de los residentes de los Estados Unidos.</p>
<p>Consideremos las variables de interés de la siguiente tabla:</p>
<table>
<colgroup>
<col width="5%" />
<col width="21%" />
<col width="73%" />
</colgroup>
<thead>
<tr class="header">
<th>Variable</th>
<th>Descripción</th>
<th>Niveles</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>YEAR</td>
<td>Año del encuestado</td>
<td>1972 - 2016</td>
</tr>
<tr class="even">
<td>GOD</td>
<td>Grado de creencia en Dios</td>
<td>No cree, no hay forma de saberlo, cree un un ser superior, cree en ocasiones, cree pero con dudas, sabe que existe.</td>
</tr>
<tr class="odd">
<td>PARTYID</td>
<td>Identificación con un partido político.</td>
<td>Fuertemente democrático, algo democrático, independiente, algo republicano, fuertemente republicano, otro partido</td>
</tr>
<tr class="even">
<td>EDUC</td>
<td>Educación del encuestado</td>
<td>Años de educación desde 1ro de primaria hasta 8 años de educación universitaria</td>
</tr>
<tr class="odd">
<td>HAPPY</td>
<td>Grado de felicidad del encuestado</td>
<td>Muy feliz, algo feliz, no muy feliz,</td>
</tr>
<tr class="even">
<td>POSTLIFE</td>
<td>Creencia de la vida después de la muerte</td>
<td>Sí, No</td>
</tr>
<tr class="odd">
<td>WRKSTAT</td>
<td>Tipo de situación laboral</td>
<td>Tiempo completo, tiempo parcial, con trabajo pero de vacaciones o incapacidad, desempleado, retirado, en la escuela, al cuidado de la casa, otra</td>
</tr>
<tr class="even">
<td>FINRELA</td>
<td>Ingreso con respecto a la media nacional</td>
<td>Muy por debajo, debajo, promedio, encima, muy por encima del promedio</td>
</tr>
</tbody>
</table>
<p>Más información en: <a href="http://gss.norc.org/" class="uri">http://gss.norc.org/</a>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">gss &lt;-<span class="st"> </span><span class="kw">read_csv</span>(<span class="st">&quot;datos/gss.csv&quot;</span>)</code></pre></div>
<p>Veamos los datos de la encuesta del 2006 al 2016. Creamos una variable categórica para analizar la variable de educación más facilamente:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">gss_<span class="dv">0616</span> &lt;-<span class="st"> </span>gss <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">filter</span>(YEAR <span class="op">&gt;=</span><span class="st"> </span><span class="dv">2006</span> <span class="op">&amp;</span><span class="st"> </span>YEAR <span class="op">&lt;=</span><span class="st"> </span><span class="dv">2016</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">EDUC1 =</span> <span class="kw">ifelse</span>(EDUC <span class="op">&lt;</span><span class="st"> </span><span class="dv">12</span>, <span class="st">&quot;Some HS&quot;</span>, 
                        <span class="kw">ifelse</span>(EDUC <span class="op">==</span><span class="st"> </span><span class="dv">12</span>, <span class="st">&quot;HS&quot;</span>,
                               <span class="kw">ifelse</span>(EDUC <span class="op">&lt;</span><span class="st"> </span><span class="dv">16</span>, <span class="st">&quot;Some College&quot;</span>, 
                                      <span class="kw">ifelse</span>(EDUC <span class="op">==</span><span class="st"> </span><span class="dv">16</span>, <span class="st">&quot;College&quot;</span>, <span class="st">&quot;Graduate&quot;</span>)))),
         <span class="dt">EDUC1 =</span> <span class="kw">ordered</span>(EDUC1, <span class="dt">levels=</span><span class="kw">c</span>(<span class="st">&quot;Some HS&quot;</span>,<span class="st">&quot;HS&quot;</span>, <span class="st">&quot;Some College&quot;</span>, <span class="st">&quot;College&quot;</span>, <span class="st">&quot;Graduate&quot;</span>)),
         <span class="dt">GOD1 =</span> <span class="kw">ordered</span>(GOD, <span class="dt">levels=</span><span class="kw">c</span>(<span class="st">&quot;DONT BELIEVE&quot;</span>,<span class="st">&quot;NO WAY TO FIND OUT&quot;</span>,<span class="st">&quot;SOME HIGHER POWER&quot;</span>,
                                      <span class="st">&quot;BELIEVE SOMETIMES&quot;</span>,<span class="st">&quot;BELIEVE BUT DOUBTS&quot;</span>,<span class="st">&quot;KNOW GOD EXISTS&quot;</span>))) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">select</span>(EDUC1, GOD1) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">drop_na</span>()</code></pre></div>
<p>Veamos la tabla de contingencias:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">table</span>(gss_<span class="dv">0616</span><span class="op">$</span>EDUC1, gss_<span class="dv">0616</span><span class="op">$</span>GOD1) <span class="op">%&gt;%</span><span class="st"> </span>knitr<span class="op">::</span><span class="kw">kable</span>()</code></pre></div>
<table>
<thead>
<tr class="header">
<th></th>
<th align="right">DONT BELIEVE</th>
<th align="right">NO WAY TO FIND OUT</th>
<th align="right">SOME HIGHER POWER</th>
<th align="right">BELIEVE SOMETIMES</th>
<th align="right">BELIEVE BUT DOUBTS</th>
<th align="right">KNOW GOD EXISTS</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Some HS</td>
<td align="right">53</td>
<td align="right">60</td>
<td align="right">134</td>
<td align="right">98</td>
<td align="right">288</td>
<td align="right">1607</td>
</tr>
<tr class="even">
<td>HS</td>
<td align="right">105</td>
<td align="right">146</td>
<td align="right">342</td>
<td align="right">140</td>
<td align="right">631</td>
<td align="right">2551</td>
</tr>
<tr class="odd">
<td>Some College</td>
<td align="right">113</td>
<td align="right">216</td>
<td align="right">461</td>
<td align="right">155</td>
<td align="right">620</td>
<td align="right">2221</td>
</tr>
<tr class="even">
<td>College</td>
<td align="right">93</td>
<td align="right">163</td>
<td align="right">345</td>
<td align="right">98</td>
<td align="right">413</td>
<td align="right">1235</td>
</tr>
<tr class="odd">
<td>Graduate</td>
<td align="right">106</td>
<td align="right">200</td>
<td align="right">332</td>
<td align="right">77</td>
<td align="right">377</td>
<td align="right">910</td>
</tr>
</tbody>
</table>
<p>A esta gráfica le llamamos <em>gráfica de mosaicos</em>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(gss_<span class="dv">0616</span>, <span class="kw">aes</span>(<span class="dt">x=</span>EDUC1, <span class="dt">fill=</span>GOD1)) <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_bar</span>(<span class="dt">position=</span><span class="st">&#39;fill&#39;</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">coord_flip</span>() <span class="op">+</span>
<span class="st">    </span><span class="kw">theme</span>(<span class="dt">aspect.ratio =</span> <span class="dv">1</span>,<span class="dt">legend.position=</span><span class="st">&quot;bottom&quot;</span>,
          <span class="dt">axis.text.y=</span><span class="kw">element_text</span>(<span class="dt">color=</span><span class="st">&#39;black&#39;</span>,<span class="dt">size=</span><span class="dv">10</span>),
          <span class="dt">axis.text.x=</span><span class="kw">element_text</span>(<span class="dt">color=</span><span class="st">&#39;black&#39;</span>,<span class="dt">size=</span><span class="dv">10</span>),
          <span class="dt">axis.title.x=</span><span class="kw">element_text</span>(<span class="dt">size=</span><span class="dv">12</span>),
          <span class="dt">axis.title.y=</span><span class="kw">element_text</span>(<span class="dt">size=</span><span class="dv">12</span>),
          <span class="dt">legend.text=</span><span class="kw">element_text</span>(<span class="dt">size=</span><span class="dv">11</span>)) <span class="op">+</span>
<span class="st">    </span><span class="kw">scale_fill_discrete</span>(<span class="st">&quot;&quot;</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">ylab</span>(<span class="st">&#39;Proporción&#39;)</span></code></pre></div>
<p>Comparamos pruebas de hipótesis con los estadísticos <span class="math inline">\(G^2\)</span> y <span class="math inline">\(X^2\)</span>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(Deducer)
<span class="kw">likelihood.test</span>(gss_<span class="dv">0616</span><span class="op">$</span>EDUC1, gss_<span class="dv">0616</span><span class="op">$</span>GOD1)
<span class="co">#&gt; </span>
<span class="co">#&gt;  Log likelihood ratio (G-test) test of independence without</span>
<span class="co">#&gt;  correction</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; data:  gss_0616$EDUC1 and gss_0616$GOD1</span>
<span class="co">#&gt; Log likelihood ratio statistic (G) = 500, X-squared df = 20,</span>
<span class="co">#&gt; p-value &lt;2e-16</span></code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">chisq.test</span>(gss_<span class="dv">0616</span><span class="op">$</span>EDUC1, gss_<span class="dv">0616</span><span class="op">$</span>GOD1)
<span class="co">#&gt; </span>
<span class="co">#&gt;  Pearson&#39;s Chi-squared test</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; data:  gss_0616$EDUC1 and gss_0616$GOD1</span>
<span class="co">#&gt; X-squared = 500, df = 20, p-value &lt;2e-16</span></code></pre></div>
<p>Estas estadísticas pueden ser evidencia de una asociación estadística fuerte.</p>
<p>Para entender mejor la naturaleza de la evidencia en contra de <span class="math inline">\(H_0\)</span> es necesario comparar casilla por casilla las frecuencias estimadas y observadas.</p>
<p>Definimos los residuales ajustados como</p>
<p><span class="math display">\[
r_{ij} = \dfrac{n_{ij} - \hat{\mu}_{ij}}{\sqrt{\hat{\mu}_{ij}(1-p_{i+})(1-p_{+j})}}.
\]</span></p>

<div class="nota">
<ul>
<li><p>Bajo <span class="math inline">\(H_0\)</span> cada <span class="math inline">\(r_{ij}\)</span> tiene una distribución muestral aproximada normal estándar.</p></li>
<li><p>Si en una casilla <span class="math inline">\(r_{ij}\)</span> excede 2 en valor absoluto, entonces esto significa que en esa casilla el modelo de independencia (<span class="math inline">\(H_0\)</span>) no es muy apropiado.</p></li>
<li>El signo describe la naturaleza de la asociación.
</div>
</li>
</ul>
<p>Veamos el cálculo de los residuales:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">tabla &lt;-<span class="st"> </span><span class="kw">table</span>(gss_<span class="dv">0616</span><span class="op">$</span>EDUC1, gss_<span class="dv">0616</span><span class="op">$</span>GOD1)
rowsum &lt;-<span class="st"> </span><span class="kw">apply</span>(tabla,<span class="dv">1</span>,sum)
colsum &lt;-<span class="st"> </span><span class="kw">apply</span>(tabla,<span class="dv">2</span>,sum)
n &lt;-<span class="st"> </span><span class="kw">sum</span>(tabla)
gd &lt;-<span class="st"> </span><span class="kw">outer</span>(rowsum, colsum<span class="op">/</span>n)
rowp &lt;-<span class="st"> </span>rowsum<span class="op">/</span>n <span class="co">#Prob. margimales renglón </span>
colp &lt;-<span class="st"> </span>colsum<span class="op">/</span>n <span class="co">#Prob. marginales columna</span>
pd &lt;-<span class="st"> </span><span class="kw">outer</span>(<span class="dv">1</span><span class="op">-</span>rowp,<span class="dv">1</span><span class="op">-</span>colp)
resid &lt;-<span class="st"> </span>(tabla<span class="op">-</span>gd)<span class="op">/</span><span class="kw">sqrt</span>(gd<span class="op">*</span>pd)
resid <span class="op">%&gt;%</span><span class="st"> </span>knitr<span class="op">::</span><span class="kw">kable</span>()</code></pre></div>
<table>
<thead>
<tr class="header">
<th></th>
<th align="right">DONT BELIEVE</th>
<th align="right">NO WAY TO FIND OUT</th>
<th align="right">SOME HIGHER POWER</th>
<th align="right">BELIEVE SOMETIMES</th>
<th align="right">BELIEVE BUT DOUBTS</th>
<th align="right">KNOW GOD EXISTS</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Some HS</td>
<td align="right">-2.67</td>
<td align="right">-6.367</td>
<td align="right">-8.65</td>
<td align="right">1.056</td>
<td align="right">-4.802</td>
<td align="right">12.70</td>
</tr>
<tr class="even">
<td>HS</td>
<td align="right">-2.50</td>
<td align="right">-5.685</td>
<td align="right">-5.94</td>
<td align="right">-1.499</td>
<td align="right">-0.359</td>
<td align="right">8.25</td>
</tr>
<tr class="odd">
<td>Some College</td>
<td align="right">-1.23</td>
<td align="right">0.667</td>
<td align="right">2.00</td>
<td align="right">0.438</td>
<td align="right">0.152</td>
<td align="right">-1.44</td>
</tr>
<tr class="even">
<td>College</td>
<td align="right">2.00</td>
<td align="right">3.376</td>
<td align="right">5.70</td>
<td align="right">0.544</td>
<td align="right">1.863</td>
<td align="right">-7.59</td>
</tr>
<tr class="odd">
<td>Graduate</td>
<td align="right">5.43</td>
<td align="right">9.522</td>
<td align="right">8.06</td>
<td align="right">-0.318</td>
<td align="right">3.309</td>
<td align="right">-13.96</td>
</tr>
</tbody>
</table>
<p>En la columna “God Know Exists” observamos residuales particularmente grandes:</p>
<ul>
<li><p>con signo positivo: 12.70 para “Some HS” y 8.25 para “HS”, significa que el número observado de personas que “saben que Dios existe” entre los encuestados con secundario o menor grado de estudios es mayor que el esperado.</p></li>
<li><p>con signo negativo: -7.59 para “Collge” y -13.96 “Graduate”, significa que el número observado de personas que “saben que Dios existe” entre las que fueron a la universidad (licenciatura o posgrado) es menor que el esperado.</p></li>
</ul>
<p>De la tabla se podría concluir que el grado de estudios tiene una asociación negativ con el gardo de creencia en la existencia de Dios.</p>
<hr />
<p><br></p>
</div>
<div id="la-catadora-de-te" class="section level2">
<h2><span class="header-section-number">5.8</span> La catadora de té</h2>
<p>Una tarde del verano de 1920 en Cambridge, Inglaterra, Ronald Fisher tomaba el té en la terraza con sus colegas y amigos.</p>
<p><img src="figuras/fisher_1913.png" width="25%" style="display: block; margin: auto;" /></p>
<p>La reunión había progresado complacientemente y en una ocasión cuando las tazas de té las volvían a llenar, Lady Muriel Bristol abruptadmente le dijo al mesero que parara de rellenar su taza.</p>
<p><img src="figuras/tea_or_milk.png" width="45%" style="display: block; margin: auto;" /></p>
<p>Lady Bristol indicó con desdeño que el mesero había puesto en la taza primero la leche y luego el té, en lugar de cumplir con una preferencia ampliamente conocida de té primero y luego leche.</p>
<p>Miradas de reojo fueron intercambiadas por numerosos miembros del grupo, preguntándose qué diferencia podría haber con que se añadiera a la taza primero la leche o primero el té. Hacía toda la diferencia, según Lady Bristol, afirmando que fácilmente ella podía decir si se había vertido primero en la taza la leche o el té.</p>
<p>Muy a salvo de la vista de Lady Bristol, se prepararon 8 tazas de té, en las cuales en 4 se virtió primero la leche y luego el té, y en las 4 restantes se virtió primero la leche y luego el té, siempre en las mismas proporciones.</p>
<p><img src="figuras/tea_cups.png" width="45%" style="display: block; margin: auto;" /></p>
<p>Muy amablemente, Lady Bristol <em>cató</em> las 8 tazas de té y dio su veredicto sobre cuáles de las 4 tazas eran aquellas en las q se sirvió primero la leche y luego el té. Los resultados obtenidos a partir de esta cata de té se muestran en la siguiente tabla:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">Poured &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;Milk&quot;</span>,<span class="st">&quot;Milk&quot;</span>,<span class="st">&quot;Tea&quot;</span>,<span class="st">&quot;Tea&quot;</span>)
Guess &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;Milk&quot;</span>,<span class="st">&quot;Tea&quot;</span>,<span class="st">&quot;Milk&quot;</span>,<span class="st">&quot;Tea&quot;</span>)
count &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">3</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">3</span>)
teadata &lt;-<span class="st"> </span><span class="kw">tibble</span>(Poured, Guess, count)
tea &lt;-<span class="st"> </span><span class="kw">xtabs</span>(count <span class="op">~</span>Poured <span class="op">+</span><span class="st"> </span>Guess, <span class="dt">data =</span> teadata)
tea <span class="op">%&gt;%</span><span class="st"> </span>knitr<span class="op">::</span><span class="kw">kable</span>()</code></pre></div>
<table>
<thead>
<tr class="header">
<th></th>
<th align="right">Milk</th>
<th align="right">Tea</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Milk</td>
<td align="right">3</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td>Tea</td>
<td align="right">1</td>
<td align="right">3</td>
</tr>
</tbody>
</table>
<p>Utilizando el método de la <span class="math inline">\(\chi^2\)</span> de Pearson hacemos la prueba de independencia <span class="math inline">\(H_0:\theta=1\)</span>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">chisq.test</span>(tea, <span class="dt">correct =</span> <span class="ot">FALSE</span>)
<span class="co">#&gt; Warning in chisq.test(tea, correct = FALSE): Chi-squared approximation may</span>
<span class="co">#&gt; be incorrect</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;  Pearson&#39;s Chi-squared test</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; data:  tea</span>
<span class="co">#&gt; X-squared = 2, df = 1, p-value = 0.2</span></code></pre></div>
<p>Obtenemos el mensaje de que la prueba podría ser incorrecta. Esto no nos sorprende ya que la prueba no tiene mucha potencia debido al poco número de observaciones. ¡Fisher no le daría a probar 30 tazas a Lady Bristol sin convertirse en el objeto de su desdeño!</p>
<p>El método de <code>R</code> implementa la prueba de <span class="math inline">\(\chi^2\)</span> utilizando la <em>corrección de Yates</em> cuando el tamaño de muestra es pequeño:</p>
<p><span class="math display">\[
X^2_Y = \sum_{i}\sum_j{\dfrac{(|n_{ij}-\hat{\mu}_{ij}|-\frac{1}{2})^2}{\hat{\mu}_{ij}}}\sim\chi^2_{(I-1)(J-1)}
\]</span></p>
<p>En el libro <em>The Lady Tasting Tea: How Statistics Revolutionized Science in the Twentieth Century</em> escrito por David Salsburg, se describe con detalle este suceso y los <em>experimentos diseñados</em> por Ronald Fisher para probar las afirmaciones de Lady Bristol.</p>
<center>
<p><a href="https://www.amazon.com/Lady-Tasting-Tea-Statistics-Revolutionized/dp/0805071342"><img src="figuras/lady_tasting_tea.jpg" alt="The Lady Tasting Tea" width="150" /></a></p>
</center>
<hr />
<p><br></p>
</div>
<div id="modelos-multinomiales-para-conteos" class="section level2">
<h2><span class="header-section-number">5.9</span> Modelos multinomiales para conteos</h2>
<p>Condicional a la suma <span class="math inline">\(n\)</span> de conteos de casillas en tablas de contingencia, los modelos log-lineales Poisson para <span class="math inline">\(\{\mu_{ij}\}\)</span> se convierten en modelos multinomiales para las probabilidades de las casillas <span class="math display">\[
\left\{\pi_{ij} = \mu_{ij}/\sum_a\sum_b{\mu_{ab}}\right\}
\]</span></p>
<p>Por ejemplo, para el <em>modelo saturado</em>:</p>
<p><span class="math display">\[
\pi_{ij} = \dfrac{\mbox{exp}(\lambda + \lambda_i^X + \lambda_j^Y + \lambda_{ij}^{XY})}{\sum_a\sum_b{\mbox{exp}(\lambda+\lambda_a^X+\lambda_b^Y+\lambda_{ab}^{XY})}}.
\]</span></p>
<p>El parámetro de intercepto <span class="math inline">\(\lambda\)</span> se cancela en este modelo multinomial. Este parámetro está relacionado con el tamaño total de la muestra, que es aleatorio en el modelo Poisson, pero no lo es en el modelo multinomial. Por esta razón, el modelo multinomial <em>saturado</em> tiene <span class="math inline">\(IJ-1\)</span> parámetros, que representa la restricción usual de las probabilidades, o sea, <span class="math inline">\(\sum_i\sum_j{\pi_{ij}}=1\)</span>.</p>
<p>Por esta razón ajustar un modelo lineal Poisson con función liga <span class="math inline">\(\eta = log(\mu)\)</span>. Veremos esto con más detalle en las siguientes clases. Recordemos el ejemplo de las admisiones de posgrado de Berkeley.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(MASS)
UCBAdmissions <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">as.data.frame</span>() <span class="op">%&gt;%</span><span class="st"> </span>knitr<span class="op">::</span><span class="kw">kable</span>()</code></pre></div>
<table>
<thead>
<tr class="header">
<th align="left">Admit</th>
<th align="left">Gender</th>
<th align="left">Dept</th>
<th align="right">Freq</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Admitted</td>
<td align="left">Male</td>
<td align="left">A</td>
<td align="right">512</td>
</tr>
<tr class="even">
<td align="left">Rejected</td>
<td align="left">Male</td>
<td align="left">A</td>
<td align="right">313</td>
</tr>
<tr class="odd">
<td align="left">Admitted</td>
<td align="left">Female</td>
<td align="left">A</td>
<td align="right">89</td>
</tr>
<tr class="even">
<td align="left">Rejected</td>
<td align="left">Female</td>
<td align="left">A</td>
<td align="right">19</td>
</tr>
<tr class="odd">
<td align="left">Admitted</td>
<td align="left">Male</td>
<td align="left">B</td>
<td align="right">353</td>
</tr>
<tr class="even">
<td align="left">Rejected</td>
<td align="left">Male</td>
<td align="left">B</td>
<td align="right">207</td>
</tr>
<tr class="odd">
<td align="left">Admitted</td>
<td align="left">Female</td>
<td align="left">B</td>
<td align="right">17</td>
</tr>
<tr class="even">
<td align="left">Rejected</td>
<td align="left">Female</td>
<td align="left">B</td>
<td align="right">8</td>
</tr>
<tr class="odd">
<td align="left">Admitted</td>
<td align="left">Male</td>
<td align="left">C</td>
<td align="right">120</td>
</tr>
<tr class="even">
<td align="left">Rejected</td>
<td align="left">Male</td>
<td align="left">C</td>
<td align="right">205</td>
</tr>
<tr class="odd">
<td align="left">Admitted</td>
<td align="left">Female</td>
<td align="left">C</td>
<td align="right">202</td>
</tr>
<tr class="even">
<td align="left">Rejected</td>
<td align="left">Female</td>
<td align="left">C</td>
<td align="right">391</td>
</tr>
<tr class="odd">
<td align="left">Admitted</td>
<td align="left">Male</td>
<td align="left">D</td>
<td align="right">138</td>
</tr>
<tr class="even">
<td align="left">Rejected</td>
<td align="left">Male</td>
<td align="left">D</td>
<td align="right">279</td>
</tr>
<tr class="odd">
<td align="left">Admitted</td>
<td align="left">Female</td>
<td align="left">D</td>
<td align="right">131</td>
</tr>
<tr class="even">
<td align="left">Rejected</td>
<td align="left">Female</td>
<td align="left">D</td>
<td align="right">244</td>
</tr>
<tr class="odd">
<td align="left">Admitted</td>
<td align="left">Male</td>
<td align="left">E</td>
<td align="right">53</td>
</tr>
<tr class="even">
<td align="left">Rejected</td>
<td align="left">Male</td>
<td align="left">E</td>
<td align="right">138</td>
</tr>
<tr class="odd">
<td align="left">Admitted</td>
<td align="left">Female</td>
<td align="left">E</td>
<td align="right">94</td>
</tr>
<tr class="even">
<td align="left">Rejected</td>
<td align="left">Female</td>
<td align="left">E</td>
<td align="right">299</td>
</tr>
<tr class="odd">
<td align="left">Admitted</td>
<td align="left">Male</td>
<td align="left">F</td>
<td align="right">22</td>
</tr>
<tr class="even">
<td align="left">Rejected</td>
<td align="left">Male</td>
<td align="left">F</td>
<td align="right">351</td>
</tr>
<tr class="odd">
<td align="left">Admitted</td>
<td align="left">Female</td>
<td align="left">F</td>
<td align="right">24</td>
</tr>
<tr class="even">
<td align="left">Rejected</td>
<td align="left">Female</td>
<td align="left">F</td>
<td align="right">317</td>
</tr>
</tbody>
</table>
<p>Ajustamos los parámetros para el modelo</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">
llmFit &lt;-<span class="st"> </span><span class="kw">loglm</span>(<span class="op">~</span><span class="st"> </span>Admit <span class="op">+</span><span class="st"> </span>Gender <span class="op">+</span><span class="st"> </span>Dept, <span class="dt">data =</span> UCBAdmissions)
<span class="kw">coef</span>(llmFit)
<span class="co">#&gt; $`(Intercept)`</span>
<span class="co">#&gt; [1] 5.18</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $Admit</span>
<span class="co">#&gt; Admitted Rejected </span>
<span class="co">#&gt;   -0.228    0.228 </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $Gender</span>
<span class="co">#&gt;   Male Female </span>
<span class="co">#&gt;  0.191 -0.191 </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $Dept</span>
<span class="co">#&gt;       A       B       C       D       E       F </span>
<span class="co">#&gt;  0.2305 -0.2363  0.2143  0.0666 -0.2380 -0.0370</span></code></pre></div>
<p>Comparamos utilizando el modelo Poisson:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">UCBdf &lt;-<span class="st"> </span><span class="kw">as.data.frame</span>(UCBAdmissions)
glmFit &lt;-<span class="st"> </span><span class="kw">glm</span>(Freq <span class="op">~</span><span class="st"> </span>Admit <span class="op">+</span><span class="st"> </span>Gender <span class="op">+</span><span class="st"> </span>Dept, <span class="dt">family=</span><span class="kw">poisson</span>(<span class="dt">link =</span> <span class="st">&quot;log&quot;</span>),
              <span class="dt">contrasts=</span><span class="kw">list</span>(<span class="dt">Admit=</span>contr.sum, <span class="dt">Gender=</span>contr.sum, <span class="dt">Dept=</span>contr.sum),
              <span class="dt">data=</span>UCBdf)
<span class="kw">coef</span>(glmFit)
<span class="co">#&gt; (Intercept)      Admit1     Gender1       Dept1       Dept2       Dept3 </span>
<span class="co">#&gt;      5.1776     -0.2284      0.1914      0.2305     -0.2363      0.2143 </span>
<span class="co">#&gt;       Dept4       Dept5 </span>
<span class="co">#&gt;      0.0666     -0.2380</span></code></pre></div>
</div>
<div id="modelos-log-lineales-con-tres-variables-categoricas" class="section level2">
<h2><span class="header-section-number">5.10</span> Modelos log lineales con tres variables categóricas</h2>
<p>En la primera clase vimos ejemplos de modelos log lineales con tres variables categóricas. Sabemos construir las tablas de contingencia de tres variables con la función <code>xtabs()</code> y ajustar los modelos con las funciones <code>loglin()</code>, <code>loglm()</code>, y <code>glm()</code>. Vimos que se podía ajustar modelos de independencia y en general, de diferentes tipos de asociaciones.</p>
<p>Una tabla de contingencia de <span class="math inline">\(I\times J \times K\)</span> con variables de respuesta <span class="math inline">\(X, Y\)</span> y <span class="math inline">\(Z\)</span> potencialmente tiene varios tipos de independencias.</p>
<p>Los modelos se aplican a la distribución multinomial con probabilidades de celdillas <span class="math inline">\(\{\pi_{ijk}\}\)</span> en las cuales <span class="math inline">\(\sum_i\sum_j\sum_k\pi_{ijk}=1\)</span> y también a muestreo con Poisson con medias <span class="math inline">\(\mu_{ijk}\)</span>.</p>
<div id="tipos-de-independencia" class="section level3">
<h3><span class="header-section-number">5.10.1</span> Tipos de independencia</h3>
<p><strong>Independencia mutua</strong></p>
<p>Las tres variables son <em>mutuamente independientes</em> cuando <span class="math display">\[
\pi_{ijk}=\pi_{i++}\pi_{+j+}\pi_{++k}\qquad\;\text{para toda}\;i,j,\,\mbox{ y }\, k.
\]</span></p>
<p>Para frecuencias esperadas <span class="math inline">\(\mu_{ijk}\)</span>, la independencia mutua tiene un modelo loglineal de la forma</p>
<p><span class="math display">\[
\mbox{log}\,\mu_{ijk} = \lambda+\lambda_{i}^X+\lambda_j^Y+\lambda_k^Z.
\]</span></p>
<p><strong>Independencia conjunta</strong></p>
<p>La variable <span class="math inline">\(Y\)</span> es <em>conjuntamente independiente</em> de <span class="math inline">\(X\)</span> y <span class="math inline">\(Z\)</span> cuando</p>
<p><span class="math display">\[
\pi_{ijk}=\pi_{i+k}\pi_{+j+}\qquad\;\text{para toda}\;i,j,\,\mbox{ y }\, k.
\]</span></p>
<p>Esto es equivalente a tener independencia entre la variable <span class="math inline">\(Y\)</span> y una variable con las <span class="math inline">\(IK\)</span> combinaciones de los niveles de <span class="math inline">\(X\)</span> y <span class="math inline">\(Z\)</span>. El modelo loglineal es:</p>
<p><span class="math display">\[
\mbox{log}\,\mu_{ijk} = \lambda+\lambda_{i}^X+\lambda_j^Y+\lambda_k^Z + \lambda_{ik}^{XZ}.
\]</span></p>
<p>Similarmente, <span class="math inline">\(X\)</span> podría ser conjuntamente independiente de <span class="math inline">\(Y\)</span> y <span class="math inline">\(Z\)</span>, o bien, <span class="math inline">\(Z\)</span> podría ser conjuntamente independiente de <span class="math inline">\(X\)</span> y <span class="math inline">\(Y\)</span>. La independencia mutua implica independencia conjunta de cualquier variable con las otras dos.</p>
<p><strong>Independencia condicional</strong></p>
<p>Las variables categóricas <span class="math inline">\(X\)</span> y <span class="math inline">\(Y\)</span> son <em>condicionalmente independientes dado</em> <span class="math inline">\(Z\)</span> cuando se cumple la independencia para cada tabla parcial cuando cada <span class="math inline">\(Z\)</span> permanece fija. Esto es, si <span class="math inline">\(\pi_{ij|k}=P(X=i,Y=j|Z=k)\)</span>, entonces</p>
<p><span class="math display">\[
\pi_{ij|k}=\pi_{i+|k}\pi_{+j|k}\qquad\;\text{para toda}\;i,j,\,\mbox{ y }\, k.
\]</span></p>
<p>Para probabilidades conjuntas en toda la tabla esto es equivalente:</p>
<p><span class="math display">\[
\pi_{ijk}=\pi_{i+k}\pi_{+jk}/\pi_{++k}\qquad\;\text{para toda}\;i,j,\,\mbox{ y }\, k.
\]</span></p>
<p>La independencia condicional de <span class="math inline">\(X\)</span> y <span class="math inline">\(Y\)</span>, dado <span class="math inline">\(Z\)</span>, tiene un modelo loglineal de la forma</p>
<p><span class="math display">\[
\mbox{log}\,\mu_{ijk} = \lambda+\lambda_i^X+\lambda_j^Y + \lambda_k^Z+ \lambda_{ik}^{XZ} + \lambda_{jk}^{YZ}.
\]</span></p>
<p>Esta es una condición más débil de independencia conjunta. La independencia mutua implica que <span class="math inline">\(Y\)</span> es conjuntamente independiente de <span class="math inline">\(X\)</span> y <span class="math inline">\(Z\)</span>, la cual implica que <span class="math inline">\(X\)</span> y <span class="math inline">\(Y\)</span> son condicionalmente independientes.</p>
<p>En la siguiente tabla resumimos los tres tipos de independencia:</p>
<center>
<table>
<colgroup>
<col width="8%" />
<col width="26%" />
<col width="32%" />
<col width="33%" />
</colgroup>
<thead>
<tr class="header">
<th>Modelo</th>
<th>Forma probabilística para <span class="math inline">\(\pi_{ijk}\)</span></th>
<th>Términos de asociación en el modelo loglineal</th>
<th>Interpretación</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td><span class="math inline">\(\pi_{i++}\pi_{+j+}\pi_{++k}\)</span></td>
<td>Ninguno</td>
<td>Independencia mutua de <span class="math inline">\(X,Y,Z\)</span></td>
</tr>
<tr class="even">
<td>2</td>
<td><span class="math inline">\(\pi_{i+k}\pi_{+j+}\)</span></td>
<td><span class="math inline">\(\lambda_{ik}^{XZ}\)</span></td>
<td>Independencia conjunta de <span class="math inline">\(Y\)</span> con <span class="math inline">\(X,Z\)</span></td>
</tr>
<tr class="odd">
<td>3</td>
<td><span class="math inline">\(\pi_{i+k}\pi_{+jk}/\pi_{++k}\)</span></td>
<td><span class="math inline">\(\lambda_{ik}^{XZ}+\lambda_{jk}^{YZ}\)</span></td>
<td>Independencia condicional de <span class="math inline">\(X\)</span> y <span class="math inline">\(Y\)</span> dado <span class="math inline">\(Z\)</span></td>
</tr>
</tbody>
</table>
</center>
<hr />
<p><br></p>
</div>
<div id="asociacion-homogenea-e-interacciones-de-3-factores" class="section level3">
<h3><span class="header-section-number">5.10.2</span> Asociación homogénea e interacciones de 3 factores</h3>
<p>Los modelos (1), (2), y (3) tienen tres, dos, y un par de variables condicionalmente independientes, respectivamente. En los modelos (2) y (3) los parámetros con doble subíndice (tales como <span class="math inline">\(\lambda_{ij}^{XY}\)</span>) representan dependencias condicionales entre las variables.</p>
<p>Un modelo con las tres dependencias condicionales es</p>
<p><span class="math display">\[
\mbox{log}\,\mu_{ijk} = \lambda + \lambda_i^X + \lambda_j^Y + \lambda_k^Z + \lambda_{ij}^{XY} + \lambda_{ik}^{XZ} + \lambda_{jk}^{YZ}.
\]</span></p>
<p>Si exponenciamos ambas partes de la ecuación, las probabilidades en cada casilla tienen la forma</p>
<p><span class="math display">\[
\pi_{ijk} = \psi_{ij}\phi_{jk}\omega_{ik}.
\]</span></p>
<p>No existe una expresión cerrada para los tres factores en términos de los márgenes de las <span class="math inline">\(\{\pi_{ijk}\}\)</span> en el caso general. Se puede demostrar que las razones de momios entre caulesquiera dos pares de variables son idénticos en cada categoría de la tercera variable. A este modelo se le llama el modelo <em>loglineal de asociación homogénea</em>, o bien, el modelo de <em>no interacción entre los 3 factores</em>.</p>
<p>El modelo <em>loglineal general</em> es</p>
<p><span class="math display">\[
\mbox{log}\, \mu_{ijk} = \lambda + \lambda_i^X + \lambda_j^Y + \lambda_k^Z + \lambda_{ij}^{XY} + \lambda_{jk}^{YZ} + \lambda_{jk}^{YZ} + \lambda_{ijk}^{XYZ}
\]</span></p>
<p>Con variables indicadoras, <span class="math inline">\(\lambda_{ijk}^{XYZ}\)</span> es el coeficiente del producto de la <span class="math inline">\(i\)</span>-ésima variable indicadora de <span class="math inline">\(X\)</span>, la <span class="math inline">\(j\)</span>-ésima de <span class="math inline">\(Y\)</span>, y la <span class="math inline">\(k\)</span>-ésima de <span class="math inline">\(Z\)</span>. El número total de parámetros no redundates es</p>
<span class="math display">\[\begin{eqnarray*}
1 &amp;+&amp; (I-1) + (J-1) + (K-1) + (I-1)(J-1) + (I-1)(K-1) \\
&amp;+&amp; (J-1)(I-1) + (I-1)(J-1)(K-1) = IJK,
\end{eqnarray*}\]</span>
<p>que es el número total de conteos de casillas. Este modelo tiene tantos parámetros como observaciones y es saturado. Describe todas las posibles <span class="math inline">\(\{\mu_{ijk}\}\)</span>. Cada par de variables pueden ser condicionalmente dependientes, y las razones de momios para cada par pueden variar a lo largo de todas las categorías de la tercera variable.</p>
<p>Poniendo algunos términos como cero obtenemos cualquiera de los modelos anteriores. En la siguiente tabla resumimos los modelos. Para facilitar cuando nos referimos a ellos en la tabla le asignamos un símbolo que pone en la lista únicamente el (los) términos de mayor orden para cada variable. Por ejemplo, el modelo (3) de independencia condicional se codifica como (XZ, YZ), porque sus términos de mayor orden son <span class="math inline">\(\lambda_{ik}^{XZ}\)</span> y <span class="math inline">\(\lambda_{jk}^{YZ}\)</span>.</p>
<center>
<table>
<colgroup>
<col width="92%" />
<col width="7%" />
</colgroup>
<thead>
<tr class="header">
<th>Fórmula del modelo loglineal</th>
<th>Símbolo</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(\mbox{log}\, \mu_{ijk} = \lambda + \lambda_i^X + \lambda_j^Y,+,\lambda_k^Z\)</span></td>
<td>(X,Y,Z)</td>
</tr>
<tr class="even">
<td><span class="math inline">\(\mbox{log}\, \mu_{ijk} = \lambda + \lambda_i^X + \lambda_j^Y,+,\lambda_k^Z + \lambda_{ij}^{XY}\)</span></td>
<td>(XY,Z)</td>
</tr>
<tr class="odd">
<td><span class="math inline">\(\mbox{log}\, \mu_{ijk} = \lambda + \lambda_i^X + \lambda_j^Y,+,\lambda_k^Z + \lambda_{ij}^{XY} + \lambda_{jk}^{YZ}\)</span></td>
<td>(XY,YZ)</td>
</tr>
<tr class="even">
<td><span class="math inline">\(\mbox{log}\, \mu_{ijk} = \lambda + \lambda_i^X + \lambda_j^Y +,\lambda_k^Z + \lambda_{ij}^{XY} + \lambda_{jk}^{YZ} + \lambda_{jk}^{YZ}\)</span></td>
<td>(XY,YZ,XZ)</td>
</tr>
<tr class="odd">
<td><span class="math inline">\(\mbox{log}\, \mu_{ijk} = \lambda + \lambda_i^X + \lambda_j^Y + \lambda_k^Z + \lambda_{ij}^{XY} + \lambda_{jk}^{YZ} + \lambda_{jk}^{YZ} + \lambda_{ijk}^{XYZ}\)</span></td>
<td>(XYZ)</td>
</tr>
</tbody>
</table>
</center>
<p><br></p>
<p>Finalmente, en la siguiente tabla resumímos el número de grados de libertad de los estadísticos <span class="math inline">\(G^2\)</span> y <span class="math inline">\(X^2\)</span> que tienen una distribución muestral aproximada a <span class="math inline">\(\chi^2\)</span>. El número de grados de libertad es igual a la diferencia entre el número de parámetros en el caso general y cuando el modelo se cumple. En el caso general hay <span class="math inline">\(IJK-1\)</span> parámetros.</p>
<center>
<table>
<thead>
<tr class="header">
<th>Modelo</th>
<th>Grados de libertad</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\((X,Y,Z)\)</span></td>
<td><span class="math inline">\(IJK - I - J - K + 2\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\((XY,Z)\)</span></td>
<td><span class="math inline">\((K-1)(IJ-1)\)</span></td>
</tr>
<tr class="odd">
<td><span class="math inline">\((XZ,Y)\)</span></td>
<td><span class="math inline">\((J-1)(IK-1)\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\((YZ,X)\)</span></td>
<td><span class="math inline">\((I-1)(JK-1)\)</span></td>
</tr>
<tr class="odd">
<td><span class="math inline">\((XY,YZ)\)</span></td>
<td><span class="math inline">\(J(I-1)(K-1)\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\((XZ,YZ)\)</span></td>
<td><span class="math inline">\(K(I-1)(J-1)\)</span></td>
</tr>
<tr class="odd">
<td><span class="math inline">\((XY,XZ)\)</span></td>
<td><span class="math inline">\(I(J-1)(K-1)\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\((XY,XZ,YZ)\)</span></td>
<td><span class="math inline">\((I-1)(J-1)(K-1)\)</span></td>
</tr>
<tr class="odd">
<td><span class="math inline">\((XYZ)\)</span></td>
<td><span class="math inline">\(0\)</span></td>
</tr>
</tbody>
</table>
</center>
</div>
</div>
<div id="ejemplo-sensitividad-y-especificidad" class="section level2">
<h2><span class="header-section-number">5.11</span> Ejemplo: sensitividad y especificidad</h2>
<p>En la siguiente tabla se muestran resultados de un artículo reciente sobre varios métodos para tratar de diagnosticar el VIH.</p>
<center>
<table>
<caption>Delaney, K. P., Branson, B. M., Uniyal, A., Phillips, S., Candal, D., Owen, S. M., &amp; Kerndt, P. R. (2011). Evaluation of the performance characteristics of 6 rapid HIV antibody tests. Clinical Infectious Diseases, 52(2), 257-263.</caption>
<thead>
<tr class="header">
<th>El paciente tiene VIH</th>
<th>Diagnóstico positivo</th>
<th>Diagnóstico negativo</th>
<th>Total</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Sí</td>
<td>0.99</td>
<td>0.01</td>
<td>1.0</td>
</tr>
<tr class="even">
<td>No</td>
<td>0.05</td>
<td>0.95</td>
<td>1.0</td>
</tr>
</tbody>
</table>
</center>
<p>Con base en una revisión de la literatura, los autores concluyen que, como el rendimiento fue similar para todas las pruebas rápidas y todos los tipos de especímenes, entonces otras características, como la conveniencia, el tiempo para obtener el resultado, la vida útil y el costo serán factores determinantes para la selección de una prueba rápida de detección del VIH para una aplicación específica.</p>
<p>Sea <span class="math inline">\(X=\)</span> verdadero valor de la enfermedad (si el paciente tiene VIH o no) y sea <span class="math inline">\(Y=\)</span> diagnóstico (positivo o negativo), donde un diagnóstico positivo predice que el individuo tiene VIH. Las probabilidades mostradas en la tabla son <em>probabilidades condicionales</em> de <span class="math inline">\(Y\)</span> dado <span class="math inline">\(X\)</span>.</p>
<p>Con una prueba de diagnóstico de una enfermedad, los dos diagnósticos correctos son:</p>
<ul>
<li><p>un resultado positivo de la prueba cuando el individuo tiene la enfermedad, y</p></li>
<li><p>un resultado negativo cuando el individuo no la tiene.</p></li>
</ul>

<div class="nota">
<ul>
<li><p>Dado que el individuo tiene la enfermedad, la probabilidad condicional de que la prueba de diagnóstico sea positiva se denomina <em>sensibilidad</em>.</p></li>
<li><p>Dado que el individuo <strong>no</strong> tiene la enfermedad, la probabilidad condicional de que la prueba sea negativa se llama <em>especificidad</em>.</p></li>
</ul>
Idealmente, estos son altos.
</div>

<p>En una tabla de <span class="math inline">\(2\times 2\)</span> como la que se muestra arriba, la sensibilidad es <span class="math inline">\(\pi_{1|1}\)</span> y la especificidad es <span class="math inline">\(\pi_{2|2}\)</span>. En la tabla de de arriba, la sensibilidad estimada de las pruebas rápidas del VIH es <span class="math inline">\(0.99\)</span>. Entre los individuos con VIH, el 99% es diagnosticado correctamente. La especificidad estimada es 0.95. Entre los individuos que <strong>no</strong> tienen VIH, el 95% es diagnosticado correctamente.</p>
<hr />
<p><br></p>
</div>
<div id="ejemplo-horoscopos" class="section level2">
<h2><span class="header-section-number">5.12</span> Ejemplo: horóscopos</h2>
<p>Supongamos que deseamo saber si los horóscopos son realmente sólo un figmento de la imaginación de las personas.</p>
<p>Se hizo una encuesta con 2201 personas. Se les pidió su signo zodiacal (esta variable, obviamente, tiene 12 categorías: Capricornio, Acuario, Piscis, Aries, Tauro, Géminis, Cáncer, Leo, Virgo, Libra, Escorpio y Sagitario) y que contestaran si creían en los horóscopos (estas dos variables tienen dos categorías: creen o no creen).</p>
<p>Posteriormente a todos los sujetos se les envió exactamente el mismo horóscopo sobre cómo sería el siguiente mes y al finalizar el mes se les preguntó si su horóscopo se cumplió o no. Buscamos realizar un análisis loglineal para ver si existe una relación entre el signo zodiacal de la persona, si cree en los horóscopos y si el horóscopo se hizo realidad.</p>
<p>Comenzamos leyendo los datos:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">horoscopos &lt;-<span class="st"> </span><span class="kw">read_csv</span>(<span class="st">&quot;datos/horoscopos.csv&quot;</span>)
<span class="co">#&gt; Parsed with column specification:</span>
<span class="co">#&gt; cols(</span>
<span class="co">#&gt;   Star_Sign = col_character(),</span>
<span class="co">#&gt;   Believe = col_character(),</span>
<span class="co">#&gt;   True = col_character(),</span>
<span class="co">#&gt;   Frequency = col_integer()</span>
<span class="co">#&gt; )</span>
horoscopos <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">head</span>() <span class="op">%&gt;%</span><span class="st"> </span>knitr<span class="op">::</span><span class="kw">kable</span>()</code></pre></div>
<table>
<thead>
<tr class="header">
<th align="left">Star_Sign</th>
<th align="left">Believe</th>
<th align="left">True</th>
<th align="right">Frequency</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Capricorn</td>
<td align="left">Unbeliever</td>
<td align="left">Horoscope Didn’t Come True</td>
<td align="right">56</td>
</tr>
<tr class="even">
<td align="left">Capricorn</td>
<td align="left">Unbeliever</td>
<td align="left">Horoscope Came True</td>
<td align="right">46</td>
</tr>
<tr class="odd">
<td align="left">Capricorn</td>
<td align="left">Believer</td>
<td align="left">Horoscope Didn’t Come True</td>
<td align="right">50</td>
</tr>
<tr class="even">
<td align="left">Capricorn</td>
<td align="left">Believer</td>
<td align="left">Horoscope Came True</td>
<td align="right">60</td>
</tr>
<tr class="odd">
<td align="left">Aquarius</td>
<td align="left">Unbeliever</td>
<td align="left">Horoscope Didn’t Come True</td>
<td align="right">26</td>
</tr>
<tr class="even">
<td align="left">Aquarius</td>
<td align="left">Unbeliever</td>
<td align="left">Horoscope Came True</td>
<td align="right">20</td>
</tr>
</tbody>
</table>
<p>Hacemos la tabla de contingencia con la función <code>xtabs()</code> y</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">tabla_horoscopos &lt;-<span class="st"> </span><span class="kw">xtabs</span>(Frequency <span class="op">~</span><span class="st"> </span>Star_Sign <span class="op">+</span><span class="st"> </span>Believe <span class="op">+</span><span class="st"> </span>True, <span class="dt">data =</span> horoscopos)
tabla_horoscopos
<span class="co">#&gt; , , True = Horoscope Came True</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;              Believe</span>
<span class="co">#&gt; Star_Sign     Believer Unbeliever</span>
<span class="co">#&gt;   Aquarius          29         20</span>
<span class="co">#&gt;   Aries             54         36</span>
<span class="co">#&gt;   Cancer            83         76</span>
<span class="co">#&gt;   Capricorn         60         46</span>
<span class="co">#&gt;   Gemini            48         53</span>
<span class="co">#&gt;   Leo               20         23</span>
<span class="co">#&gt;   Libra             36         26</span>
<span class="co">#&gt;   Pisces            70         51</span>
<span class="co">#&gt;   Sagittarius       50         41</span>
<span class="co">#&gt;   Scorpio           32         20</span>
<span class="co">#&gt;   Taurus            50         42</span>
<span class="co">#&gt;   Virgo             66         55</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; , , True = Horoscope Didn&#39;t Come True</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;              Believe</span>
<span class="co">#&gt; Star_Sign     Believer Unbeliever</span>
<span class="co">#&gt;   Aquarius          22         26</span>
<span class="co">#&gt;   Aries             70         42</span>
<span class="co">#&gt;   Cancer            96         84</span>
<span class="co">#&gt;   Capricorn         50         56</span>
<span class="co">#&gt;   Gemini            40         65</span>
<span class="co">#&gt;   Leo               12         14</span>
<span class="co">#&gt;   Libra             22         27</span>
<span class="co">#&gt;   Pisces            64         55</span>
<span class="co">#&gt;   Sagittarius       42         56</span>
<span class="co">#&gt;   Scorpio           24         32</span>
<span class="co">#&gt;   Taurus            41         56</span>
<span class="co">#&gt;   Virgo             49         69</span></code></pre></div>
<p>Comenzamos el análisis con el modelo saturado:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">horoscopo_saturado &lt;-<span class="st"> </span><span class="kw">loglm</span>(Frequency <span class="op">~</span><span class="st"> </span>Star_Sign<span class="op">*</span>Believe<span class="op">*</span>True, <span class="dt">data =</span> tabla_horoscopos)
horoscopo_saturado
<span class="co">#&gt; Call:</span>
<span class="co">#&gt; loglm(formula = Frequency ~ Star_Sign * Believe * True, data = tabla_horoscopos)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Statistics:</span>
<span class="co">#&gt;                  X^2 df P(&gt; X^2)</span>
<span class="co">#&gt; Likelihood Ratio   0  0        1</span>
<span class="co">#&gt; Pearson            0  0        1</span></code></pre></div>
<p>Podemos ver que el número de grados de libertad es cero, esto es, el número de parámetros es igual al número de observaciones.</p>
<p>Quitamos la interacción de los 3 factores y vemos la diferencia entre ambos modelos utilizando la función <code>anova()</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">horoscopo_homogeneo &lt;-<span class="st"> </span><span class="kw">update</span>(horoscopo_saturado, .<span class="op">~</span>. <span class="op">-</span>Star_Sign<span class="op">:</span>Believe<span class="op">:</span>True)
<span class="kw">anova</span>(horoscopo_saturado, horoscopo_homogeneo)
<span class="co">#&gt; LR tests for hierarchical log-linear models</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Model 1:</span>
<span class="co">#&gt;  Frequency ~ Star_Sign + Believe + True + Star_Sign:Believe + Star_Sign:True + Believe:True </span>
<span class="co">#&gt; Model 2:</span>
<span class="co">#&gt;  Frequency ~ Star_Sign * Believe * True </span>
<span class="co">#&gt; </span>
<span class="co">#&gt;           Deviance df Delta(Dev) Delta(df) P(&gt; Delta(Dev)</span>
<span class="co">#&gt; Model 1       8.84 11                                    </span>
<span class="co">#&gt; Model 2       0.00  0       8.84        11          0.637</span>
<span class="co">#&gt; Saturated     0.00  0       0.00         0          1.000</span></code></pre></div>
<p>Ahora podemos quitar las interacciones una a la vez:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">BelieveTrue &lt;-<span class="st"> </span><span class="kw">update</span>(horoscopo_homogeneo, .<span class="op">~</span>. <span class="op">-</span>Believe<span class="op">:</span>True)
Star_SignTrue &lt;-<span class="st"> </span><span class="kw">update</span>(horoscopo_homogeneo, .<span class="op">~</span>. <span class="op">-</span>Star_Sign<span class="op">:</span>True)
Star_SignBelieve &lt;-<span class="st"> </span><span class="kw">update</span>(horoscopo_homogeneo, .<span class="op">~</span>. <span class="op">-</span>Star_Sign<span class="op">:</span>Believe)</code></pre></div>
<p>Podemos ver nuevamente las diferencias de cada uno con respecto al modelo de asociación homogénea:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">anova</span>(horoscopo_homogeneo, Star_SignTrue)
<span class="co">#&gt; LR tests for hierarchical log-linear models</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Model 1:</span>
<span class="co">#&gt;  Frequency ~ Star_Sign + Believe + True + Star_Sign:Believe + Believe:True </span>
<span class="co">#&gt; Model 2:</span>
<span class="co">#&gt;  Frequency ~ Star_Sign + Believe + True + Star_Sign:Believe + Star_Sign:True + Believe:True </span>
<span class="co">#&gt; </span>
<span class="co">#&gt;           Deviance df Delta(Dev) Delta(df) P(&gt; Delta(Dev)</span>
<span class="co">#&gt; Model 1      19.58 22                                    </span>
<span class="co">#&gt; Model 2       8.84 11      10.74        11          0.465</span>
<span class="co">#&gt; Saturated     0.00  0       8.84        11          0.637</span></code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">anova</span>(horoscopo_homogeneo, BelieveTrue)
<span class="co">#&gt; LR tests for hierarchical log-linear models</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Model 1:</span>
<span class="co">#&gt;  Frequency ~ Star_Sign + Believe + True + Star_Sign:Believe + Star_Sign:True </span>
<span class="co">#&gt; Model 2:</span>
<span class="co">#&gt;  Frequency ~ Star_Sign + Believe + True + Star_Sign:Believe + Star_Sign:True + Believe:True </span>
<span class="co">#&gt; </span>
<span class="co">#&gt;           Deviance df Delta(Dev) Delta(df) P(&gt; Delta(Dev)</span>
<span class="co">#&gt; Model 1      21.38 12                                    </span>
<span class="co">#&gt; Model 2       8.84 11      12.54         1         0.0004</span>
<span class="co">#&gt; Saturated     0.00  0       8.84        11         0.6365</span></code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">anova</span>(horoscopo_homogeneo, Star_SignBelieve)
<span class="co">#&gt; LR tests for hierarchical log-linear models</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Model 1:</span>
<span class="co">#&gt;  Frequency ~ Star_Sign + Believe + True + Star_Sign:True + Believe:True </span>
<span class="co">#&gt; Model 2:</span>
<span class="co">#&gt;  Frequency ~ Star_Sign + Believe + True + Star_Sign:Believe + Star_Sign:True + Believe:True </span>
<span class="co">#&gt; </span>
<span class="co">#&gt;           Deviance df Delta(Dev) Delta(df) P(&gt; Delta(Dev)</span>
<span class="co">#&gt; Model 1      29.51 22                                    </span>
<span class="co">#&gt; Model 2       8.84 11      20.67        11          0.037</span>
<span class="co">#&gt; Saturated     0.00  0       8.84        11          0.637</span></code></pre></div>
<p>El modelo que consideraríamos más apropiado sería el que no incluye la interacción de Star_Sign y True. Comparamos con todos los modelos:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">anova</span>(horoscopo_homogeneo, BelieveTrue, Star_SignTrue, Star_SignBelieve)
<span class="co">#&gt; LR tests for hierarchical log-linear models</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Model 1:</span>
<span class="co">#&gt;  Frequency ~ Star_Sign + Believe + True + Star_Sign:Believe + Believe:True </span>
<span class="co">#&gt; Model 2:</span>
<span class="co">#&gt;  Frequency ~ Star_Sign + Believe + True + Star_Sign:True + Believe:True </span>
<span class="co">#&gt; Model 3:</span>
<span class="co">#&gt;  Frequency ~ Star_Sign + Believe + True + Star_Sign:Believe + Star_Sign:True </span>
<span class="co">#&gt; Model 4:</span>
<span class="co">#&gt;  Frequency ~ Star_Sign + Believe + True + Star_Sign:Believe + Star_Sign:True + Believe:True </span>
<span class="co">#&gt; </span>
<span class="co">#&gt;           Deviance df Delta(Dev) Delta(df) P(&gt; Delta(Dev)</span>
<span class="co">#&gt; Model 1      19.58 22                                    </span>
<span class="co">#&gt; Model 2      29.51 22      -9.93         0         1.0000</span>
<span class="co">#&gt; Model 3      21.38 12       8.12        10         0.6166</span>
<span class="co">#&gt; Model 4       8.84 11      12.54         1         0.0004</span>
<span class="co">#&gt; Saturated     0.00  0       8.84        11         0.6365</span></code></pre></div>
<p>Elegimos el modelo 1 (Star_Sign:True) porque tiene menor devianza para un número de parámetros aceptable (el número de grados de libertad es mayor). Esto implica que <em>no</em> hay asociación entre “si es verdad el horóscopo” y signo zodiacal, sin embargo sí existe una relación entre el signo zodiacal y si creen que el horóscopo es verdad.</p>
<p>Por ejemplo, los Aries tienden a creer mucho en su horóscopo, pero los Géminis no.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">Star_SignTrue<span class="op">$</span>param<span class="op">$</span>Star_Sign.Believe
<span class="co">#&gt;              Believe</span>
<span class="co">#&gt; Star_Sign     Believer Unbeliever</span>
<span class="co">#&gt;   Aquarius      0.0302    -0.0302</span>
<span class="co">#&gt;   Aries         0.2104    -0.2104</span>
<span class="co">#&gt;   Cancer        0.0348    -0.0348</span>
<span class="co">#&gt;   Capricorn     0.0164    -0.0164</span>
<span class="co">#&gt;   Gemini       -0.1680     0.1680</span>
<span class="co">#&gt;   Leo          -0.0939     0.0939</span>
<span class="co">#&gt;   Libra         0.0237    -0.0237</span>
<span class="co">#&gt;   Pisces        0.0959    -0.0959</span>
<span class="co">#&gt;   Sagittarius  -0.0478     0.0478</span>
<span class="co">#&gt;   Scorpio       0.0157    -0.0157</span>
<span class="co">#&gt;   Taurus       -0.0584     0.0584</span>
<span class="co">#&gt;   Virgo        -0.0590     0.0590</span></code></pre></div>
<hr />
<p><br></p>
</div>
<div id="tarea-opcional" class="section level2">
<h2><span class="header-section-number">5.13</span> Tarea (opcional)</h2>
<ol style="list-style-type: decimal">
<li>Demuestra que si <span class="math inline">\((n_1,n_2,\ldots,n_c)\)</span> sigue una distribución multinomial, entonces <span class="math inline">\(\mbox{Cov}(n_i,n_j)=-n\pi_i \pi_j\)</span> para toda <span class="math inline">\(i\neq j\)</span>. Para esto, define <span class="math inline">\(Y_{ij}\)</span> como <span class="math display">\[
Y_{ij} = \left\{ \begin{array}{cl}
1 &amp; \text{si la }\; i\text{-esima observacion es la categoria }j,\\
0 &amp; \text{en otro caso.}
\end{array}\right.
\]</span></li>
</ol>
<p>Sea <span class="math inline">\(Y_i=(Y_{i1},\ldots,Y_{ic})\)</span> el vector aleatorio correspondiente a la observación <span class="math inline">\(i\)</span>, tal que cada <span class="math inline">\(Y_i\)</span> tiene parámetros <span class="math display">\[
\pi = E(Y_i), \qquad \Sigma=\mbox{Cov}(Y_i),\quad i=1,\ldots,n.
\]</span></p>
<p><span class="math inline">\(Y_1,Y_2,\ldots,Y_n\)</span> son independientes e idénticamente distribuidos.</p>
<ol style="list-style-type: lower-alpha">
<li><p>Calcula <span class="math inline">\(\sigma_{jk}\)</span> para <span class="math inline">\(j\neq k\)</span> y <span class="math inline">\(\sigma_{jj}\)</span>. Escribe <span class="math inline">\(\mbox{Cov}(Y_i) = \sigma\)</span> en forma matricial.</p></li>
<li><p>Define <span class="math inline">\(p=(n_1,\ldots,n_c)\)</span> en términos de <span class="math inline">\((Y_1, \ldots, Y_n)\)</span>.</p></li>
<li><p>Calcula <span class="math inline">\(\mbox{Cov}(p)\)</span> y concluye que <span class="math inline">\(\mbox{Cov}(n_i,n_j)=-n\pi_i\pi_j\)</span> si <span class="math inline">\(i\neq j\)</span>.</p></li>
</ol>
<ol start="2" style="list-style-type: decimal">
<li>Para probar <span class="math inline">\(H_0:\pi_j = \pi_{j0}\)</span>, <span class="math inline">\(j=1,\ldots,c\)</span> con proporciones multinomiales muestrales <span class="math inline">\(\{\hat{\pi}_j\}\)</span> el estadístico del cociente de verosimilitud es <span class="math display">\[
G^2 = -2n \sum_j{\hat{\pi}_j}\,\mbox{log}\left(\pi_{j0}/\hat{\pi}_j\right).
\]</span></li>
</ol>
<p>Demuestra que <span class="math inline">\(G^2 \neq 0\)</span> y que la igualdad se da si y sólo si <span class="math inline">\(\hat{\pi}_j=\pi_{j0}\)</span> para toda <span class="math inline">\(j\)</span>. Para demostrar esto aplica la desigualdad de Jensen a <span class="math inline">\(E(-2n\,\mbox{log}(X))\)</span>, donde <span class="math inline">\(X\)</span> es igual a <span class="math inline">\(\pi_{j0}/\hat{\pi_j}\)</span> con probabilidad <span class="math inline">\(\hat{\pi}_j\)</span>.</p>
<ol start="3" style="list-style-type: decimal">
<li><p>Muestra que <span class="math inline">\(X^2 \leq n \,\cdot\,\mbox{min}(I-1,J-1)\)</span>. Por lo cual, <span class="math display">\[
V^2=\dfrac{X^2}{n \,\cdot\,\mbox{min}(I-1,J-1)}
\]</span> está entre <span class="math inline">\(0\)</span> y <span class="math inline">\(1\)</span>. A <span class="math inline">\(V^2\)</span> se le llama la <em>V de Cramér</em>.</p></li>
<li><p>Con los datos de la encuesta GSS realiza un análisis para responder las siguientes preguntas.</p></li>
</ol>
<ol style="list-style-type: lower-alpha">
<li><p>¿Las personas que creen en la vida después de la muerte son más felices?</p></li>
<li><p>¿Está asociada la creencia en la existencia de Dios con la afiliación política? Para esto combina las categorías de <code>PARTYID</code> de la siguiente forma: las categorías <span class="math inline">\(0,1\)</span> para Demócratas, <span class="math inline">\(2,3,4\)</span> para Independientes, y <span class="math inline">\(5,6\)</span> para Republicanos.</p></li>
</ol>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="teorema-del-limite-central.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="regresion-logistica-1.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
